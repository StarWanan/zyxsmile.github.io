{"title":"DMLNet","uid":"cca6975b74b1218e11c5b9ba5de4d5ef","slug":"DMLNet","date":"2022-05-03T12:07:00.000Z","updated":"2022-05-04T06:39:34.572Z","comments":true,"path":"api/articles/DMLNet.json","keywords":null,"cover":[],"content":"<meta name=\"referrer\" content=\"no-referrer\"/>\n<p>开放世界语义分割</p>\n<ul>\n<li>开集语义分割模块\n<ul>\n<li>闭集语义分割子模块</li>\n<li>异常分割子模块</li>\n</ul>\n</li>\n<li>增量小样本学习模块</li>\n</ul>\n<p>我是短小精悍的文章摘要(๑•̀ㅂ•́) ✧</p>\n<span id=\"more\"></span>\n<h1>CODE</h1>\n<p>multiscale 是自己设定的吗 <code>cfg.DATASET.imgSizes = (300, 375, 450, 525, 600)</code></p>\n<p>Seg 转化为long Tensor的目的是什么</p>\n<p>colors的作用是什么</p>\n<p>几个辅助函数的作用：</p>\n<p><code>Normalization(x)</code>: <img src=\"https://math.now.sh?inline=%5Cdfrac%7Bx%20-%20min%28x%29%7D%7Bmax(x)%20-%20min(x)%7D\" style=\"display:inline-block;margin: 0;\"/></p>\n<p><code>Coefficient_map(x, thre)</code>: <img src=\"https://math.now.sh?inline=%5Cdfrac%7B1%7D%7B1%20%2B%20exp%2850*(x%20-%20thre%29)%7D\" style=\"display:inline-block;margin: 0;\"/></p>\n<p><code>normfun(x, mu, sigma)</code>:<img src=\"https://math.now.sh?inline=%5Cdfrac%7Bexp%28-%5Cfrac%7B(x%20-%20mu%29%5E2%7D%7B2%20*%20%5Csigma%5E2%7D)%7D%7B%5Csigma%20*%20%5Csqrt%7B2*%5Cpi%7D%7D\" style=\"display:inline-block;margin: 0;\"/></p>\n<h1>论文阅读</h1>\n<h2 id=\"引言\">引言</h2>\n<p>Classical close-set semantic segmentation networks have limited ability to detect out-of-distribution (OOD) objects, which is important for safety-critical applications such as autonomous driving. Incrementally learning these OOD objects with few annotations is an ideal way to enlarge the knowledge base of the deep learning models. In this paper, we propose an open world semantic segmenta- tion system that includes two modules:</p>\n<p>(1) ==an open-set semantic segmentation module to detect both in-distribution and OOD objects==.</p>\n<p>(2) an incremental few-shot learning module to gradually incorporate those OOD objects into its existing knowledge base.</p>\n<p>This open world semantic segmentation system behaves like a human being, which is able to identify OOD objects and gradually learn them <strong>with corresponding supervision</strong>.</p>\n<p>We adopt the ==Deep Metric Learning Network (DMLNet) with contrastive clustering== to implement open-set semantic segmentation. Compared to other open-set semantic segmentation methods, our DMLNet achieves state-of-the-art performance on three challenging open-set semantic segmentation datasets without using additional data or generative models.</p>\n<p>On this basis, two incremental few-shot learning methods are fur- ther proposed to progressively improve the DMLNet with the annotations of OOD objects</p>\n<hr>\n<p>经典的闭集语义分割网络检测分布外 (OOD) 对象的能力有限，这对于自动驾驶等安全关键型应用很重要。 增量学习这些带有少量注释的 OOD 对象是扩大深度学习模型知识库的理想方法。 在本文中，我们提出了一个开放世界语义分割系统，包括两个模块：</p>\n<p>(1) <strong>一个开放集语义分割模块，用于检测内分布和OOD对象。</strong></p>\n<p><s>(2) 一个增量的小样本学习模块，逐渐将这些 OOD 对象纳入其现有的知识库。</s></p>\n<p>这个开放世界的语义分割系统就像一个人，能够识别OOD对象并在相应的监督下逐渐学习它们。</p>\n<p>我们采用具有==对比聚类的深度度量学习网络（DMLNet）==来实现开放集语义分割。 与其他开放集语义分割方法相比，我们的 DMLNet 在三个具有挑战性的开放集语义分割数据集上实现了最先进的性能，而无需使用额外的数据或生成模型。</p>\n<p><s>在此基础上，进一步提出了两种增量少样本学习方法，通过 OOD 对象的注释逐步改进 DMLNet</s></p>\n<h2 id=\"6-Conclusion\">6. Conclusion</h2>\n<p>We introduce an open world semantic segmentation system which incorporates two modules:</p>\n<ul>\n<li>an open-set segmentation module</li>\n<li>an incremental few-shot learning module.</li>\n</ul>\n<p>Our proposed open-set segmentation module is based on the <strong>deep metric learning network</strong>, and it uses the <strong>Euclidean distance sum</strong> criterion to achieve state-of-the-art performance.</p>\n<p>Two incremental few-shot learning methods are proposed to broaden the perception knowledge of the network. Both modules of the open world semantic segmentation system can be further studied to improve the performance. We hope our work can draw more researchers to contribute to this practically valuable research direction.</p>\n<hr>\n<p>我们介绍了一个开放世界语义分割系统，它包含两个模块：一个开放集分割模块和一个增量小样本学习模块。</p>\n<p>我们提出的开放集分割模块基于深度度量学习网络，它使用==欧几里德距离和标准==来实现最先进的性能。</p>\n<p>提出了两种增量少样本学习方法来拓宽网络的感知知识。 开放世界语义分割系统的两个模块都可以进一步研究以提高性能。 我们希望我们的工作能够吸引更多的研究人员为这个具有实际价值的研究方向做出贡献</p>\n<h2 id=\"1-介绍\">1. 介绍</h2>\n<p>得益于高质量的数据集 [3,4,5]，深度卷积网络在语义分割任务 [1, 2] 中取得了巨大成功。 这些语义分割网络在许多应用中被用作感知系统，如自动驾驶[6]、医疗诊断[7]等。然而，这些感知系统中的大多数都是闭集和静态的。 闭集语义分割假设测试中的所有类都已经在训练期间参与，这在开放世界中是不正确的。 如果闭集系统错误地将分发中标签分配给 OOD 对象 [8]，它可能会在安全关键型应用程序（如自动驾驶）中造成灾难性后果。 同时，静态感知系统无法根据所见内容更新其知识库，因此，它仅限于特定场景，需要在一定时间后重新训练。 为了解决这些问题，我们提出了一种开放集的动态感知系统，称为开放世界语义分割系统。 它包含两个模块：</p>\n<p>（1）一个开放集语义分割模块，用于检测OOD对象并将正确的标签分配给分布中的对象。</p>\n<p>(2) 一个增量的小样本学习模块，将这些未知对象逐步合并到其现有的知识库中。</p>\n<p>我们提出的开放世界语义分割系统的整个流程如<strong>图 1</strong> 所示</p>\n<p>开放集语义分割和增量小样本学习都没有得到很好的解决。</p>\n<p>对于开集语义分割，最重要的部分是在一张图像的所有像素中识别OOD像素，称为异常分割。 异常分割的典型方法是将图像级的开集分类方法应用于像素级的开集分类。</p>\n<p>这些方法包括基于不确定性估计的方法 [9, 10, 11, 12] 和基于自动编码器的方法 [13, 14]。 然而，这两种方法已被证明在驾驶场景中无效，因为基于不确定性估计的方法==会给出许多假阳性异常值检测== [15] 并且自动编码器==无法重新生成复杂的城市场景== [16]。 最近，基于生成对抗网络（基于 GAN）的方法 [16, 17] 已被证明是有效的，但它们远==非轻量级==，因为它们需要在管道中使用多个深度网络。</p>\n<p>对于增量少样本学习，我们不仅要处理增量学习的挑战，例如灾难性遗忘[18]，还要处理少样本学习的挑战，包括从少量样本中提取代表性特征[19]</p>\n<p>在本文中，我们建议使用 DMLNet 来解决开放世界语义分割问题。 原因有三：</p>\n<p>(1) DMLNet的分类原理是基于<strong>对比聚类</strong>，可以有效识别异常物体，如<strong>图2</strong>所示<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/3059369fae53d17d9774372efde6308d.png\" alt=\"image-20220427093204641\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>度量学习：从数据中学习一种度量数据对象间距离的方法。其目标是使得在学得的距离度量下，相似对象间的距离小，不相似对象间的距离大。</p>\n<p>传统的度量学习方法只能学习出线性特征，虽然有一些能够提取非线性特征的核方法被提出，但对学习效果也没有明显提升</p>\n<p>深度度量学习：深度学习的激活函数学习非线性特征的优秀能力，深度学习方法能够自动地从原始数据中学出高质量的特征。因此深度学习的网络结构与传统的度量学习方法相结合能够带来理想的效果。</p></blockquote>\n<p><s>(2) DMLNet结合原型非常适合few-shot 任务[19]。</s></p>\n<p><s>(3) DMLNet 的增量学习可以通过添加新的原型来实现，这是一种自然而有用的方法 [20]。</s></p>\n<p>基于 DMLNet 架构，我们为开放集语义分割模块开发了两种未知识别标准，为增量少样本学习模块开发了两种方法。</p>\n<p>根据我们的实验，这两个模块都被验证为有效且轻量级的。 总而言之，我们的贡献如下：</p>\n<ul>\n<li>我们率先推出开放世界语义分割系统，在实际应用中更加稳健实用。</li>\n<li>我们提出的基于 DMLNet 的开放集语义分割模块在三个具有挑战性的数据集上实现了最先进的性能。</li>\n<li>我们提出的few-shot 增量学习模块方法在很大程度上缓解了灾难性遗忘问题。</li>\n<li>通过结合我们提出的开放集语义分割模块和增量少样本学习模块，实现了一个开放世界语义分割系统。</li>\n</ul>\n<h2 id=\"2-Related-Work-2\">2. Related Work</h2>\n<h4 id=\"2-1-异常语义分割\">2.1 异常语义分割</h4>\n<p>异常语义分割的方法可以分为两种趋势：  基于不确定性估计的方法和基于生成模型的方法。</p>\n<p>不确定性估计的基线是最大softmax概率（MSP），它首先在[9]中提出。  Dan 等人没有使用 softmax 概率。  [11]提出使用最大logit（MaxLogit）并取得更好的异常分割性能。 贝叶斯网络采用深度学习网络的概率观点，所以它们的权重和输出是概率分布而不是特定的数字 [21, 22]。 在实践中，Dropout [10] 或集成 [12] 通常用于近似贝叶斯推理。</p>\n<p>自动编码器（AE）[23, 13] 和 RBM [14] 是典型的生成方法，假设 OOD 图像的重建误差大于分布内图像</p>\n<p>最近，另一种基于 GAN 再合成的生成模型被证明可以基于其可靠的高分辨率像素到像素转换结果实现最先进的性能。  SynthCP [17] 和 DUIR [16] 是基于 GAN 再合成的两种方法。 不幸的是，它们离轻量级还很远，因为必须依次使用两个或三个神经网络来进行 OOD 检测。</p>\n<p>与它们相比，我们证明了基于对比聚类的 DMLNet 具有更好的异常分割性能，而只需要推理一次</p>\n<h4 id=\"2-2-深度度量学习网络\">2.2 深度度量学习网络</h4>\n<p>DMLNets 已用于多种应用，包括视频理解 [24] 和人员重新识别 [25]。  DMLNet 使用欧几里得、马氏距离或 Matusita 距离 [26] 将此类问题转换为计算度量空间中的嵌入特征相似度。</p>\n<p><strong>卷积原型网络和 DMLNets</strong> 通常一起用于解决特定问题，例如检测图像级 OOD 样本 [27、28、29] 和用于语义分割的小样本学习 [19、30、31]。 我们也按照这种组合构建了第一个用于开放世界语义分割的 DMLNet</p>\n<h4 id=\"2-3-开放世界分类和检测\">2.3 开放世界分类和检测</h4>\n<p>开放世界分类首先由 [32] 提出。这项工作提出了最近非异常值 (NNO) 算法，该算法在增量添加对象类别、检测异常值和管理开放空间风险方面非常有效。<br>\n最近约瑟夫等人。  [33]提出了一种基于对比聚类、未知感知提议网络和基于能量的未知识别标准的开放世界对象检测系统。 我们的开放世界语义分割系统的管道与他们的相似，除了两个重要的区别使我们的任务更具挑战性：（1）在他们的开放集检测模块中，他们依赖于区域提议网络（RPN）是 类不可知，因此也可以检测到未标记的潜在 OOD 对象。 这样，OOD样本的信息对于训练是有效的。 但是，我们专注于语义分割，其中训练中使用的每个像素都被分配了一个分布内标签，因此<strong>不能将 OOD 样本添加到训练中</strong>。  (2) 在增量学习模块中，他们使用新类的所有标记数据，而我们专注于自然更困难的少样本条件。 很少有研究集中在增量小样本学习上，其中包括用于分类的增量小样本学习[34]、对象检测[35]和语义分割[36]</p>\n<h2 id=\"3-开放世界语义分割\">3. 开放世界语义分割</h2>\n<p>在本节中，我们给出了开放世界语义分割系统的工作流程。 该系统由一个开放集语义分割模块和一个增量小样本学习模块组成。 假设<img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bin%7D%20%3D%20%5C%7B%5Cmathcal%7BC%7D_%7Bin%2C1%7D%2C%20%5Cmathcal%7BC%7D_%7Bin%2C2%7D%2C...%2C%5Cmathcal%7BC%7D_%7Bin%2CN%7D%20%5C%7D\" style=\"display:inline-block;margin: 0;\"/>  是 N 个分布内的类，它们都在训练数据集中进行了注释，并且 <img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bout%7D%20%3D%20%5C%7B%5Cmathcal%7BC%7D_%7Bout%2C1%7D%2C%5Cmathcal%7BC%7D_%7Bout%2C2%7D%2C...%2C%5Cmathcal%7BC%7D_%7Bout%2CM%7D%20%5C%7D\" style=\"display:inline-block;margin: 0;\"/> 是训练数据集中没有遇到的 M 个 OOD 类</p>\n<p><strong>开集语义分割模块</strong>又分为两个子模块：<strong>闭集语义分割子模</strong>块和<strong>异常分割子模块</strong>。</p>\n<ul>\n<li><img src=\"https://math.now.sh?inline=%5Chat%7BY%7D%5E%7Bclose%7D\" style=\"display:inline-block;margin: 0;\"/> 是闭集语义分割子模块的输出图，所以每个像素的类别 <img src=\"https://math.now.sh?inline=%5Chat%7BY%7D%5E%7Bclose%7D_%7Bi%2Cj%7D%20%E2%88%88%20C_%7Bin%7D\" style=\"display:inline-block;margin: 0;\"/>。</li>\n<li>异常分割子模块的功能是识别OOD像素，其输出称为异常概率图：<img src=\"https://math.now.sh?inline=%5Chat%7BP%7D%20%5Cin%20%5B1%2C0%5D%5E%7BH%20%5Ctimes%20W%7D\" style=\"display:inline-block;margin: 0;\"/>，其中 <img src=\"https://math.now.sh?inline=H\" style=\"display:inline-block;margin: 0;\"/> 和 <img src=\"https://math.now.sh?inline=W\" style=\"display:inline-block;margin: 0;\"/> 表示输入图像的高度和宽度。</li>\n</ul>\n<p>基于 <img src=\"https://math.now.sh?inline=%5Chat%7BY%7D_%7Bclose%7D\" style=\"display:inline-block;margin: 0;\"/> 和 <img src=\"https://math.now.sh?inline=%5Chat%7BP%7D\" style=\"display:inline-block;margin: 0;\"/>，开集语义分割图 <img src=\"https://math.now.sh?inline=%5Chat%7BY%7D%5E%7Bopen%7D\" style=\"display:inline-block;margin: 0;\"/> 给出为:</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Chat%7BY%7D%5E%7Bopen%7D_%7Bi%2Cj%7D%20%3D%20%0A%5Cbegin%7Bcases%7D%0A%5Cmathcal%7BC%7D_%7Banomaly%7D%20%5Cquad%20%5C%20%20%20%20%20%5Chat%7BP%7D_%7Bi%2Cj%7D%20%3E%20%5Clambda_%7Bout%7D%20%5C%5C%0A%5Chat%7BY%7D_%7Bi%2Cj%7D%5E%7Bclose%7D%20%5Cquad%20%5Cquad%20%5Chat%7BP%7D_%7Bi%2Cj%7D%20%5Cle%20%5Clambda_%7Bout%7D%0A%5Cend%7Bcases%7D%20%5Ctag%7B1%7D%0A\" /></p><p><img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Banomaly%7D\" style=\"display:inline-block;margin: 0;\"/> ：表示 OOD 类别<br>\n<img src=\"https://math.now.sh?inline=%CE%BB_%7Bout%7D\" style=\"display:inline-block;margin: 0;\"/> ：确定 OOD 像素的阈值。</p>\n<p>因此，openset语义分割模块应该识别OOD像素并分配正确的分布标签。然后 Yopen 可以转发给可以从 <img src=\"https://math.now.sh?inline=C_%7Bout%7D\" style=\"display:inline-block;margin: 0;\"/> 中识别 <img src=\"https://math.now.sh?inline=C_%7Banomaly%7D\" style=\"display:inline-block;margin: 0;\"/> 并给出新类的相应注释的标注者  增量少样本学习模块用于在有新标签时将近集分割子模块的知识库从 <img src=\"https://math.now.sh?inline=C_%7Bin%7D\" style=\"display:inline-block;margin: 0;\"/> 一个一个更新为 <img src=\"https://math.now.sh?inline=C_%7Bin%2BM%7D\" style=\"display:inline-block;margin: 0;\"/>，其中 <img src=\"https://math.now.sh?inline=C_%7Bin%2Bt%7D%20%3D%20Cin%20%5Ccup%20%5C%7BC_%7Bout%2C1%7D%2CC_%7Bout%2C2%7D%2C...%2CC_%7Bout%2Ct%7D%5C%7D%2Ct%20%E2%88%88%7B1%2C2%2C...%2CM%7D\" style=\"display:inline-block;margin: 0;\"/>。 <strong>图 1</strong> 显示了开放世界语义分割系统的循环工作流水线</p>\n<p>图 1. 开放世界语义分割系统。 第 1 步：识别已知和未知对象（蓝色箭头）。 第 2 步：注释未知对象（红色箭头）。 第 3 步：应用增量少样本学习来增加网络的分类范围（绿色箭头）。 第 4 步：在增量少样本学习之后，DMLNet 可以在更大的域中输出结果（紫色箭头）。<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/a0bd42a6330af3e8f0f98b7db6003fa9.png\" alt=\"image-20220420232032090\"></p>\n<h2 id=\"4-方法\">4. 方法</h2>\n<p>我们采用 DMLNet 作为我们的特征提取器，并在 4.1 节讨论架构和损失函数。 开放集分割模块和增量少样本学习模块在 4.2 和 4.3 节中进行了说明</p>\n<h3 id=\"4-1-深度度量学习网络\">4.1 深度度量学习网络</h3>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Classical CNN-based semantic segmentation networks can be disentangled into two parts:</p>\n<ul>\n<li>a feature extractor <img src=\"https://math.now.sh?inline=f%28X%3B%CE%B8_f%29\" style=\"display:inline-block;margin: 0;\"/> for obtaining the embedding vector of each pixel</li>\n<li>a classifier <img src=\"https://math.now.sh?inline=g%28f(X%3B%CE%B8_f%29%3B%CE%B8_g)\" style=\"display:inline-block;margin: 0;\"/> for generating the decision boundary,</li>\n</ul>\n<p>where <img src=\"https://math.now.sh?inline=X\" style=\"display:inline-block;margin: 0;\"/>, <img src=\"https://math.now.sh?inline=%CE%B8_f\" style=\"display:inline-block;margin: 0;\"/> and <img src=\"https://math.now.sh?inline=%CE%B8_g\" style=\"display:inline-block;margin: 0;\"/> denote the <strong>input image</strong>, <strong>parameters</strong> of the feature extractor and classifier respectively.</p>\n<p>This learnable classifier is not suitable for OOD detection because it assigns all feature space to known classes and leaves no space for OOD classes.</p></blockquote>\n<p>传统CNN-based语义分割网络：</p>\n<ul>\n<li><img src=\"https://math.now.sh?inline=f%28X%3B%5Ctheta_f%29\" style=\"display:inline-block;margin: 0;\"/> 特征提取器：获取每个像素的嵌入向量</li>\n<li><img src=\"https://math.now.sh?inline=g%28f(X%3B%5Ctheta_f%29%3B%5Ctheta_g)\" style=\"display:inline-block;margin: 0;\"/> 分类器：生成决策边界</li>\n</ul>\n<p>这种==可学习的分类器不适用于 OOD 检测==，因为它将所有特征空间分配给已知类，并且没有为 OOD 类留下空间。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>In contrast, the classifier is replaced by the Euclidean distance representation with all prototypes <img src=\"https://math.now.sh?inline=%5Cmathcal%7BM%7D_%7Bin%7D%20%3D%20%5C%7B%20m_t%20%5Cin%20%5Cmathbb%7BR%7D%5E%7B1%20%5Ctimes%20N%7D%7Ct%20%5Cin%20%5C%7B1%2C2%2C...%2CN%5C%7D%20%20%5C%7D\" style=\"display:inline-block;margin: 0;\"/> in DMLNet, where <img src=\"https://math.now.sh?inline=m_t\" style=\"display:inline-block;margin: 0;\"/> refers to the prototype of class <img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bin%2Ct%7D\" style=\"display:inline-block;margin: 0;\"/>. The feature extractor <img src=\"https://math.now.sh?inline=f%28X%3B%CE%B8_f%29\" style=\"display:inline-block;margin: 0;\"/> learns to map the input <img src=\"https://math.now.sh?inline=X\" style=\"display:inline-block;margin: 0;\"/> to the feature vector which has the same length as the prototype in metric space. For the close-set segmentation task, the probability of one pixel <img src=\"https://math.now.sh?inline=X_%7Bi%2Cj%7D\" style=\"display:inline-block;margin: 0;\"/> belonging to the class <img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bin%2Ct%7D\" style=\"display:inline-block;margin: 0;\"/> is formulated as:</p></blockquote>\n<p>DMLNet 中, ==所有原型的欧几里得距离==表示代替了传统的可学习分类器</p>\n<ul>\n<li><img src=\"https://math.now.sh?inline=m_t\" style=\"display:inline-block;margin: 0;\"/> 指的是 <img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bin%2Ct%7D\" style=\"display:inline-block;margin: 0;\"/> 类的原型。</li>\n</ul>\n<p>特征提取器 <img src=\"https://math.now.sh?inline=f%28X%3B%CE%B8_f%29\" style=\"display:inline-block;margin: 0;\"/>学习将输入 X 映射到与度量空间中的原型长度相同的特征向量。</p>\n<p>对于闭集分割任务，一个像素 <img src=\"https://math.now.sh?inline=X_%7Bi%2Cj%7D\" style=\"display:inline-block;margin: 0;\"/> 属于类 <img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bin%2Ct%7D\" style=\"display:inline-block;margin: 0;\"/> 的概率公式为：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=p_t%28X_%7Bi%2Cj%7D%29%20%3D%20%5Cfrac%7Bexp(-%7C%7Cf(X%3B%5Ctheta_f)_%7Bi%2Cj%7D%20-%20m_t%7C%7C%5E2)%7D%7B%5Csum%5EN_%7Bt'%3D1%7D%20exp(-%7C%7Cf(X%3B%5Ctheta_f)_%7Bi%2Cj%7D%20-%20m_%7Bt'%7D%7C%7C%5E2)%7D%20%5Ctag%7B2%7D%0A\" /></p><p>基于这种基于欧几里德距离的概率，<strong>判别交叉熵 (DCE)</strong> 损失函数 <img src=\"https://math.now.sh?inline=%5Cmathcal%7BL%7D_%7BDCE%7D%28X_%7Bi%2Cj%7D%2CY_%7Bi%2Cj%7D%3B%CE%B8_f%2CM_%7Bin%7D%29\" style=\"display:inline-block;margin: 0;\"/> [27] 定义为:</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Cmathcal%7BL%7D_%7BDCE%7D%20%3D%20%5Csum_%7Bi%2Cj%7D%20-log%20%28%5Cfrac%7Bexp(-%7C%7Cf(X%3B%5Ctheta_f%29_%7Bi%2Cj%7D%20-%20m_%7BY_%7Bi%2Cj%7D%7D%7C%7C%5E2)%7D%7B%5Csum%5EN_%7Bk%3D1%7D%20exp(-%7C%7Cf(X%3B%5Ctheta_f)_%7Bi%2Cj%7D%20-%20m_%7Bk%7D%7C%7C%5E2)%7D%20%5Ctag%7B3%7D%0A\" /></p><p><img src=\"https://math.now.sh?inline=Y\" style=\"display:inline-block;margin: 0;\"/>：输入图像 <img src=\"https://math.now.sh?inline=X\" style=\"display:inline-block;margin: 0;\"/> 的标签<br>\n<img src=\"https://math.now.sh?inline=%5Cmathcal%7BL%7D_%7BDCE%7D\" style=\"display:inline-block;margin: 0;\"/> 的分子和分母分别指图2中的吸引力和排斥力。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>排斥力不需要除去本身所属的类，本身类的原型吗？</p></blockquote>\n<p>图 2. DMLNet 的对比聚类。 在推理过程中，已知对象将被同一类的原型所吸引，而被剩余的原型所排斥。 最后，它们将围绕特定的原型进行聚合。 相反，异常对象将被所有原型排斥，因此它们将聚集在度量空间的中间。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/img_convert/612d74a8faea61ce32297df9c175614a.png\" alt=\"\"></p>\n<p>我们制定了另一个损失函数，称为<strong>方差损失 (VL)</strong> 函数 <img src=\"https://math.now.sh?inline=%5Cmathcal%7BL%7D_%7BVL%7D%28X_%7Bi%2Cj%7D%2CY_%7Bi%2Cj%7D%3B%CE%B8_f%2CM_%7Bin%7D%29\" style=\"display:inline-block;margin: 0;\"/>，其定义为：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Cmathcal%7BL%7D_%7BVL%7D%20%3D%20%5Csum_%7Bi%2Cj%7D%20%7C%7Cf%28X%3B%5Ctheta_f%29_%7Bi%2Cj%7D%20-%20m_%7BY_%7Bi%2Cj%7D%7D%7C%7C%5E2%20%5Ctag%7B4%7D%0A\" /></p><p><img src=\"https://math.now.sh?inline=%5Cmathcal%7BL%7D_%7BVL%7D\" style=\"display:inline-block;margin: 0;\"/> 只有吸引力作用，没有排斥力作用。</p>\n<p>使用 DCE 和 VL，混合损失定义为：<img src=\"https://math.now.sh?inline=%5Cmathcal%7BL%7D%3D%20%5Cmathcal%7BL%7D_%7BDCE%7D%20%2B%20%CE%BB_%7BVL%7D%5Cmathcal%7BL%7D_%7BVL%7D\" style=\"display:inline-block;margin: 0;\"/>，其中 <img src=\"https://math.now.sh?inline=%CE%BB_%7BVL%7D\" style=\"display:inline-block;margin: 0;\"/> 是权重参数</p>\n<h3 id=\"4-2-开集语义分割模型\">4.2 开集语义分割模型</h3>\n<p>开集语义分割模块由闭集语义分割子模块和异常分割子模块组成。 开放集语义分割模块的流程如 图3 所示。</p>\n<p><strong>图3</strong>.闭集分割子模块包含在蓝色虚线框内，异常分割子模块包含在红色虚线框内。 开集分割图是这两个子模块生成的结果的组合。 在开放集分割图中预测分布内类和 OOD 类。  EDS map 和 MMSP map 的定义请参考 4.2 节。<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/199103762c48247cdd50705bd8aae780.png\" alt=\"image-20220420113236739\"></p>\n<ul>\n<li>\n<p><strong>闭集语义分割子模块</strong>为一幅图像的所有像素分配分布标签。 由于一个像素 <img src=\"https://math.now.sh?inline=X_%7Bi%2Cj%7D\" style=\"display:inline-block;margin: 0;\"/> 属于类 <img src=\"https://math.now.sh?inline=%5Cmathcal%7BC%7D_%7Bin%2Ct%7D\" style=\"display:inline-block;margin: 0;\"/> 的概率是用公式 2 表示，闭集分割图为：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Chat%7BY%7D_%7Bi%2Cj%7D%5E%7Bclose%7D%20%3D%20argmax_t%20%5C%20p_t%28X_%7Bi%2Cj%7D%29%20%5Ctag%7B5%7D%0A\" /></p></li>\n<li>\n<p><strong>异常分割子模块</strong>检测OOD像素。 我们提出了两个未知的识别标准来测量异常概率，包括_基于度量的最大softmax概率（MMSP）<em>和_欧几里得距离和（EDS）</em>。</p>\n<ul>\n<li>\n<p>以下是基于 MMSP 的异常概率：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Chat%7BP%7D%5E%7BMMSP%7D_%7Bi%2Cj%7D%20%3D%201%20-%20max%20%5C%20p_t%28X_%7Bi%2Cj%7D%29%2C%5C%20t%20%5Cin%20%5C%7B%201%2C2%2C3...%2CN%20%5C%7D%20%5Ctag%7B6%7D%0A\" /></p></li>\n<li>\n<p>EDS 是根据以下发现提出的：如果特征位于 OOD 像素聚集的度量空间的中心，则与所有原型的欧几里得距离和更小，即==异常的欧几里得距离较小==。  EDS 定义为：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=S%28X_%7Bi%2Cj%7D%29%20%3D%20%5Csum_%7Bt%3D1%7D%5EN%20%7C%7Cf(X%3B%5Ctheta_f)_%7Bi%2Cj%7D%20-%20m_t%7C%7C%5E2%20%5Ctag%7B7%7D%0A\" /></p><p>基于 EDS 的异常概率计算如下：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Chat%7BP%7D%5E%7BEDS%7D_%7Bi%2Cj%7D%20%3D%201-%20%5Cfrac%7BS%28X_%7Bi%2Cj%7D%29%7D%7BmaxS(X)%7D%20%5Ctag%7B8%7D%0A\" /></p></li>\n</ul>\n</li>\n</ul>\n<p>EDS 是类独立的，因此所有类的原型应该均匀分布在度量空间中，并且在训练期间不移动。 ==可学习的原型会在训练期间导致不稳定，并且对更好的性能没有贡献== [37]。 因此，我们以 one-hot 向量形式定义原型：只有 <img src=\"https://math.now.sh?inline=m_t\" style=\"display:inline-block;margin: 0;\"/> 的第 t 个元素是 <img src=\"https://math.now.sh?inline=T\" style=\"display:inline-block;margin: 0;\"/>，而其他元素保持为零，其中 t ∈ {1,2,…,N}</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>PAnS是什么情况？</p></blockquote>\n<p>EDS 是相对于所有像素之间的最大距离和的比率，即使图像中没有 OOD 对象，高异常分数区域肯定存在于每幅图像中。 此外，每个分布内类别的距离总和分布彼此略有不同，如图4所示。<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/0d67bbc9c6b8ba396376bad696c5f660.png\" alt=\"\"></p>\n<p>将MMSP与EDS相结合，以抑制那些实际上处于分布状态的具有中间响应的像素。</p>\n<p>混合函数为：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Chat%7BP%7D%20%3D%20%5Calpha%20%5Chat%7BP%7D%5E%7BEDS%7D%20%2B%20%281-%5Calpha%29%5Chat%7BP%7D%5E%7BMMSP%7D%20%5Ctag%7B9%7D%0A\" /></p><ul>\n<li>\n<p>α ：</p>\n<p style=\"\"><img src=\"https://math.now.sh?from=%5Calpha%20%3D%20%5Cfrac%7B1%7D%7B1%20%2B%20exp%28-%5Cbeta(%5Chat%7BP%7D%5E%7BEDS%7D%20-%20%5Cgamma%29)%7D%20%5Ctag%7B10%7D%0A\" /></p><ul>\n<li>β 和 γ 是控制抑制效果和阈值的超参数。</li>\n</ul>\n</li>\n</ul>\n<p>通过方程 9 得到异常概率图和方程 5 得到闭集分割图后，我们应用方程 1 生成最终的开集分割图</p>\n<h2 id=\"5-实验\">5. 实验</h2>\n<p>Our experiments are divided into three parts.</p>\n<ul>\n<li>We first evaluate our open-set semantic segmentation approach in Section 5.1.</li>\n<li><s>Then we demonstrate our incremental few-shot learning results in Section 5.2.</s></li>\n<li><s>Based on the open-set semantic segmentation module and incremental few-show learning module, the whole open world semantic segmentation is realized in Section 5.3.</s></li>\n</ul>\n<h3 id=\"5-1-开集语义分割\">5.1 开集语义分割</h3>\n<p><strong>数据集</strong>。 三个数据集包括 StreetHazards [11]、Lost and Found [38] 和 Road Anomaly [16] 用于证明我们基于 DMLNet 的开放集语义分割方法的稳健性和有效性。</p>\n<ul>\n<li>StreetHazards 的大多数异常物体是大型稀有运输机器，例如直升机、飞机和拖拉机。</li>\n<li>Lost and Found 含许多小的异常物品，如货物、玩具和盒子。</li>\n<li>Road Anomaly 数据集不再限制城市场景中的场景，还包含村庄和山脉的图像。</li>\n</ul>\n<p><strong>指标</strong>。 开放集语义分割是封闭集分割和异常分割的组合，如 4.2 节所述。</p>\n<ul>\n<li>对于闭集语义分割任务，我们使用 mIoU 来评估性能。</li>\n<li>对于异常分割任务，根据 [11] 使用三个指标，包括 ROC 曲线下面积（AUROC）、95% 召回的误报率（FPR95）和精确召回曲线下面积（AUPR）。</li>\n</ul>\n<p><strong>实施细节</strong>。</p>\n<ul>\n<li>\n<p>对于 StreetHazards，我们遵循与 [11] 相同的训练程序，在 StreetHazards 的训练集上训练 PSPNet [2]。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>[11]: Scaling out-of-distribution detection for real-world settings.</p></blockquote>\n</li>\n<li>\n<p>对于Lost and Found和 Road Anomaly，我们按照 [16] 使用 BDD-100k [39] 来训练 PSPNet。 请注意，PSPNet 仅用于提取我们在 4.1 节中讨论的特征（获得每个像素的嵌入向量）。 混合损失的 <img src=\"https://math.now.sh?inline=%CE%BB_%7BVL%7D\" style=\"display:inline-block;margin: 0;\"/> 为 0.01。   所有原型中非零元素 <img src=\"https://math.now.sh?inline=T\" style=\"display:inline-block;margin: 0;\"/> 为 3。等式 10 中的 β 和 γ 分别为 20 和 0.8。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>[16]: Detecting the unexpected via image resynthesis</p></blockquote>\n</li>\n</ul>\n<p><strong>基线</strong>。</p>\n<ul>\n<li>StreetHazards:  MSP [9]、Dropout [10]、AE [13]、MaxLogit [11] 和 SynthCP [17]。</li>\n<li>Lost and Found 和 Road Anomaly:  MSP、MaxLogit、Ensemble [12]、RBM [14] 和 DUIR [16]。</li>\n</ul>\n<p><strong>结果</strong>。</p>\n<p>StreetHazards 的结果如表 1 所示。<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/7af32b5d50560d198a2257c0403552c5.png\" alt=\"image-20220421080547891\"></p>\n<p>对于 Lost and Found 和 Road Anomaly，mIoU 是无效的，因为它们只提供 OOD 类标签，但没有特定的分布内类标签。 结果在表 2 中。<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/cc63fd7d97d7081dffe3de465d30dfb6.png\" alt=\"image-20220421080604032\"></p>\n<p>我们的实验表明：</p>\n<ul>\n<li>基于 DMLNet 的方法在所有三个异常分割相关指标中都达到了最先进的性能。</li>\n<li>与最近提出的基于 GAN 的方法（包括 DUIR 和 SynthCP）相比，我们的方法在异常分割质量方面优于它们，结构更轻量级，因为它们在整个流程中需要两个或三个深度神经网络，而我们只需要推理一次。</li>\n<li>StreetHazards 中闭集分割的 mIoU 值表明我们的方法对闭集分割没有危害。</li>\n</ul>\n<p>一些定性结果如图 8 所示<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/c5e1b4154631126fe31bd9d1048b62ba.png\" alt=\"image-20220424132323338\"></p>\n<p><strong>消融研究</strong>。 我们仔细进行了消融实验，研究了不同损失函数（VL 和 DCE）和异常判断标准（EDS 和 MMSP）的影响，如表 3 所示。<br>\n<img src=\"https://img-blog.csdnimg.cn/img_convert/8c7e4e19282709f61074e0ac5ec97503.png\" alt=\"\"></p>\n<ul>\n<li>DCE 在 mIoU 上的性能优于 VL 的事实表明了 排斥力。</li>\n<li>EDS 在所有损失下都优于 MMSP 函数，这意味着==与类无关的标准更适合于异常分割任务==</li>\n</ul>\n","feature":true,"text":" 开放世界语义分割 开集语义分割模块 闭集语义分割子模块 异常分割子模块 增量小样本学习模块 我是短小精悍的文章摘要(๑•̀ㅂ•́) ✧ CODE multiscale 是自己设定的吗 cfg.DATASET.imgSizes = (300, 375, 450, 525, 600) ...","link":"","photos":[],"count_time":{"symbolsCount":"10k","symbolsTime":"9 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":2,"path":"api/tags/深度学习.json"},{"name":"异常分割","slug":"异常分割","count":2,"path":"api/tags/异常分割.json"},{"name":"度量学习","slug":"度量学习","count":1,"path":"api/tags/度量学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\"><span class=\"toc-text\">CODE</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\"><span class=\"toc-text\">论文阅读</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BC%95%E8%A8%80\"><span class=\"toc-text\">引言</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-Conclusion\"><span class=\"toc-text\">6. Conclusion</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">1. 介绍</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-Related-Work-2\"><span class=\"toc-text\">2. Related Work</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2-1-%E5%BC%82%E5%B8%B8%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2\"><span class=\"toc-text\">2.1 异常语义分割</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2-2-%E6%B7%B1%E5%BA%A6%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">2.2 深度度量学习网络</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2-3-%E5%BC%80%E6%94%BE%E4%B8%96%E7%95%8C%E5%88%86%E7%B1%BB%E5%92%8C%E6%A3%80%E6%B5%8B\"><span class=\"toc-text\">2.3 开放世界分类和检测</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-%E5%BC%80%E6%94%BE%E4%B8%96%E7%95%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2\"><span class=\"toc-text\">3. 开放世界语义分割</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">4. 方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-1-%E6%B7%B1%E5%BA%A6%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">4.1 深度度量学习网络</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-2-%E5%BC%80%E9%9B%86%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">4.2 开集语义分割模型</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-%E5%AE%9E%E9%AA%8C\"><span class=\"toc-text\">5. 实验</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-%E5%BC%80%E9%9B%86%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2\"><span class=\"toc-text\">5.1 开集语义分割</span></a></li></ol></li></ol></li></ol>","author":{"name":"Star","slug":"blog-author","avatar":"https://gitee.com/zyxstar/Pic_bed/raw/master/image/C06BE6D9-B862-4B4B-A025-F273AE06FAF0.jpeg","link":"/","description":"有棱有角，还会发光；认真生活，星之煌煌","socials":{"github":"https://github.com/ZYXsmile","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Pytorch & python","uid":"4346091fabb18c4f718acfd51c087897","slug":"python&pytorch使用指南","date":"2022-05-03T12:10:00.000Z","updated":"2022-05-04T03:39:30.478Z","comments":true,"path":"api/articles/python&pytorch使用指南.json","keywords":null,"cover":null,"text":"pytorch 参数 &amp; 命令行 &amp; 辅助 logger logger模块解释 —— CSDN logger使用案例 logging模块是Python内置的标准模块，主要用于输出运行日志，可以设置输出日志的等级、日志保存路径、日志文件回滚等 yacs.config...","link":"","photos":[],"count_time":{"symbolsCount":"7.4k","symbolsTime":"7 mins."},"categories":[],"tags":[],"author":{"name":"Star","slug":"blog-author","avatar":"https://gitee.com/zyxstar/Pic_bed/raw/master/image/C06BE6D9-B862-4B4B-A025-F273AE06FAF0.jpeg","link":"/","description":"有棱有角，还会发光；认真生活，星之煌煌","socials":{"github":"https://github.com/ZYXsmile","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{}}