[{"id":"082602022df518a2faf6c62dcd303051","title":"一类嵌入的反向蒸馏","content":"Anomaly\nDetection via Reverse Distillation from One-Class Embedding\n通过一类嵌入的反向蒸馏进行异常检测\n\nAbstract\nKnowledge distillation (KD) achieves promising results on the\nchallenging problem of unsupervised anomaly detection (AD). The\nrepresentation discrepancy of anomalies in the teacher-student (T-S)\nmodel provides essential evidence for AD.\nHowever, using similar or identical architectures to build the\nteacher and student models in previous stud- ies hinders the diversity\nof anomalous representations. To tackle this problem, we propose a novel\nT-S model consisting of a teacher encoder and a student decoder and\nintroduce a simple yet effective “reverse distillation”\nparadigm accordingly.\nInstead of receiving raw images directly, the student network takes\nteacher model’s one-class embedding as input and targets to restore the\nteacher’s multi-scale representations.\nInherently, knowledge distillation in this study starts from\nabstract, high-level presentations to low-level features.\nIn addition, we introduce a trainable one-class bottleneck\nembedding (OCBE) module in our T-S model.\nThe obtained compact embedding effectively preserves essential\ninformation on normal patterns, but abandons anomaly perturbations.\nExtensive experimentation on AD and one-class novelty detection\nbenchmarks shows that our method surpasses SOTA performance,\ndemonstrating our proposed approach’s effectiveness and\ngeneralizability.\n\n知识蒸馏（KD）在无监督异常检测（AD）的挑战性问题上取得了可喜的成果。\n师生（T-S）模型中异常的表示差异为AD提供了必要的证据。\n然而，在以前的研究中使用相似或相同的架构来构建教师和学生模型阻碍了异常表示的多样性。\n为了解决这个问题，我们提出了一种由教师编码器和学生解码器组成的新型 T-S\n模型，并相应地引入了一种简单而有效的“逆向蒸馏”范式。\n学生网络不是直接接收原始图像，而是将教师模型的一类嵌入作为输入和目标，以恢复教师的多尺度表示。\n本质上，本研究中的知识蒸馏从抽象的高级表示开始到低级特征。\n此外，我们在 T-S 模型中引入了可训练的一类瓶颈嵌入 (OCBE) 模块。\n获得的紧凑嵌入有效地保留了正常模式的基本信息，但放弃了异常扰动。\n对 AD 和一类新颖性检测基准的广泛实验表明，我们的方法超越了 SOTA\n性能，证明了我们提出的方法的有效性和普遍性。\n1. Introduction\nAnomaly detection (AD) refers to identifying and localizing\nanomalies with limited, even no, prior knowledge of\nabnormality.\nThe wide applications of AD, such as indus- trial defect detection\n[3], medical out-of-distribution detection [50], and video surveillance\n[24], makes it a critical task as well as a spotlight. In the context of\nunsupervised AD, no prior information on anomalies is\navailable. Instead, a set of normal samples is provided for\nreference.\nTo tackle this problem, previous efforts attempt to construct various\nself-supervision tasks on those anomaly-free samples. These tasks\ninclude, but not limited to, sample reconstruction [2, 5, 11, 16, 26,\n34, 38, 48], pseudo-outlier augmentation [23, 42, 46], knowledge\ndistillation [4, 33, 39], etc.\nIn this study, we tackle the problem of unsupervised anomaly\ndetection from the knowledge distillation-based point of view.\nIn knowledge distillation (KD) [6, 15], knowledge is\ntransferred within a teacher-student (T-S) pair. In the context of\nunsupervised AD, since the student experiences only normal samples\nduring training, it is likely to generate discrepant representations\nfrom the teacher when a query is anomalous. This hypothesis forms the\nbasis of KD-based methods for anomaly detection.\nHowever, this hypothesis is not always true in practice due to\n\nthe identical or similar architectures of the teacher and student\nnetworks (i.e., non-distinguishing filters [33])\nthe same data flow in the T-S model during knowledge trans-\nfer/distillation.\n\nThough the use of a smaller student network partially addresses this\nissue [33, 39], the weaker represen- tation capability of shallow\narchitectures hinders the model from precisely detecting and localizing\nanomalies.\n\n异常检测 (AD)\n是指在对异常的先验知识有限甚至没有的情况下识别和定位异常。\nAD 的广泛应用，如工业缺陷检测 [3]、医疗分布外检测 [50] 和视频监控\n[24]，使其成为一项关键任务和聚光灯。 在无监督 AD\n的背景下，没有关于异常的先验信息可用。\n相反，提供了一组正常样本以供参考。\n为了解决这个问题，以前的努力试图在那些无异常的样本上构建各种自我监督任务。\n这些任务包括但不限于样本重建[2、5、11、16、26、34、38、48]、伪异常值增强[23、42、46]、知识蒸馏[4、33、\n39]等。\n在这项研究中，我们从基于知识蒸馏的角度解决了无监督异常检测的问题。\n在知识蒸馏 (KD) [6, 15] 中，知识在师生 (T-S) 对中转移。 在无监督 AD\n的背景下，由于学生在训练期间只体验到正常样本，因此当查询异常时，它可能会从教师那里产生不一致的表示。\n该假设构成了基于 KD 的异常检测方法的基础。\n然而，这个假设在实践中并不总是正确的，因为\n\n教师和学生网络的相同或相似架构（即非区分过滤器 [33]）\nT-S 模型中的相同数据流 知识转移/蒸馏。\n\n尽管使用较小的学生网络部分解决了这个问题 [33,\n39]，但浅层架构较弱的表示能力阻碍了模型精确检测和定位异常。\n\nTo holistically address the issue mentioned above, we propose a new\nparadigm of knowledge distillation, namely Reverse Distillation, for\nanomaly detection. We use sim- ple diagrams in Fig. 2 to highlight the\nsystematic differ- ence between conventional knowledge distillation and\nthe proposed reverse distillation. First, unlike the conventional\nknowledge distillation framework where both teacher and student adopt\nthe encoder structure, the T-S model in our reverse distillation\nconsists of heterogeneous architectures: a teacher encoder and a student\ndecoder. Second, instead of directly feeding the raw data to the T-S\nmodel simulta- neously, the student decoder takes the low-dimensional\nem- bedding as input, targeting to mimic the teacher’s behavior by\nrestoring the teacher model’s representations in different scales. From\nthe regression perspective, our reverse distil- lation uses the student\nnetwork to predict the representa- tion of the teacher model. Therefore,\n”reverse” here indi- cates both the reverse shapes of teacher encoder\nand stu- dent decoder and the distinct knowledge distillation order\nwhere high-level representation is first distilled, followed by\nlow-level features. It is noteworthy that our reverse distilla- tion\npresents two significant advantages: i) Non-similarity\nstructure. In the proposed T-S model, one can consider the teacher\nencoder as a down-sampling filter and the stu- dent decoder as an\nup-sampling filter. The ”reverse struc- tures” avoid the confusion\ncaused by non-distinguishing fil- ters [33] as we discussed above. ii)\nCompactness embed- ding. The low-dimensional embedding fed to\nthe student decoder acts as an information bottleneck for normal pat-\ntern restoration. Let’s formulate anomaly features as pertur- bations on\nnormal patterns. Then the compact embedding helps to prohibit the\npropagation of such unusual perturba- tions to the student model and\nthus boosts the T-S model’s representation discrepancy on anomalies.\nNotably, tradi- tional AE-based methods [5, 11, 16, 26] detect anomalies\nutilising pixel differences, whereas we perform discrimi- nation with\ndense descriptive features. Deep features as region-aware descriptors\nprovide more effective discrimi- native information than per-pixel in\nimages.\n\n\n\n\n\n\n\n\n\n为了全面解决上述问题，我们提出了一种新的知识蒸馏范式，即反向蒸馏，用于异常检测。\n我们使用图 2\n中的简单图表来突出传统知识蒸馏和提出的逆向蒸馏之间的系统差异。\n首先，与教师和学生都采用编码器结构的传统知识蒸馏框架不同，我们的逆向蒸馏中的\nT-S 模型由异构架构组成：教师编码器和学生解码器。\n其次，学生解码器不是直接将原始数据同时馈送到 T-S\n模型，而是将低维嵌入作为输入，旨在通过恢复教师模型在不同尺度上的表示来模仿教师的行为。\n从回归的角度来看，我们的反向蒸馏使用学生网络来预测教师模型的表示。\n因此，这里的“反向”表示教师编码器和学生解码器的反向形状以及不同的知识蒸馏顺序，其中首先蒸馏高级表示，然后是低级特征。\n值得注意的是，我们的逆向蒸馏具有两个显着优势：i）非相似性结构。\n在提出的 T-S\n模型中，可以将教师编码器视为下采样滤波器，将学生解码器视为上采样滤波器。\n正如我们上面讨论的，“反向结构”避免了由非区分过滤器[33]引起的混淆。 ii)\n紧凑性嵌入。\n馈送到学生解码器的低维嵌入充当了正常模式恢复的信息瓶颈。\n让我们将异常特征表述为对正常模式的扰动。\n然后紧凑嵌入有助于禁止这种不寻常的扰动传播到学生模型，从而提高 T-S\n模型对异常的表示差异。 值得注意的是，传统的基于 AE 的方法\n[5、11、16、26]\n利用像素差异检测异常，而我们使用密集的描述性特征进行区分。\n作为区域感知描述符的深度特征比图像中的每个像素提供更有效的判别信息。\nIn addition, since the compactness of the bottleneck em- bedding is\nvital for anomaly detection (as discussed above), we introduce a\none-class bottleneck embedding (OCBE) module to condense the feature\ncodes further. Our OCBE module consists of a multi-scale feature fusion\n(MFF) block and one-class embedding (OCE) block, both jointly opti-\nmized with the student decoder. Notably, the former aggre- gates low-\nand high-level features to construct a rich embed- ding for normal\npattern reconstruction. The latter targets to retain essential\ninformation favorable for the student to de- code out the teacher’s\nresponse. We perform extensive experiments on public bench- marks. The\nexperimental results indicate that our re- verse distillation paradigm\nachieves comparable perfor- mance with prior arts. The proposed OCBE\nmodule further improves the performance to a new state-of-the-art (SOTA)\nrecord. Our main contributions are summarized as follows:\n\nWe introduce a simple, yet effective Reverse Distilla- tion\nparadigm for anomaly detection. The encoder- decoder structure and\nreverse knowledge distillation strategy holistically address the\nnon-distinguishing fil- ter problem in conventional KD models, boosting\nthe T-S model’s discrimination capability on anomalies.\nWe propose a one-class bottleneck embedding mod- ule to project\nthe teacher’s high-dimensional features to a compact one-class embedding\nspace. This inno- vation facilitates retaining rich yet compact codes\nfor anomaly-free representation restoration at the student.\nWe perform extensive experiments and show that our approach\nachieves new SOTA performance.\n\n\n\n\n\n\n\n\n\n\n此外，由于瓶颈嵌入的紧凑性对于异常检测至关重要（如上所述），我们引入了一类瓶颈嵌入（OCBE）模块来进一步压缩特征代码。\n我们的 OCBE 模块由多尺度特征融合 (MFF) 块和一类嵌入 (OCE)\n块组成，两者都与学生解码器联合优化。\n值得注意的是，前者聚合了低级和高级特征以构建用于正常模式重建的丰富嵌入。\n后者的目标是保留有利于学生解码教师反应的基本信息。\n我们在公共基准上进行了广泛的实验。\n实验结果表明，我们的反向蒸馏范式实现了与现有技术相当的性能。 所提出的\nOCBE 模块进一步将性能提高到新的最先进 (SOTA) 记录。\n我们的主要贡献总结如下：\n\n我们为异常检测引入了一种简单而有效的逆向蒸馏范式。\n编码器-解码器结构和反向知识蒸馏策略整体解决了传统 KD\n模型中的非区分过滤器问题，提高了 T-S 模型对异常的判别能力。\n\n我们提出了一类瓶颈嵌入模块，将教师的高维特征投影到紧凑的一类嵌入空间。\n这项创新有助于保留丰富而紧凑的代码，以便在学生处进行无异常表示恢复。\n我们进行了广泛的实验并表明我们的方法实现了新的 SOTA 性能。\n\n\n2. Related Work\nThis section briefly reviews previous efforts on unsuper- vised\nanomaly detection. We will highlight the similarity and difference\nbetween the proposed method and prior arts. Classical anomaly detection\nmethods focus on defining a compact closed one-class distribution using\nnormal sup- port vectors. The pioneer studies include one-class support\nvector machine (OC-SVM) [35] and support vector data description (SVDD)\n[36]. To cope with high-dimensional data, DeepSVDD [31] and PatchSVDD\n[43] estimate data representations through deep networks. Another\nunsupervised AD prototype is the use of gener- ative models, such as\nAutoEncoder (AE) [19] and Genera- tive Adversarial Nets (GAN) [12], for\nsample reconstruc- tion. These methods rely on the hypothesis that\ngenera- tive models trained on normal samples only can success- fully\nreconstruct anomaly-free regions, but fail for anoma- lous regions [2,\n5, 34]. However, recent studies show that deep models generalize so well\nthat even anomalous re- gions can be well-restored [46]. To address this\nissue, memory mechanism [11, 16, 26] , image masking strat- egy [42, 46]\nand pseudo-anomaly [28, 45] are incorporated in reconstruction-based\nmethods. However, these meth- ods still lack a strong discriminating\nability for real-world anomaly detection [3, 5]. Recently, Metaformer\n(MF) [40] proposes the use of meta-learning [9] to bridge model adap-\ntation and reconstruction gap for reconstruction-based ap- proaches.\nNotably, the proposed reverse knowledge distil- lation also adopts the\nencoder-decoder architecture, but it differs from construction-based\nmethods in two-folds. First, the encoder in a generative model is\njointly trained with the decoder, while our reverse distillation freezes\na pre-trained model as the teacher. Second, instead of pixel-level\nrecon- struction error, it performs anomaly detection on the seman- tic\nfeature space.\n\n\n\n\n\n\n\n\n\n本节简要回顾了以前在无监督异常检测方面的努力。\n我们将强调所提出的方法与现有技术之间的相似之处和不同之处。\n经典的异常检测方法侧重于使用正态支持向量定义紧凑的封闭一类分布。\n先驱研究包括一类支持向量机（OC-SVM）[35]和支持向量数据描述（SVDD）[36]。\n为了处理高维数据，DeepSVDD [31] 和 PatchSVDD [43]\n通过深度网络估计数据表示。 另一个无监督的 AD\n原型是使用生成模型，例如自动编码器 (AE) [19] 和生成对抗网络 (GAN)\n[12]，用于样本重建。\n这些方法依赖于这样一个假设，即在正常样本上训练的生成模型只能成功地重建无异常区域，但对于异常区域则失败\n[2, 5, 34]。\n然而，最近的研究表明，深度模型的泛化能力非常好，即使是异常区域也可以很好地恢复\n[46]。\n为了解决这个问题，记忆机制[11、16、26]、图像掩蔽策略[42、46]和伪异常[28、45]被纳入基于重建的方法中。\n然而，这些方法对于现实世界的异常检测仍然缺乏很强的辨别能力[3, 5]。\n最近，Metaformer (MF) [40] 提出使用元学习 [9]\n来弥合基于重建的方法的模型适应和重建差距。\n值得注意的是，所提出的反向知识蒸馏也采用了编码器-解码器架构，但它与基于构造的方法有两方面的不同。\n首先，生成模型中的编码器与解码器联合训练，而我们的逆向蒸馏将预先训练的模型冻结为教师。\n其次，它不是像素级的重建错误，而是对语义特征空间进行异常检测。\nData augmentation strategy is also widely used. By adding pseudo\nanomalies in the provided anomaly-free samples, the unsupervised task is\nconverted to a supervised learning task [23, 42, 46]. However, these\napproaches are prone to bias towards pseudo outliers and fail to detect\na large variety of anomaly types. For example, CutPaste [23] generates\npseudo outliers by adding small patches onto nor- mal images and trains\na model to detect these anomalous regions. Since the model focuses on\ndetecting local fea- tures such as edge discontinuity and texture\nperturbations, it fails to detect and localize large defects and global\nstruc- tural anomalies as shown in Fig. 6. Recently, networks\npre-trained on the large dataset are proven to be capable of extracting\ndiscriminative features for anomaly detection [7,8,23,25,29,30]. With a\npre-trained model, memorizing its anomaly-free features helps to iden-\ntify anomalous samples [7, 29]. The studies in [8, 30] show that using\nthe Mahalanobis distance to measure the simi- larity between anomalies\nand anomaly-free features leads to accurate anomaly detection. Since\nthese methods re- quire memorizing all features from training samples,\nthey are computationally expensive. Knowledge distillation from\npre-trained models is an- other potential solution to anomaly detection.\nIn the con- text of unsupervised AD, since the student model is ex-\nposed to anomaly-free samples in knowledge distillation, the T-S model\nis expected to generate discrepant features on anomalies in inference\n[4,33,39]. To further increase the discrimnating capability of the T-S\nmodel on various types of abnormalities, different strategies are\nintroduced. For in- stance, in order to capture multi-scale anomaly, US\n[4] en- sembles several models trained on normal data at different\nscales, and MKD [33] propose to use multi-level features alignment. It\nshould be noted that though the proposed method is also based on\nknowledge distillation, our reverse distillation is the first to adopt\nan encoder and a decoder to construct the T-S model. The heterogeneity\nof the teacher and student networks and reverse data flow in knowledge\ndistillation distinguishes our method from prior arts.\n\n\n\n\n\n\n\n\n\n数据增强策略也被广泛使用。\n通过在提供的无异常样本中添加伪异常，将无监督任务转换为监督学习任务\n[23,42,46]。\n然而，这些方法容易偏向伪异常值，并且无法检测到多种异常类型。\n例如，CutPaste [23]\n通过在正常图像上添加小块来生成伪异常值，并训练模型来检测这些异常区域。\n由于该模型侧重于检测局部特征，例如边缘不连续性和纹理扰动，因此无法检测和定位大缺陷和全局结构异常，如图\n6 所示。\n最近，在大型数据集上预训练的网络被证明能够提取用于异常检测的判别特征\n[7,8,23,25,29,30]。 使用预训练模型，记住其无异常特征有助于识别异常样本\n[7, 29]。 [8, 30]\n中的研究表明，使用马氏距离来测量异常和无异常特征之间的相似性可以实现准确的异常检测。\n由于这些方法需要记住训练样本的所有特征，因此它们的计算成本很高。\n来自预训练模型的知识蒸馏是异常检测的另一个潜在解决方案。 在无监督 AD\n的背景下，由于学生模型在知识蒸馏中暴露于无异常样本，因此 T-S\n模型预计会在推理异常上产生差异特征 [4,33,39]。 为了进一步提高 T-S\n模型对各类异常的判别能力，引入了不同的策略。\n例如，为了捕获多尺度异常，US [4]\n集成了几个在不同尺度的正常数据上训练的模型，MKD [33]\n建议使用多级特征对齐。\n需要注意的是，虽然所提出的方法也是基于知识蒸馏的，但我们的逆向蒸馏是第一个采用编码器和解码器来构建\nT-S 模型的方法。\n教师和学生网络的异质性以及知识蒸馏中的反向数据流将我们的方法与现有技术区分开来。\n","slug":"一类嵌入反向蒸馏","date":"2022-05-04T03:30:00.000Z","categories_index":"","tags_index":"深度学习,异常分割","author_index":"Star"},{"id":"4346091fabb18c4f718acfd51c087897","title":"Pytorch & python","content":"pytorch\n参数 &amp; 命令行 &amp; 辅助\nlogger\nlogger模块解释\n—— CSDN logger使用案例\nlogging模块是Python内置的标准模块，主要用于输出运行日志，可以设置输出日志的等级、日志保存路径、日志文件回滚等\nyacs.config\nyacs使用 ——\n知乎\nyacs库，用于为一个系统构建config文件\n需要创建CN()这个作为容器来装载我们的参数，这个容器可以嵌套\n设备相关\ntorch.cuda.synchronize()\n等待当前设备上所有流中的所有核心完成。\n🌰：测试时间的代码\n# code 1\nstart = time.time()\nresult = model(input)\nend = time.time()\n\n# code 2\ntorch.cuda.synchronize()\nstart = time.time()\nresult = model(input)\ntorch.cuda.synchronize()\nend = time.time()\n\n# code 3\nstart = time.time()\nresult = model(input)\nprint(result)\nend = time.time()\n代码2是正确的。因为在pytorch里面，程序的执行都是异步的。\n如果采用代码1，测试的时间会很短，因为执行完end=time.time()程序就退出了，后台的cu也因为python的退出退出了。\n如果采用代码2，代码会同步cu的操作，等待gpu上的操作都完成了再继续成形end\n= time.time()\n代码3和代码2的时间是类似的。\n因为代码3会等待gpu上的结果执行完传给print函数，所以时间就和代码2同步的操作的时间基本上是一致的了。\n将print(result)换成result.cpu()结果是一致的。\n数据加载\n图像数据变换\ntransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224,\n0.225])\nNormalize是把图像数据从[0,1]变成[-1,1]，变换公式是image=(image-mean)/std，那么其中的参数就分别是三个通道的mean和std，这个均值和标准差需要自己计算，范围就是训练集和验证集的所有图像。\nDataLoader\nCSDN原文链接\ncollate_fn参数使用详解\n—— 知乎 num_works参数\n—— CSDN\n\n加载一个batch的数据这一步需要使用一个torch.utils.data.DataLoader对象，并且DataLoader是一个基于某个dataset的iterable，这个iterable每次从dataset中基于某种采样原则取出一个batch的数据。\n也可以这样说：Torch中可以创建一个torch.utils.data.==Dataset==对象，并与torch.utils.data.==DataLoader==一起使用，在训练模型时不断为模型提供数据。\ntorch.utils.data.DataLoader\n定义：Data loader. Combines a dataset and a sampler, and provides an\niterable over the given dataset. 构造函数: torch.utils.data.DataLoader(dataset, \n\t\t\t\t\t\t\tbatch_size=1, \n\t\t\t\t\t\t\tshuffle=False, \n\t\t\t\t\t\t\tsampler=None,\n\t\t\t\t\t\t\tbatch_sampler=None, num_workers=0, collate_fn=None,\n\t\t\t\t\t\t\tpin_memory=False, drop_last=False, timeout=0,\n\t\t\t\t\t\t\tworker_init_fn=None) - dataset:\n抽象类,包含两种类型 - map-style datasets -\niterable-style datasets - batch_size :\n每一次抽样的batch-size大小 - shuffle : True则随机打乱数据 -\nNum_works：将batch加载进RAM的进程数。内存开销大，CPU负担大。可能之后几次迭代的数据在本次迭代的时候已经加载进内存。\n-\ncollate_fn：如何取样本的，我们可以定义自己的函数来准确地实现想要的功能。\n-\ndrop_last：告诉如何处理数据集长度除于batch_size余下的数据。True就抛弃，否则保留。\nMap-style datasets\n是一个类，要求有\n__getitem__()and__len__()这两个构造函数，代表一个从索引映射到数据样本。\n- __getitem__(): 根据索引index遍历数据 -\n__len__(): 返回数据集的长度 - 可编写独立的数据处理函数 - 在\n__getitem()__ 函数中进行调用 - 直接将数据处理函数写在\n__getitem()__ 或者 __init()__\n函数中，但是__getitem()__\n必须根据==index==返回响应的值，该值会通过index传到dataloader中进行后续的batch批处理。\n基本需要满足： def __getitem__(self, index):\n    return self.src[index], self.trg[index]\n\ndef __len__(self):\n\treturn len(self.src)  \ngetitem()方法用来从datasets中读取一条数据，这条数据包含训练图片（已CV距离）和标签，参数index表示图片和标签在总数据集中的Index。\nlen()方法返回数据集的总长度（训练集的总数）。\n实现 MyDatasets 类\n\n简单直白\n\n把 x 和 label 分别装入两个列表 self.src 和 self.trg ，然后通过\ngetitem(self, idex) 返回对应元素 import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n \nclass My_dataset(Dataset):\n    def __init__(self):\n        super().__init__()\n        ## 使用sin函数返回10000个时间序列,如果不自己构造数据，就使用numpy,pandas等读取自己的数据为x即可。\n        ## 以下数据组织这块既可以放在init方法里，也可以放在getitem方法里\n        self.x = torch.randn(1000,3)\n        self.y = self.x.sum(axis=1)\n        self.src,  self.trg = [], []\n        for i in range(1000):\n            self.src.append(self.x[i])\n            self.trg.append(self.y[i])\n    \n           \n    def __getitem__(self, index):\n        return self.src[index], self.trg[index]\n\n    def __len__(self):\n        return len(self.src) \n        \n ## 或者return len(self.trg), src和trg长度一样\n \ndata_train = My_dataset()\ndata_test = My_dataset()\ndata_loader_train = DataLoader(data_train, batch_size=5, shuffle=False)\ndata_loader_test = DataLoader(data_test, batch_size=5, shuffle=False)\n## i_batch的多少根据batch size和def __len__(self)返回的长度确定\n## batch_data返回的值根据def __getitem__(self, index)来确定\n## 对训练集：(不太清楚enumerate返回什么的时候就多print试试)\nfor i_batch, batch_data in enumerate(data_loader_train):\n    print(i_batch)  ## 打印batch编号\n    print(batch_data[0])  ## 打印该batch里面src\n    print(batch_data[1])  ## 打印该batch里面trg\n## 对测试集：（下面的语句也可以）\nfor i_batch, (src, trg) in enumerate(data_loader_test):\n    print(i_batch)  ## 打印batch编号\n    print(src)  ## 打印该batch里面src的尺寸\n    print(trg)  ## 打印该batch里面trg的尺寸    \n生成的data_train可以通过\ndata_train[xxx]直接索引某个元素，或者通过next(iter(data_train))\n得到一条条的数据。\n\n借助TensorDataset将数据包装成dataset\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n \nsrc = torch.sin(torch.arange(1, 1000, 0.1))\ntrg = torch.cos(torch.arange(1, 1000, 0.1))\n \ndata = TensorDataset(src, trg)\ndata_loader = DataLoader(data, batch_size=5, shuffle=False)\nfor i_batch, batch_data in enumerate(data_loader):\n    print(i_batch)  ## 打印batch编号\n    print(batch_data[0].size())  ## 打印该batch里面src\n    print(batch_data[1].size())  ## 打印该batch里面trg\n\n地址读取，生成数据的路径 txt文件\n\nimport os\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport matplotlib.image as mpimg\n\n\n\n## 对所有图片生成path-label map.txt 这个程序可根据实际需要适当修改\ndef generate_map(root_dir):\n\t##得到当前绝对路径\n    current_path = os.path.abspath('.')\n    ##os.path.dirname()向前退一个路径\n    father_path = os.path.abspath(os.path.dirname(current_path) + os.path.sep + \".\")\n\n    with open(root_dir + 'map.txt', 'w') as wfp:\n        for idx in range(10):\n            subdir = os.path.join(root_dir, '%d/' % idx)\n            for file_name in os.listdir(subdir):\n                abs_name = os.path.join(father_path, subdir, file_name)\n                ## linux_abs_name = abs_name.replace(\"\\\\\", '/')\n                wfp.write('&#123;file_dir&#125; &#123;label&#125;\\n'.format(file_dir=linux_abs_name, label=idx))\n\n## 实现MyDatasets类\nclass MyDatasets(Dataset):\n\n    def __init__(self, dir):\n        ## 获取数据存放的dir\n        ## 例如d:/images/\n        self.data_dir = dir\n        ## 用于存放(image,label) tuple的list,存放的数据例如(d:/image/1.png,4)\n        self.image_target_list = []\n        ## 从dir--label的map文件中将所有的tuple对读取到image_target_list中\n        ## map.txt中全部存放的是d:/.../image_data/1/3.jpg 1 路径最好是绝对路径\n        with open(os.path.join(dir, 'map.txt'), 'r') as fp:\n            content = fp.readlines()\n            ##s.rstrip()删除字符串末尾指定字符（默认是字符）\n            ## 得到 [['d:/.../image_data/1/3.jpg', '1'], ...,]\n            str_list = [s.rstrip().split() for s in content]\n            ## 将所有图片的dir--label对都放入列表，如果要执行多个epoch，可以在这里多复制几遍，然后统一shuffle比较好\n            self.image_target_list = [(x[0], int(x[1])) for x in str_list]\n\n    def __getitem__(self, index):\n        image_label_pair = self.image_target_list[index]\n        ## 按path读取图片数据，并转换为图片格式例如[3,32,32]\n        ## 可以用别的代替\n        img = mpimg.imread(image_label_pair[0])\n        return img, image_label_pair[1]\n\n    def __len__(self):\n        return len(self.image_target_list)\n\n\nif __name__ == '__main__':\n    ## 生成map.txt\n    ## generate_map('train/')\n\n    train_loader = DataLoader(MyDatasets('train/'), batch_size=128, shuffle=True)\n\n    for step in range(20000):\n        for idx, (img, label) in enumerate(train_loader):\n            print(img.shape)\n            print(label.shape)\n网络搭建Trick\nwith torch.no_grad()\n\n\n\n\n\n\n\n\n\n参考：https://blog.csdn.net/sazass/article/details/116668755\n作用：在该模块下，所有计算得出的tensor的requires_grad都自动设置为False。当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存。\n基本功能函数\ntorch.max()\ntorch.max(input) → Tensor:返回输入tensor中所有元素的最大值\ntorch.max(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor):\n按维度dim 返回最大值，并且返回索引。\ntorch.max()[0]， 只返回最大值的每个数\n\ntroch.max()[1]， 只返回最大值的每个索引\n\ntorch.max()[1].data 只返回variable中的数据部分（去掉Variable containing:）\n\ntorch.max()[1].data.numpy() 把数据转化成numpy ndarry\n\ntorch.max()[1].data.numpy().squeeze() 把数据条目中维度为1 的删除掉\npython\nstr.lower() 全部转化为小写字母\n","slug":"python&pytorch使用指南","date":"2022-05-03T12:10:00.000Z","categories_index":"","tags_index":"","author_index":"Star"},{"id":"cca6975b74b1218e11c5b9ba5de4d5ef","title":"DMLNet","content":"\n开放世界语义分割\n\n开集语义分割模块\n\n闭集语义分割子模块\n\n异常分割子模块\n\n增量小样本学习模块\n\n我是短小精悍的文章摘要(๑•̀ㅂ•́) ✧\n\nCODE\nmultiscale 是自己设定的吗\ncfg.DATASET.imgSizes = (300, 375, 450, 525, 600)\nSeg 转化为long Tensor的目的是什么\ncolors的作用是什么\n几个辅助函数的作用：\nNormalization(x): \\(\\dfrac{x -\nmin(x)}{max(x) - min(x)}\\)\nCoefficient_map(x, thre): \\(\\dfrac{1}{1 + exp(50*(x - thre))}\\)\nnormfun(x, mu, sigma):\\(\\dfrac{exp(-\\frac{(x - mu)^2}{2 *\n\\sigma^2})}{\\sigma * \\sqrt{2*\\pi}}\\)\n论文阅读\n引言\nClassical close-set semantic segmentation networks have limited\nability to detect out-of-distribution (OOD) objects, which is important\nfor safety-critical applications such as autonomous driving.\nIncrementally learning these OOD objects with few annotations is an\nideal way to enlarge the knowledge base of the deep learning models. In\nthis paper, we propose an open world semantic segmenta- tion system that\nincludes two modules:\n\n==an open-set semantic segmentation module to detect both\nin-distribution and OOD objects==.\nan incremental few-shot learning module to gradually incorporate\nthose OOD objects into its existing knowledge base.\n\nThis open world semantic segmentation system behaves like a human\nbeing, which is able to identify OOD objects and gradually learn them\nwith corresponding supervision.\nWe adopt the ==Deep Metric Learning Network (DMLNet) with contrastive\nclustering== to implement open-set semantic segmentation. Compared to\nother open-set semantic segmentation methods, our DMLNet achieves\nstate-of-the-art performance on three challenging open-set semantic\nsegmentation datasets without using additional data or generative\nmodels.\nOn this basis, two incremental few-shot learning methods are fur-\nther proposed to progressively improve the DMLNet with the annotations\nof OOD objects\n\n经典的闭集语义分割网络检测分布外 (OOD)\n对象的能力有限，这对于自动驾驶等安全关键型应用很重要。\n增量学习这些带有少量注释的 OOD 对象是扩大深度学习模型知识库的理想方法。\n在本文中，我们提出了一个开放世界语义分割系统，包括两个模块：\n\n一个开放集语义分割模块，用于检测内分布和OOD对象。\n\n(2) 一个增量的小样本学习模块，逐渐将这些 OOD\n对象纳入其现有的知识库。\n这个开放世界的语义分割系统就像一个人，能够识别OOD对象并在相应的监督下逐渐学习它们。\n我们采用具有==对比聚类的深度度量学习网络（DMLNet）==来实现开放集语义分割。\n与其他开放集语义分割方法相比，我们的 DMLNet\n在三个具有挑战性的开放集语义分割数据集上实现了最先进的性能，而无需使用额外的数据或生成模型。\n在此基础上，进一步提出了两种增量少样本学习方法，通过 OOD\n对象的注释逐步改进 DMLNet\n6. Conclusion\nWe introduce an open world semantic segmentation system which\nincorporates two modules:\n\nan open-set segmentation module\nan incremental few-shot learning module.\n\nOur proposed open-set segmentation module is based on the\ndeep metric learning network, and it uses the\nEuclidean distance sum criterion to achieve\nstate-of-the-art performance.\nTwo incremental few-shot learning methods are proposed to broaden the\nperception knowledge of the network. Both modules of the open world\nsemantic segmentation system can be further studied to improve the\nperformance. We hope our work can draw more researchers to contribute to\nthis practically valuable research direction.\n\n我们介绍了一个开放世界语义分割系统，它包含两个模块：一个开放集分割模块和一个增量小样本学习模块。\n我们提出的开放集分割模块基于深度度量学习网络，它使用==欧几里德距离和标准==来实现最先进的性能。\n提出了两种增量少样本学习方法来拓宽网络的感知知识。\n开放世界语义分割系统的两个模块都可以进一步研究以提高性能。\n我们希望我们的工作能够吸引更多的研究人员为这个具有实际价值的研究方向做出贡献\n1. 介绍\n得益于高质量的数据集 [3,4,5]，深度卷积网络在语义分割任务 [1, 2]\n中取得了巨大成功。\n这些语义分割网络在许多应用中被用作感知系统，如自动驾驶[6]、医疗诊断[7]等。然而，这些感知系统中的大多数都是闭集和静态的。\n闭集语义分割假设测试中的所有类都已经在训练期间参与，这在开放世界中是不正确的。\n如果闭集系统错误地将分发中标签分配给 OOD 对象\n[8]，它可能会在安全关键型应用程序（如自动驾驶）中造成灾难性后果。\n同时，静态感知系统无法根据所见内容更新其知识库，因此，它仅限于特定场景，需要在一定时间后重新训练。\n为了解决这些问题，我们提出了一种开放集的动态感知系统，称为开放世界语义分割系统。\n它包含两个模块：\n（1）一个开放集语义分割模块，用于检测OOD对象并将正确的标签分配给分布中的对象。\n\n一个增量的小样本学习模块，将这些未知对象逐步合并到其现有的知识库中。\n\n我们提出的开放世界语义分割系统的整个流程如图 1\n所示\n开放集语义分割和增量小样本学习都没有得到很好的解决。\n对于开集语义分割，最重要的部分是在一张图像的所有像素中识别OOD像素，称为异常分割。\n异常分割的典型方法是将图像级的开集分类方法应用于像素级的开集分类。\n这些方法包括基于不确定性估计的方法 [9, 10, 11, 12]\n和基于自动编码器的方法 [13, 14]。\n然而，这两种方法已被证明在驾驶场景中无效，因为基于不确定性估计的方法==会给出许多假阳性异常值检测==\n[15] 并且自动编码器==无法重新生成复杂的城市场景== [16]。\n最近，基于生成对抗网络（基于 GAN）的方法 [16, 17]\n已被证明是有效的，但它们远==非轻量级==，因为它们需要在管道中使用多个深度网络。\n对于增量少样本学习，我们不仅要处理增量学习的挑战，例如灾难性遗忘[18]，还要处理少样本学习的挑战，包括从少量样本中提取代表性特征[19]\n在本文中，我们建议使用 DMLNet 来解决开放世界语义分割问题。\n原因有三：\n\nDMLNet的分类原理是基于对比聚类，可以有效识别异常物体，如图2所示\n\n\n\n\n\n\n\n\n\n\n\n度量学习：从数据中学习一种度量数据对象间距离的方法。其目标是使得在学得的距离度量下，相似对象间的距离小，不相似对象间的距离大。\n传统的度量学习方法只能学习出线性特征，虽然有一些能够提取非线性特征的核方法被提出，但对学习效果也没有明显提升\n深度度量学习：深度学习的激活函数学习非线性特征的优秀能力，深度学习方法能够自动地从原始数据中学出高质量的特征。因此深度学习的网络结构与传统的度量学习方法相结合能够带来理想的效果。\n(2) DMLNet结合原型非常适合few-shot 任务[19]。\n(3) DMLNet\n的增量学习可以通过添加新的原型来实现，这是一种自然而有用的方法\n[20]。\n基于 DMLNet\n架构，我们为开放集语义分割模块开发了两种未知识别标准，为增量少样本学习模块开发了两种方法。\n根据我们的实验，这两个模块都被验证为有效且轻量级的。\n总而言之，我们的贡献如下：\n\n我们率先推出开放世界语义分割系统，在实际应用中更加稳健实用。\n我们提出的基于 DMLNet\n的开放集语义分割模块在三个具有挑战性的数据集上实现了最先进的性能。\n我们提出的few-shot\n增量学习模块方法在很大程度上缓解了灾难性遗忘问题。\n通过结合我们提出的开放集语义分割模块和增量少样本学习模块，实现了一个开放世界语义分割系统。\n\n2. Related Work\n2.1 异常语义分割\n异常语义分割的方法可以分为两种趋势：\n基于不确定性估计的方法和基于生成模型的方法。\n不确定性估计的基线是最大softmax概率（MSP），它首先在[9]中提出。 Dan\n等人没有使用 softmax 概率。\n[11]提出使用最大logit（MaxLogit）并取得更好的异常分割性能。\n贝叶斯网络采用深度学习网络的概率观点，所以它们的权重和输出是概率分布而不是特定的数字\n[21, 22]。 在实践中，Dropout [10] 或集成 [12]\n通常用于近似贝叶斯推理。\n自动编码器（AE）[23, 13] 和 RBM [14] 是典型的生成方法，假设 OOD\n图像的重建误差大于分布内图像\n最近，另一种基于 GAN\n再合成的生成模型被证明可以基于其可靠的高分辨率像素到像素转换结果实现最先进的性能。\nSynthCP [17] 和 DUIR [16] 是基于 GAN 再合成的两种方法。\n不幸的是，它们离轻量级还很远，因为必须依次使用两个或三个神经网络来进行\nOOD 检测。\n与它们相比，我们证明了基于对比聚类的 DMLNet\n具有更好的异常分割性能，而只需要推理一次\n2.2 深度度量学习网络\nDMLNets 已用于多种应用，包括视频理解 [24] 和人员重新识别 [25]。\nDMLNet 使用欧几里得、马氏距离或 Matusita 距离 [26]\n将此类问题转换为计算度量空间中的嵌入特征相似度。\n卷积原型网络和 DMLNets\n通常一起用于解决特定问题，例如检测图像级 OOD 样本 [27、28、29]\n和用于语义分割的小样本学习 [19、30、31]。\n我们也按照这种组合构建了第一个用于开放世界语义分割的 DMLNet\n2.3 开放世界分类和检测\n开放世界分类首先由 [32] 提出。这项工作提出了最近非异常值 (NNO)\n算法，该算法在增量添加对象类别、检测异常值和管理开放空间风险方面非常有效。\n最近约瑟夫等人。\n[33]提出了一种基于对比聚类、未知感知提议网络和基于能量的未知识别标准的开放世界对象检测系统。\n我们的开放世界语义分割系统的管道与他们的相似，除了两个重要的区别使我们的任务更具挑战性：（1）在他们的开放集检测模块中，他们依赖于区域提议网络（RPN）是\n类不可知，因此也可以检测到未标记的潜在 OOD 对象。\n这样，OOD样本的信息对于训练是有效的。\n但是，我们专注于语义分割，其中训练中使用的每个像素都被分配了一个分布内标签，因此不能将\nOOD 样本添加到训练中。 (2)\n在增量学习模块中，他们使用新类的所有标记数据，而我们专注于自然更困难的少样本条件。\n很少有研究集中在增量小样本学习上，其中包括用于分类的增量小样本学习[34]、对象检测[35]和语义分割[36]\n3. 开放世界语义分割\n在本节中，我们给出了开放世界语义分割系统的工作流程。\n该系统由一个开放集语义分割模块和一个增量小样本学习模块组成。 假设\\(\\mathcal{C}_{in} = \\{\\mathcal{C}_{in,1},\n\\mathcal{C}_{in,2},...,\\mathcal{C}_{in,N} \\}\\) 是 N\n个分布内的类，它们都在训练数据集中进行了注释，并且 \\(\\mathcal{C}_{out} =\n\\{\\mathcal{C}_{out,1},\\mathcal{C}_{out,2},...,\\mathcal{C}_{out,M}\n\\}\\) 是训练数据集中没有遇到的 M 个 OOD 类\n开集语义分割模块又分为两个子模块：闭集语义分割子模块和异常分割子模块。\n\n\\(\\hat{Y}^{close}\\)\n是闭集语义分割子模块的输出图，所以每个像素的类别 \\(\\hat{Y}^{close}_{i,j} ∈ C_{in}\\)。\n异常分割子模块的功能是识别OOD像素，其输出称为异常概率图：\\(\\hat{P} \\in [1,0]^{H \\times W}\\)，其中\n\\(H\\) 和 \\(W\\) 表示输入图像的高度和宽度。\n\n基于 \\(\\hat{Y}_{close}\\) 和 \\(\\hat{P}\\)，开集语义分割图 \\(\\hat{Y}^{open}\\) 给出为: \\[\n\\hat{Y}^{open}_{i,j} =\n\\begin{cases}\n\\mathcal{C}_{anomaly} \\quad \\     \\hat{P}_{i,j} &gt; \\lambda_{out} \\\\\n\\hat{Y}_{i,j}^{close} \\quad \\quad \\hat{P}_{i,j} \\le \\lambda_{out}\n\\end{cases} \\tag{1}\n\\] \\(\\mathcal{C}_{anomaly}\\)\n：表示 OOD 类别 \\(λ_{out}\\) ：确定 OOD\n像素的阈值。\n因此，openset语义分割模块应该识别OOD像素并分配正确的分布标签。然后\nYopen 可以转发给可以从 \\(C_{out}\\)\n中识别 \\(C_{anomaly}\\)\n并给出新类的相应注释的标注者\n增量少样本学习模块用于在有新标签时将近集分割子模块的知识库从 \\(C_{in}\\) 一个一个更新为 \\(C_{in+M}\\)，其中 \\(C_{in+t} = Cin \\cup\n\\{C_{out,1},C_{out,2},...,C_{out,t}\\},t ∈{1,2,...,M}\\)。\n图 1 显示了开放世界语义分割系统的循环工作流水线\n图 1. 开放世界语义分割系统。 第 1\n步：识别已知和未知对象（蓝色箭头）。 第 2 步：注释未知对象（红色箭头）。\n第 3 步：应用增量少样本学习来增加网络的分类范围（绿色箭头）。 第 4\n步：在增量少样本学习之后，DMLNet 可以在更大的域中输出结果（紫色箭头）。\n\n4. 方法\n我们采用 DMLNet 作为我们的特征提取器，并在 4.1 节讨论架构和损失函数。\n开放集分割模块和增量少样本学习模块在 4.2 和 4.3 节中进行了说明\n4.1 深度度量学习网络\n\n\n\n\n\n\n\n\n\nClassical CNN-based semantic segmentation networks can be\ndisentangled into two parts:\n\na feature extractor \\(f(X;θ_f)\\)\nfor obtaining the embedding vector of each pixel\na classifier \\(g(f(X;θ_f);θ_g)\\)\nfor generating the decision boundary,\n\nwhere \\(X\\), \\(θ_f\\) and \\(θ_g\\) denote the input\nimage, parameters of the feature extractor and\nclassifier respectively.\nThis learnable classifier is not suitable for OOD detection because\nit assigns all feature space to known classes and leaves no space for\nOOD classes.\n传统CNN-based语义分割网络：\n\n\\(f(X;\\theta_f)\\)\n特征提取器：获取每个像素的嵌入向量\n\\(g(f(X;\\theta_f);\\theta_g)\\)\n分类器：生成决策边界\n\n这种==可学习的分类器不适用于 OOD\n检测==，因为它将所有特征空间分配给已知类，并且没有为 OOD\n类留下空间。\n\n\n\n\n\n\n\n\n\nIn contrast, the classifier is replaced by the Euclidean distance\nrepresentation with all prototypes \\(\\mathcal{M}_{in} = \\{ m_t \\in \\mathbb{R}^{1 \\times\nN}|t \\in \\{1,2,...,N\\} \\}\\) in DMLNet, where \\(m_t\\) refers to the prototype of class\n\\(\\mathcal{C}_{in,t}\\). The feature\nextractor \\(f(X;θ_f)\\) learns to map\nthe input \\(X\\) to the feature vector\nwhich has the same length as the prototype in metric space. For the\nclose-set segmentation task, the probability of one pixel \\(X_{i,j}\\) belonging to the class \\(\\mathcal{C}_{in,t}\\) is formulated as:\nDMLNet 中, ==所有原型的欧几里得距离==表示代替了传统的可学习分类器\n\n\\(m_t\\) 指的是 \\(\\mathcal{C}_{in,t}\\) 类的原型。\n\n特征提取器 \\(f(X;θ_f)\\)学习将输入 X\n映射到与度量空间中的原型长度相同的特征向量。\n对于闭集分割任务，一个像素 \\(X_{i,j}\\) 属于类 \\(\\mathcal{C}_{in,t}\\) 的概率公式为： \\[\np_t(X_{i,j}) = \\frac{exp(-||f(X;\\theta_f)_{i,j} -\nm_t||^2)}{\\sum^N_{t&#39;=1} exp(-||f(X;\\theta_f)_{i,j} -\nm_{t&#39;}||^2)} \\tag{2}\n\\]\n基于这种基于欧几里德距离的概率，判别交叉熵 (DCE)\n损失函数 \\(\\mathcal{L}_{DCE}(X_{i,j},Y_{i,j};θ_f,M_{in})\\)\n[27] 定义为: \\[\n\\mathcal{L}_{DCE} = \\sum_{i,j} -log (\\frac{exp(-||f(X;\\theta_f)_{i,j} -\nm_{Y_{i,j}}||^2)}{\\sum^N_{k=1} exp(-||f(X;\\theta_f)_{i,j} - m_{k}||^2)}\n\\tag{3}\n\\]\n\\(Y\\)：输入图像 \\(X\\) 的标签 \\(\\mathcal{L}_{DCE}\\)\n的分子和分母分别指图2中的吸引力和排斥力。\n\n\n\n\n\n\n\n\n\n排斥力不需要除去本身所属的类，本身类的原型吗？\n图 2. DMLNet 的对比聚类。\n在推理过程中，已知对象将被同一类的原型所吸引，而被剩余的原型所排斥。\n最后，它们将围绕特定的原型进行聚合。\n相反，异常对象将被所有原型排斥，因此它们将聚集在度量空间的中间。\n\n我们制定了另一个损失函数，称为方差损失 (VL) 函数\n\\(\\mathcal{L}_{VL}(X_{i,j},Y_{i,j};θ_f,M_{in})\\)，其定义为：\n\\[\n\\mathcal{L}_{VL} = \\sum_{i,j} ||f(X;\\theta_f)_{i,j} - m_{Y_{i,j}}||^2\n\\tag{4}\n\\] \\(\\mathcal{L}_{VL}\\)\n只有吸引力作用，没有排斥力作用。\n使用 DCE 和 VL，混合损失定义为：\\(\\mathcal{L}= \\mathcal{L}_{DCE} +\nλ_{VL}\\mathcal{L}_{VL}\\)，其中 \\(λ_{VL}\\) 是权重参数\n4.2 开集语义分割模型\n开集语义分割模块由闭集语义分割子模块和异常分割子模块组成。\n开放集语义分割模块的流程如 图3 所示。\n图3.闭集分割子模块包含在蓝色虚线框内，异常分割子模块包含在红色虚线框内。\n开集分割图是这两个子模块生成的结果的组合。\n在开放集分割图中预测分布内类和 OOD 类。 EDS map 和 MMSP map 的定义请参考\n4.2 节。 \n\n闭集语义分割子模块为一幅图像的所有像素分配分布标签。\n由于一个像素 \\(X_{i,j}\\) 属于类 \\(\\mathcal{C}_{in,t}\\) 的概率是用公式 2\n表示，闭集分割图为： \\[\n\\hat{Y}_{i,j}^{close} = argmax_t \\ p_t(X_{i,j}) \\tag{5}\n\\]\n异常分割子模块检测OOD像素。\n我们提出了两个未知的识别标准来测量异常概率，包括_基于度量的最大softmax概率（MMSP）和_欧几里得距离和（EDS）。\n\n以下是基于 MMSP 的异常概率： \\[\n\\hat{P}^{MMSP}_{i,j} = 1 - max \\ p_t(X_{i,j}),\\ t \\in \\{ 1,2,3...,N \\}\n\\tag{6}\n\\]\nEDS 是根据以下发现提出的：如果特征位于 OOD\n像素聚集的度量空间的中心，则与所有原型的欧几里得距离和更小，即==异常的欧几里得距离较小==。\nEDS 定义为： \\[\nS(X_{i,j}) = \\sum_{t=1}^N ||f(X;\\theta_f)_{i,j} - m_t||^2 \\tag{7}\n\\] 基于 EDS 的异常概率计算如下： \\[\n\\hat{P}^{EDS}_{i,j} = 1- \\frac{S(X_{i,j})}{maxS(X)} \\tag{8}\n\\]\n\n\nEDS\n是类独立的，因此所有类的原型应该均匀分布在度量空间中，并且在训练期间不移动。\n==可学习的原型会在训练期间导致不稳定，并且对更好的性能没有贡献== [37]。\n因此，我们以 one-hot 向量形式定义原型：只有 \\(m_t\\) 的第 t 个元素是 \\(T\\)，而其他元素保持为零，其中 t ∈\n{1,2,...,N}\n\n\n\n\n\n\n\n\n\nPAnS是什么情况？\nEDS 是相对于所有像素之间的最大距离和的比率，即使图像中没有 OOD\n对象，高异常分数区域肯定存在于每幅图像中。\n此外，每个分布内类别的距离总和分布彼此略有不同，如图4所示。 \n将MMSP与EDS相结合，以抑制那些实际上处于分布状态的具有中间响应的像素。\n混合函数为： \\[\n\\hat{P} = \\alpha \\hat{P}^{EDS} + (1-\\alpha)\\hat{P}^{MMSP} \\tag{9}\n\\]\n\nα ： \\[\n\\alpha = \\frac{1}{1 + exp(-\\beta(\\hat{P}^{EDS} - \\gamma))} \\tag{10}\n\\]\n\nβ 和 γ 是控制抑制效果和阈值的超参数。\n\n\n通过方程 9 得到异常概率图和方程 5 得到闭集分割图后，我们应用方程 1\n生成最终的开集分割图\n5. 实验\nOur experiments are divided into three parts.\n\nWe first evaluate our open-set semantic segmentation approach in\nSection 5.1.\nThen we demonstrate our incremental few-shot learning results\nin Section 5.2.\nBased on the open-set semantic segmentation module and\nincremental few-show learning module, the whole open world semantic\nsegmentation is realized in Section 5.3.\n\n5.1 开集语义分割\n数据集。 三个数据集包括 StreetHazards [11]、Lost and\nFound [38] 和 Road Anomaly [16] 用于证明我们基于 DMLNet\n的开放集语义分割方法的稳健性和有效性。\n\nStreetHazards\n的大多数异常物体是大型稀有运输机器，例如直升机、飞机和拖拉机。\nLost and Found 含许多小的异常物品，如货物、玩具和盒子。\n\nRoad Anomaly\n数据集不再限制城市场景中的场景，还包含村庄和山脉的图像。\n\n指标。\n开放集语义分割是封闭集分割和异常分割的组合，如 4.2 节所述。\n\n对于闭集语义分割任务，我们使用 mIoU 来评估性能。\n对于异常分割任务，根据 [11] 使用三个指标，包括 ROC\n曲线下面积（AUROC）、95%\n召回的误报率（FPR95）和精确召回曲线下面积（AUPR）。\n\n实施细节。\n\n对于 StreetHazards，我们遵循与 [11] 相同的训练程序，在\nStreetHazards 的训练集上训练 PSPNet [2]。\n\n\n\n\n\n\n\n\n\n[11]: Scaling out-of-distribution detection for real-world\nsettings.\n对于Lost and Found和 Road Anomaly，我们按照 [16] 使用 BDD-100k\n[39] 来训练 PSPNet。 请注意，PSPNet 仅用于提取我们在 4.1\n节中讨论的特征（获得每个像素的嵌入向量）。 混合损失的 \\(λ_{VL}\\) 为 0.01。 所有原型中非零元素 \\(T\\) 为 3。等式 10 中的 β 和 γ 分别为 20 和\n0.8。\n\n\n\n\n\n\n\n\n\n[16]: Detecting the unexpected via image resynthesis\n\n基线。\n\nStreetHazards: MSP [9]、Dropout [10]、AE [13]、MaxLogit [11] 和\nSynthCP [17]。\nLost and Found 和 Road Anomaly: MSP、MaxLogit、Ensemble [12]、RBM\n[14] 和 DUIR [16]。\n\n结果。\nStreetHazards 的结果如表 1 所示。 \n对于 Lost and Found 和 Road Anomaly，mIoU 是无效的，因为它们只提供\nOOD 类标签，但没有特定的分布内类标签。 结果在表 2 中。 \n我们的实验表明：\n\n基于 DMLNet\n的方法在所有三个异常分割相关指标中都达到了最先进的性能。\n与最近提出的基于 GAN 的方法（包括 DUIR 和\nSynthCP）相比，我们的方法在异常分割质量方面优于它们，结构更轻量级，因为它们在整个流程中需要两个或三个深度神经网络，而我们只需要推理一次。\n\nStreetHazards 中闭集分割的 mIoU\n值表明我们的方法对闭集分割没有危害。\n\n一些定性结果如图 8 所示\n\n消融研究。\n我们仔细进行了消融实验，研究了不同损失函数（VL 和\nDCE）和异常判断标准（EDS 和 MMSP）的影响，如表 3 所示。 \n\nDCE 在 mIoU 上的性能优于 VL 的事实表明了 排斥力。\n\nEDS 在所有损失下都优于 MMSP\n函数，这意味着==与类无关的标准更适合于异常分割任务==\n\n","slug":"DMLNet","date":"2022-05-03T12:07:00.000Z","categories_index":"","tags_index":"深度学习,异常分割,度量学习","author_index":"Star"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very\nfirst post. Check documentation for\nmore info. If you get any problems when using Hexo, you can find the\nanswer in troubleshooting or\nyou can ask me on GitHub.\n\nQuick Start\nCreate a new post\n$ hexo new \"My New Post\"\nMore info: Writing\nRun server\n$ hexo server\nMore info: Server\nGenerate static files\n$ hexo generate\nMore info: Generating\nDeploy to remote sites\n$ hexo deploy\nMore info: Deployment\n","slug":"hello-world","date":"2022-05-03T10:31:15.256Z","categories_index":"","tags_index":"","author_index":"Star"}]