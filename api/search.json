[{"id":"082602022df518a2faf6c62dcd303051","title":"ä¸€ç±»åµŒå…¥çš„åå‘è’¸é¦","content":"Anomaly\nDetection via Reverse Distillation from One-Class Embedding\né€šè¿‡ä¸€ç±»åµŒå…¥çš„åå‘è’¸é¦è¿›è¡Œå¼‚å¸¸æ£€æµ‹\n\nAbstract\nKnowledge distillation (KD) achieves promising results on the\nchallenging problem of unsupervised anomaly detection (AD). The\nrepresentation discrepancy of anomalies in the teacher-student (T-S)\nmodel provides essential evidence for AD.\nHowever, using similar or identical architectures to build the\nteacher and student models in previous stud- ies hinders the diversity\nof anomalous representations. To tackle this problem, we propose a novel\nT-S model consisting of a teacher encoder and a student decoder and\nintroduce a simple yet effective â€œreverse distillationâ€\nparadigm accordingly.\nInstead of receiving raw images directly, the student network takes\nteacher modelâ€™s one-class embedding as input and targets to restore the\nteacherâ€™s multi-scale representations.\nInherently, knowledge distillation in this study starts from\nabstract, high-level presentations to low-level features.\nIn addition, we introduce a trainable one-class bottleneck\nembedding (OCBE) module in our T-S model.\nThe obtained compact embedding effectively preserves essential\ninformation on normal patterns, but abandons anomaly perturbations.\nExtensive experimentation on AD and one-class novelty detection\nbenchmarks shows that our method surpasses SOTA performance,\ndemonstrating our proposed approachâ€™s effectiveness and\ngeneralizability.\n\nçŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰åœ¨æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰çš„æŒ‘æˆ˜æ€§é—®é¢˜ä¸Šå–å¾—äº†å¯å–œçš„æˆæœã€‚\nå¸ˆç”Ÿï¼ˆT-Sï¼‰æ¨¡å‹ä¸­å¼‚å¸¸çš„è¡¨ç¤ºå·®å¼‚ä¸ºADæä¾›äº†å¿…è¦çš„è¯æ®ã€‚\nç„¶è€Œï¼Œåœ¨ä»¥å‰çš„ç ”ç©¶ä¸­ä½¿ç”¨ç›¸ä¼¼æˆ–ç›¸åŒçš„æ¶æ„æ¥æ„å»ºæ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹é˜»ç¢äº†å¼‚å¸¸è¡¨ç¤ºçš„å¤šæ ·æ€§ã€‚\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”±æ•™å¸ˆç¼–ç å™¨å’Œå­¦ç”Ÿè§£ç å™¨ç»„æˆçš„æ–°å‹ T-S\næ¨¡å‹ï¼Œå¹¶ç›¸åº”åœ°å¼•å…¥äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„â€œé€†å‘è’¸é¦â€èŒƒå¼ã€‚\nå­¦ç”Ÿç½‘ç»œä¸æ˜¯ç›´æ¥æ¥æ”¶åŸå§‹å›¾åƒï¼Œè€Œæ˜¯å°†æ•™å¸ˆæ¨¡å‹çš„ä¸€ç±»åµŒå…¥ä½œä¸ºè¾“å…¥å’Œç›®æ ‡ï¼Œä»¥æ¢å¤æ•™å¸ˆçš„å¤šå°ºåº¦è¡¨ç¤ºã€‚\næœ¬è´¨ä¸Šï¼Œæœ¬ç ”ç©¶ä¸­çš„çŸ¥è¯†è’¸é¦ä»æŠ½è±¡çš„é«˜çº§è¡¨ç¤ºå¼€å§‹åˆ°ä½çº§ç‰¹å¾ã€‚\næ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ T-S æ¨¡å‹ä¸­å¼•å…¥äº†å¯è®­ç»ƒçš„ä¸€ç±»ç“¶é¢ˆåµŒå…¥ (OCBE) æ¨¡å—ã€‚\nè·å¾—çš„ç´§å‡‘åµŒå…¥æœ‰æ•ˆåœ°ä¿ç•™äº†æ­£å¸¸æ¨¡å¼çš„åŸºæœ¬ä¿¡æ¯ï¼Œä½†æ”¾å¼ƒäº†å¼‚å¸¸æ‰°åŠ¨ã€‚\nå¯¹ AD å’Œä¸€ç±»æ–°é¢–æ€§æ£€æµ‹åŸºå‡†çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¶…è¶Šäº† SOTA\næ€§èƒ½ï¼Œè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ™®éæ€§ã€‚\n1. Introduction\nAnomaly detection (AD) refers to identifying and localizing\nanomalies with limited, even no, prior knowledge of\nabnormality.\nThe wide applications of AD, such as indus- trial defect detection\n[3], medical out-of-distribution detection [50], and video surveillance\n[24], makes it a critical task as well as a spotlight. In the context of\nunsupervised AD, no prior information on anomalies is\navailable. Instead, a set of normal samples is provided for\nreference.\nTo tackle this problem, previous efforts attempt to construct various\nself-supervision tasks on those anomaly-free samples. These tasks\ninclude, but not limited to, sample reconstruction [2, 5, 11, 16, 26,\n34, 38, 48], pseudo-outlier augmentation [23, 42, 46], knowledge\ndistillation [4, 33, 39], etc.\nIn this study, we tackle the problem of unsupervised anomaly\ndetection from the knowledge distillation-based point of view.\nIn knowledge distillation (KD) [6, 15], knowledge is\ntransferred within a teacher-student (T-S) pair. In the context of\nunsupervised AD, since the student experiences only normal samples\nduring training, it is likely to generate discrepant representations\nfrom the teacher when a query is anomalous. This hypothesis forms the\nbasis of KD-based methods for anomaly detection.\nHowever, this hypothesis is not always true in practice due to\n\nthe identical or similar architectures of the teacher and student\nnetworks (i.e., non-distinguishing filters [33])\nthe same data flow in the T-S model during knowledge trans-\nfer/distillation.\n\nThough the use of a smaller student network partially addresses this\nissue [33, 39], the weaker represen- tation capability of shallow\narchitectures hinders the model from precisely detecting and localizing\nanomalies.\n\nå¼‚å¸¸æ£€æµ‹ (AD)\næ˜¯æŒ‡åœ¨å¯¹å¼‚å¸¸çš„å…ˆéªŒçŸ¥è¯†æœ‰é™ç”šè‡³æ²¡æœ‰çš„æƒ…å†µä¸‹è¯†åˆ«å’Œå®šä½å¼‚å¸¸ã€‚\nAD çš„å¹¿æ³›åº”ç”¨ï¼Œå¦‚å·¥ä¸šç¼ºé™·æ£€æµ‹ [3]ã€åŒ»ç–—åˆ†å¸ƒå¤–æ£€æµ‹ [50] å’Œè§†é¢‘ç›‘æ§\n[24]ï¼Œä½¿å…¶æˆä¸ºä¸€é¡¹å…³é”®ä»»åŠ¡å’Œèšå…‰ç¯ã€‚ åœ¨æ— ç›‘ç£ AD\nçš„èƒŒæ™¯ä¸‹ï¼Œæ²¡æœ‰å…³äºå¼‚å¸¸çš„å…ˆéªŒä¿¡æ¯å¯ç”¨ã€‚\nç›¸åï¼Œæä¾›äº†ä¸€ç»„æ­£å¸¸æ ·æœ¬ä»¥ä¾›å‚è€ƒã€‚\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä»¥å‰çš„åŠªåŠ›è¯•å›¾åœ¨é‚£äº›æ— å¼‚å¸¸çš„æ ·æœ¬ä¸Šæ„å»ºå„ç§è‡ªæˆ‘ç›‘ç£ä»»åŠ¡ã€‚\nè¿™äº›ä»»åŠ¡åŒ…æ‹¬ä½†ä¸é™äºæ ·æœ¬é‡å»º[2ã€5ã€11ã€16ã€26ã€34ã€38ã€48]ã€ä¼ªå¼‚å¸¸å€¼å¢å¼º[23ã€42ã€46]ã€çŸ¥è¯†è’¸é¦[4ã€33ã€\n39]ç­‰ã€‚\nåœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä»åŸºäºçŸ¥è¯†è’¸é¦çš„è§’åº¦è§£å†³äº†æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹çš„é—®é¢˜ã€‚\nåœ¨çŸ¥è¯†è’¸é¦ (KD) [6, 15] ä¸­ï¼ŒçŸ¥è¯†åœ¨å¸ˆç”Ÿ (T-S) å¯¹ä¸­è½¬ç§»ã€‚ åœ¨æ— ç›‘ç£ AD\nçš„èƒŒæ™¯ä¸‹ï¼Œç”±äºå­¦ç”Ÿåœ¨è®­ç»ƒæœŸé—´åªä½“éªŒåˆ°æ­£å¸¸æ ·æœ¬ï¼Œå› æ­¤å½“æŸ¥è¯¢å¼‚å¸¸æ—¶ï¼Œå®ƒå¯èƒ½ä¼šä»æ•™å¸ˆé‚£é‡Œäº§ç”Ÿä¸ä¸€è‡´çš„è¡¨ç¤ºã€‚\nè¯¥å‡è®¾æ„æˆäº†åŸºäº KD çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•çš„åŸºç¡€ã€‚\nç„¶è€Œï¼Œè¿™ä¸ªå‡è®¾åœ¨å®è·µä¸­å¹¶ä¸æ€»æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸º\n\næ•™å¸ˆå’Œå­¦ç”Ÿç½‘ç»œçš„ç›¸åŒæˆ–ç›¸ä¼¼æ¶æ„ï¼ˆå³éåŒºåˆ†è¿‡æ»¤å™¨ [33]ï¼‰\nT-S æ¨¡å‹ä¸­çš„ç›¸åŒæ•°æ®æµ çŸ¥è¯†è½¬ç§»/è’¸é¦ã€‚\n\nå°½ç®¡ä½¿ç”¨è¾ƒå°çš„å­¦ç”Ÿç½‘ç»œéƒ¨åˆ†è§£å†³äº†è¿™ä¸ªé—®é¢˜ [33,\n39]ï¼Œä½†æµ…å±‚æ¶æ„è¾ƒå¼±çš„è¡¨ç¤ºèƒ½åŠ›é˜»ç¢äº†æ¨¡å‹ç²¾ç¡®æ£€æµ‹å’Œå®šä½å¼‚å¸¸ã€‚\n\nTo holistically address the issue mentioned above, we propose a new\nparadigm of knowledge distillation, namely Reverse Distillation, for\nanomaly detection. We use sim- ple diagrams in Fig. 2 to highlight the\nsystematic differ- ence between conventional knowledge distillation and\nthe proposed reverse distillation. First, unlike the conventional\nknowledge distillation framework where both teacher and student adopt\nthe encoder structure, the T-S model in our reverse distillation\nconsists of heterogeneous architectures: a teacher encoder and a student\ndecoder. Second, instead of directly feeding the raw data to the T-S\nmodel simulta- neously, the student decoder takes the low-dimensional\nem- bedding as input, targeting to mimic the teacherâ€™s behavior by\nrestoring the teacher modelâ€™s representations in different scales. From\nthe regression perspective, our reverse distil- lation uses the student\nnetwork to predict the representa- tion of the teacher model. Therefore,\nâ€reverseâ€ here indi- cates both the reverse shapes of teacher encoder\nand stu- dent decoder and the distinct knowledge distillation order\nwhere high-level representation is first distilled, followed by\nlow-level features. It is noteworthy that our reverse distilla- tion\npresents two significant advantages: i) Non-similarity\nstructure. In the proposed T-S model, one can consider the teacher\nencoder as a down-sampling filter and the stu- dent decoder as an\nup-sampling filter. The â€reverse struc- turesâ€ avoid the confusion\ncaused by non-distinguishing fil- ters [33] as we discussed above. ii)\nCompactness embed- ding. The low-dimensional embedding fed to\nthe student decoder acts as an information bottleneck for normal pat-\ntern restoration. Letâ€™s formulate anomaly features as pertur- bations on\nnormal patterns. Then the compact embedding helps to prohibit the\npropagation of such unusual perturba- tions to the student model and\nthus boosts the T-S modelâ€™s representation discrepancy on anomalies.\nNotably, tradi- tional AE-based methods [5, 11, 16, 26] detect anomalies\nutilising pixel differences, whereas we perform discrimi- nation with\ndense descriptive features. Deep features as region-aware descriptors\nprovide more effective discrimi- native information than per-pixel in\nimages.\n\n\n\n\n\n\n\n\n\nä¸ºäº†å…¨é¢è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„çŸ¥è¯†è’¸é¦èŒƒå¼ï¼Œå³åå‘è’¸é¦ï¼Œç”¨äºå¼‚å¸¸æ£€æµ‹ã€‚\næˆ‘ä»¬ä½¿ç”¨å›¾ 2\nä¸­çš„ç®€å•å›¾è¡¨æ¥çªå‡ºä¼ ç»ŸçŸ¥è¯†è’¸é¦å’Œæå‡ºçš„é€†å‘è’¸é¦ä¹‹é—´çš„ç³»ç»Ÿå·®å¼‚ã€‚\né¦–å…ˆï¼Œä¸æ•™å¸ˆå’Œå­¦ç”Ÿéƒ½é‡‡ç”¨ç¼–ç å™¨ç»“æ„çš„ä¼ ç»ŸçŸ¥è¯†è’¸é¦æ¡†æ¶ä¸åŒï¼Œæˆ‘ä»¬çš„é€†å‘è’¸é¦ä¸­çš„\nT-S æ¨¡å‹ç”±å¼‚æ„æ¶æ„ç»„æˆï¼šæ•™å¸ˆç¼–ç å™¨å’Œå­¦ç”Ÿè§£ç å™¨ã€‚\nå…¶æ¬¡ï¼Œå­¦ç”Ÿè§£ç å™¨ä¸æ˜¯ç›´æ¥å°†åŸå§‹æ•°æ®åŒæ—¶é¦ˆé€åˆ° T-S\næ¨¡å‹ï¼Œè€Œæ˜¯å°†ä½ç»´åµŒå…¥ä½œä¸ºè¾“å…¥ï¼Œæ—¨åœ¨é€šè¿‡æ¢å¤æ•™å¸ˆæ¨¡å‹åœ¨ä¸åŒå°ºåº¦ä¸Šçš„è¡¨ç¤ºæ¥æ¨¡ä»¿æ•™å¸ˆçš„è¡Œä¸ºã€‚\nä»å›å½’çš„è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬çš„åå‘è’¸é¦ä½¿ç”¨å­¦ç”Ÿç½‘ç»œæ¥é¢„æµ‹æ•™å¸ˆæ¨¡å‹çš„è¡¨ç¤ºã€‚\nå› æ­¤ï¼Œè¿™é‡Œçš„â€œåå‘â€è¡¨ç¤ºæ•™å¸ˆç¼–ç å™¨å’Œå­¦ç”Ÿè§£ç å™¨çš„åå‘å½¢çŠ¶ä»¥åŠä¸åŒçš„çŸ¥è¯†è’¸é¦é¡ºåºï¼Œå…¶ä¸­é¦–å…ˆè’¸é¦é«˜çº§è¡¨ç¤ºï¼Œç„¶åæ˜¯ä½çº§ç‰¹å¾ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„é€†å‘è’¸é¦å…·æœ‰ä¸¤ä¸ªæ˜¾ç€ä¼˜åŠ¿ï¼šiï¼‰éç›¸ä¼¼æ€§ç»“æ„ã€‚\nåœ¨æå‡ºçš„ T-S\næ¨¡å‹ä¸­ï¼Œå¯ä»¥å°†æ•™å¸ˆç¼–ç å™¨è§†ä¸ºä¸‹é‡‡æ ·æ»¤æ³¢å™¨ï¼Œå°†å­¦ç”Ÿè§£ç å™¨è§†ä¸ºä¸Šé‡‡æ ·æ»¤æ³¢å™¨ã€‚\næ­£å¦‚æˆ‘ä»¬ä¸Šé¢è®¨è®ºçš„ï¼Œâ€œåå‘ç»“æ„â€é¿å…äº†ç”±éåŒºåˆ†è¿‡æ»¤å™¨[33]å¼•èµ·çš„æ··æ·†ã€‚ ii)\nç´§å‡‘æ€§åµŒå…¥ã€‚\né¦ˆé€åˆ°å­¦ç”Ÿè§£ç å™¨çš„ä½ç»´åµŒå…¥å……å½“äº†æ­£å¸¸æ¨¡å¼æ¢å¤çš„ä¿¡æ¯ç“¶é¢ˆã€‚\nè®©æˆ‘ä»¬å°†å¼‚å¸¸ç‰¹å¾è¡¨è¿°ä¸ºå¯¹æ­£å¸¸æ¨¡å¼çš„æ‰°åŠ¨ã€‚\nç„¶åç´§å‡‘åµŒå…¥æœ‰åŠ©äºç¦æ­¢è¿™ç§ä¸å¯»å¸¸çš„æ‰°åŠ¨ä¼ æ’­åˆ°å­¦ç”Ÿæ¨¡å‹ï¼Œä»è€Œæé«˜ T-S\næ¨¡å‹å¯¹å¼‚å¸¸çš„è¡¨ç¤ºå·®å¼‚ã€‚ å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¼ ç»Ÿçš„åŸºäº AE çš„æ–¹æ³•\n[5ã€11ã€16ã€26]\nåˆ©ç”¨åƒç´ å·®å¼‚æ£€æµ‹å¼‚å¸¸ï¼Œè€Œæˆ‘ä»¬ä½¿ç”¨å¯†é›†çš„æè¿°æ€§ç‰¹å¾è¿›è¡ŒåŒºåˆ†ã€‚\nä½œä¸ºåŒºåŸŸæ„ŸçŸ¥æè¿°ç¬¦çš„æ·±åº¦ç‰¹å¾æ¯”å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ æä¾›æ›´æœ‰æ•ˆçš„åˆ¤åˆ«ä¿¡æ¯ã€‚\nIn addition, since the compactness of the bottleneck em- bedding is\nvital for anomaly detection (as discussed above), we introduce a\none-class bottleneck embedding (OCBE) module to condense the feature\ncodes further. Our OCBE module consists of a multi-scale feature fusion\n(MFF) block and one-class embedding (OCE) block, both jointly opti-\nmized with the student decoder. Notably, the former aggre- gates low-\nand high-level features to construct a rich embed- ding for normal\npattern reconstruction. The latter targets to retain essential\ninformation favorable for the student to de- code out the teacherâ€™s\nresponse. We perform extensive experiments on public bench- marks. The\nexperimental results indicate that our re- verse distillation paradigm\nachieves comparable perfor- mance with prior arts. The proposed OCBE\nmodule further improves the performance to a new state-of-the-art (SOTA)\nrecord. Our main contributions are summarized as follows:\n\nWe introduce a simple, yet effective Reverse Distilla- tion\nparadigm for anomaly detection. The encoder- decoder structure and\nreverse knowledge distillation strategy holistically address the\nnon-distinguishing fil- ter problem in conventional KD models, boosting\nthe T-S modelâ€™s discrimination capability on anomalies.\nWe propose a one-class bottleneck embedding mod- ule to project\nthe teacherâ€™s high-dimensional features to a compact one-class embedding\nspace. This inno- vation facilitates retaining rich yet compact codes\nfor anomaly-free representation restoration at the student.\nWe perform extensive experiments and show that our approach\nachieves new SOTA performance.\n\n\n\n\n\n\n\n\n\n\næ­¤å¤–ï¼Œç”±äºç“¶é¢ˆåµŒå…¥çš„ç´§å‡‘æ€§å¯¹äºå¼‚å¸¸æ£€æµ‹è‡³å…³é‡è¦ï¼ˆå¦‚ä¸Šæ‰€è¿°ï¼‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç±»ç“¶é¢ˆåµŒå…¥ï¼ˆOCBEï¼‰æ¨¡å—æ¥è¿›ä¸€æ­¥å‹ç¼©ç‰¹å¾ä»£ç ã€‚\næˆ‘ä»¬çš„ OCBE æ¨¡å—ç”±å¤šå°ºåº¦ç‰¹å¾èåˆ (MFF) å—å’Œä¸€ç±»åµŒå…¥ (OCE)\nå—ç»„æˆï¼Œä¸¤è€…éƒ½ä¸å­¦ç”Ÿè§£ç å™¨è”åˆä¼˜åŒ–ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå‰è€…èšåˆäº†ä½çº§å’Œé«˜çº§ç‰¹å¾ä»¥æ„å»ºç”¨äºæ­£å¸¸æ¨¡å¼é‡å»ºçš„ä¸°å¯ŒåµŒå…¥ã€‚\nåè€…çš„ç›®æ ‡æ˜¯ä¿ç•™æœ‰åˆ©äºå­¦ç”Ÿè§£ç æ•™å¸ˆååº”çš„åŸºæœ¬ä¿¡æ¯ã€‚\næˆ‘ä»¬åœ¨å…¬å…±åŸºå‡†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒã€‚\nå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„åå‘è’¸é¦èŒƒå¼å®ç°äº†ä¸ç°æœ‰æŠ€æœ¯ç›¸å½“çš„æ€§èƒ½ã€‚ æ‰€æå‡ºçš„\nOCBE æ¨¡å—è¿›ä¸€æ­¥å°†æ€§èƒ½æé«˜åˆ°æ–°çš„æœ€å…ˆè¿› (SOTA) è®°å½•ã€‚\næˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š\n\næˆ‘ä»¬ä¸ºå¼‚å¸¸æ£€æµ‹å¼•å…¥äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„é€†å‘è’¸é¦èŒƒå¼ã€‚\nç¼–ç å™¨-è§£ç å™¨ç»“æ„å’Œåå‘çŸ¥è¯†è’¸é¦ç­–ç•¥æ•´ä½“è§£å†³äº†ä¼ ç»Ÿ KD\næ¨¡å‹ä¸­çš„éåŒºåˆ†è¿‡æ»¤å™¨é—®é¢˜ï¼Œæé«˜äº† T-S æ¨¡å‹å¯¹å¼‚å¸¸çš„åˆ¤åˆ«èƒ½åŠ›ã€‚\n\næˆ‘ä»¬æå‡ºäº†ä¸€ç±»ç“¶é¢ˆåµŒå…¥æ¨¡å—ï¼Œå°†æ•™å¸ˆçš„é«˜ç»´ç‰¹å¾æŠ•å½±åˆ°ç´§å‡‘çš„ä¸€ç±»åµŒå…¥ç©ºé—´ã€‚\nè¿™é¡¹åˆ›æ–°æœ‰åŠ©äºä¿ç•™ä¸°å¯Œè€Œç´§å‡‘çš„ä»£ç ï¼Œä»¥ä¾¿åœ¨å­¦ç”Ÿå¤„è¿›è¡Œæ— å¼‚å¸¸è¡¨ç¤ºæ¢å¤ã€‚\næˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒå¹¶è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†æ–°çš„ SOTA æ€§èƒ½ã€‚\n\n\n2. Related Work\nThis section briefly reviews previous efforts on unsuper- vised\nanomaly detection. We will highlight the similarity and difference\nbetween the proposed method and prior arts. Classical anomaly detection\nmethods focus on defining a compact closed one-class distribution using\nnormal sup- port vectors. The pioneer studies include one-class support\nvector machine (OC-SVM) [35] and support vector data description (SVDD)\n[36]. To cope with high-dimensional data, DeepSVDD [31] and PatchSVDD\n[43] estimate data representations through deep networks. Another\nunsupervised AD prototype is the use of gener- ative models, such as\nAutoEncoder (AE) [19] and Genera- tive Adversarial Nets (GAN) [12], for\nsample reconstruc- tion. These methods rely on the hypothesis that\ngenera- tive models trained on normal samples only can success- fully\nreconstruct anomaly-free regions, but fail for anoma- lous regions [2,\n5, 34]. However, recent studies show that deep models generalize so well\nthat even anomalous re- gions can be well-restored [46]. To address this\nissue, memory mechanism [11, 16, 26] , image masking strat- egy [42, 46]\nand pseudo-anomaly [28, 45] are incorporated in reconstruction-based\nmethods. However, these meth- ods still lack a strong discriminating\nability for real-world anomaly detection [3, 5]. Recently, Metaformer\n(MF) [40] proposes the use of meta-learning [9] to bridge model adap-\ntation and reconstruction gap for reconstruction-based ap- proaches.\nNotably, the proposed reverse knowledge distil- lation also adopts the\nencoder-decoder architecture, but it differs from construction-based\nmethods in two-folds. First, the encoder in a generative model is\njointly trained with the decoder, while our reverse distillation freezes\na pre-trained model as the teacher. Second, instead of pixel-level\nrecon- struction error, it performs anomaly detection on the seman- tic\nfeature space.\n\n\n\n\n\n\n\n\n\næœ¬èŠ‚ç®€è¦å›é¡¾äº†ä»¥å‰åœ¨æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æ–¹é¢çš„åŠªåŠ›ã€‚\næˆ‘ä»¬å°†å¼ºè°ƒæ‰€æå‡ºçš„æ–¹æ³•ä¸ç°æœ‰æŠ€æœ¯ä¹‹é—´çš„ç›¸ä¼¼ä¹‹å¤„å’Œä¸åŒä¹‹å¤„ã€‚\nç»å…¸çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ä¾§é‡äºä½¿ç”¨æ­£æ€æ”¯æŒå‘é‡å®šä¹‰ç´§å‡‘çš„å°é—­ä¸€ç±»åˆ†å¸ƒã€‚\nå…ˆé©±ç ”ç©¶åŒ…æ‹¬ä¸€ç±»æ”¯æŒå‘é‡æœºï¼ˆOC-SVMï¼‰[35]å’Œæ”¯æŒå‘é‡æ•°æ®æè¿°ï¼ˆSVDDï¼‰[36]ã€‚\nä¸ºäº†å¤„ç†é«˜ç»´æ•°æ®ï¼ŒDeepSVDD [31] å’Œ PatchSVDD [43]\né€šè¿‡æ·±åº¦ç½‘ç»œä¼°è®¡æ•°æ®è¡¨ç¤ºã€‚ å¦ä¸€ä¸ªæ— ç›‘ç£çš„ AD\nåŸå‹æ˜¯ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œä¾‹å¦‚è‡ªåŠ¨ç¼–ç å™¨ (AE) [19] å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN)\n[12]ï¼Œç”¨äºæ ·æœ¬é‡å»ºã€‚\nè¿™äº›æ–¹æ³•ä¾èµ–äºè¿™æ ·ä¸€ä¸ªå‡è®¾ï¼Œå³åœ¨æ­£å¸¸æ ·æœ¬ä¸Šè®­ç»ƒçš„ç”Ÿæˆæ¨¡å‹åªèƒ½æˆåŠŸåœ°é‡å»ºæ— å¼‚å¸¸åŒºåŸŸï¼Œä½†å¯¹äºå¼‚å¸¸åŒºåŸŸåˆ™å¤±è´¥\n[2, 5, 34]ã€‚\nç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œæ·±åº¦æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›éå¸¸å¥½ï¼Œå³ä½¿æ˜¯å¼‚å¸¸åŒºåŸŸä¹Ÿå¯ä»¥å¾ˆå¥½åœ°æ¢å¤\n[46]ã€‚\nä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè®°å¿†æœºåˆ¶[11ã€16ã€26]ã€å›¾åƒæ©è”½ç­–ç•¥[42ã€46]å’Œä¼ªå¼‚å¸¸[28ã€45]è¢«çº³å…¥åŸºäºé‡å»ºçš„æ–¹æ³•ä¸­ã€‚\nç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯¹äºç°å®ä¸–ç•Œçš„å¼‚å¸¸æ£€æµ‹ä»ç„¶ç¼ºä¹å¾ˆå¼ºçš„è¾¨åˆ«èƒ½åŠ›[3, 5]ã€‚\næœ€è¿‘ï¼ŒMetaformer (MF) [40] æå‡ºä½¿ç”¨å…ƒå­¦ä¹  [9]\næ¥å¼¥åˆåŸºäºé‡å»ºçš„æ–¹æ³•çš„æ¨¡å‹é€‚åº”å’Œé‡å»ºå·®è·ã€‚\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ‰€æå‡ºçš„åå‘çŸ¥è¯†è’¸é¦ä¹Ÿé‡‡ç”¨äº†ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œä½†å®ƒä¸åŸºäºæ„é€ çš„æ–¹æ³•æœ‰ä¸¤æ–¹é¢çš„ä¸åŒã€‚\né¦–å…ˆï¼Œç”Ÿæˆæ¨¡å‹ä¸­çš„ç¼–ç å™¨ä¸è§£ç å™¨è”åˆè®­ç»ƒï¼Œè€Œæˆ‘ä»¬çš„é€†å‘è’¸é¦å°†é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹å†»ç»“ä¸ºæ•™å¸ˆã€‚\nå…¶æ¬¡ï¼Œå®ƒä¸æ˜¯åƒç´ çº§çš„é‡å»ºé”™è¯¯ï¼Œè€Œæ˜¯å¯¹è¯­ä¹‰ç‰¹å¾ç©ºé—´è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚\nData augmentation strategy is also widely used. By adding pseudo\nanomalies in the provided anomaly-free samples, the unsupervised task is\nconverted to a supervised learning task [23, 42, 46]. However, these\napproaches are prone to bias towards pseudo outliers and fail to detect\na large variety of anomaly types. For example, CutPaste [23] generates\npseudo outliers by adding small patches onto nor- mal images and trains\na model to detect these anomalous regions. Since the model focuses on\ndetecting local fea- tures such as edge discontinuity and texture\nperturbations, it fails to detect and localize large defects and global\nstruc- tural anomalies as shown in Fig. 6. Recently, networks\npre-trained on the large dataset are proven to be capable of extracting\ndiscriminative features for anomaly detection [7,8,23,25,29,30]. With a\npre-trained model, memorizing its anomaly-free features helps to iden-\ntify anomalous samples [7, 29]. The studies in [8, 30] show that using\nthe Mahalanobis distance to measure the simi- larity between anomalies\nand anomaly-free features leads to accurate anomaly detection. Since\nthese methods re- quire memorizing all features from training samples,\nthey are computationally expensive. Knowledge distillation from\npre-trained models is an- other potential solution to anomaly detection.\nIn the con- text of unsupervised AD, since the student model is ex-\nposed to anomaly-free samples in knowledge distillation, the T-S model\nis expected to generate discrepant features on anomalies in inference\n[4,33,39]. To further increase the discrimnating capability of the T-S\nmodel on various types of abnormalities, different strategies are\nintroduced. For in- stance, in order to capture multi-scale anomaly, US\n[4] en- sembles several models trained on normal data at different\nscales, and MKD [33] propose to use multi-level features alignment. It\nshould be noted that though the proposed method is also based on\nknowledge distillation, our reverse distillation is the first to adopt\nan encoder and a decoder to construct the T-S model. The heterogeneity\nof the teacher and student networks and reverse data flow in knowledge\ndistillation distinguishes our method from prior arts.\n\n\n\n\n\n\n\n\n\næ•°æ®å¢å¼ºç­–ç•¥ä¹Ÿè¢«å¹¿æ³›ä½¿ç”¨ã€‚\né€šè¿‡åœ¨æä¾›çš„æ— å¼‚å¸¸æ ·æœ¬ä¸­æ·»åŠ ä¼ªå¼‚å¸¸ï¼Œå°†æ— ç›‘ç£ä»»åŠ¡è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ ä»»åŠ¡\n[23,42,46]ã€‚\nç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å®¹æ˜“åå‘ä¼ªå¼‚å¸¸å€¼ï¼Œå¹¶ä¸”æ— æ³•æ£€æµ‹åˆ°å¤šç§å¼‚å¸¸ç±»å‹ã€‚\nä¾‹å¦‚ï¼ŒCutPaste [23]\né€šè¿‡åœ¨æ­£å¸¸å›¾åƒä¸Šæ·»åŠ å°å—æ¥ç”Ÿæˆä¼ªå¼‚å¸¸å€¼ï¼Œå¹¶è®­ç»ƒæ¨¡å‹æ¥æ£€æµ‹è¿™äº›å¼‚å¸¸åŒºåŸŸã€‚\nç”±äºè¯¥æ¨¡å‹ä¾§é‡äºæ£€æµ‹å±€éƒ¨ç‰¹å¾ï¼Œä¾‹å¦‚è¾¹ç¼˜ä¸è¿ç»­æ€§å’Œçº¹ç†æ‰°åŠ¨ï¼Œå› æ­¤æ— æ³•æ£€æµ‹å’Œå®šä½å¤§ç¼ºé™·å’Œå…¨å±€ç»“æ„å¼‚å¸¸ï¼Œå¦‚å›¾\n6 æ‰€ç¤ºã€‚\næœ€è¿‘ï¼Œåœ¨å¤§å‹æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæå–ç”¨äºå¼‚å¸¸æ£€æµ‹çš„åˆ¤åˆ«ç‰¹å¾\n[7,8,23,25,29,30]ã€‚ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè®°ä½å…¶æ— å¼‚å¸¸ç‰¹å¾æœ‰åŠ©äºè¯†åˆ«å¼‚å¸¸æ ·æœ¬\n[7, 29]ã€‚ [8, 30]\nä¸­çš„ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨é©¬æ°è·ç¦»æ¥æµ‹é‡å¼‚å¸¸å’Œæ— å¼‚å¸¸ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼æ€§å¯ä»¥å®ç°å‡†ç¡®çš„å¼‚å¸¸æ£€æµ‹ã€‚\nç”±äºè¿™äº›æ–¹æ³•éœ€è¦è®°ä½è®­ç»ƒæ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾ï¼Œå› æ­¤å®ƒä»¬çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚\næ¥è‡ªé¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†è’¸é¦æ˜¯å¼‚å¸¸æ£€æµ‹çš„å¦ä¸€ä¸ªæ½œåœ¨è§£å†³æ–¹æ¡ˆã€‚ åœ¨æ— ç›‘ç£ AD\nçš„èƒŒæ™¯ä¸‹ï¼Œç”±äºå­¦ç”Ÿæ¨¡å‹åœ¨çŸ¥è¯†è’¸é¦ä¸­æš´éœ²äºæ— å¼‚å¸¸æ ·æœ¬ï¼Œå› æ­¤ T-S\næ¨¡å‹é¢„è®¡ä¼šåœ¨æ¨ç†å¼‚å¸¸ä¸Šäº§ç”Ÿå·®å¼‚ç‰¹å¾ [4,33,39]ã€‚ ä¸ºäº†è¿›ä¸€æ­¥æé«˜ T-S\næ¨¡å‹å¯¹å„ç±»å¼‚å¸¸çš„åˆ¤åˆ«èƒ½åŠ›ï¼Œå¼•å…¥äº†ä¸åŒçš„ç­–ç•¥ã€‚\nä¾‹å¦‚ï¼Œä¸ºäº†æ•è·å¤šå°ºåº¦å¼‚å¸¸ï¼ŒUS [4]\né›†æˆäº†å‡ ä¸ªåœ¨ä¸åŒå°ºåº¦çš„æ­£å¸¸æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼ŒMKD [33]\nå»ºè®®ä½¿ç”¨å¤šçº§ç‰¹å¾å¯¹é½ã€‚\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶æ‰€æå‡ºçš„æ–¹æ³•ä¹Ÿæ˜¯åŸºäºçŸ¥è¯†è’¸é¦çš„ï¼Œä½†æˆ‘ä»¬çš„é€†å‘è’¸é¦æ˜¯ç¬¬ä¸€ä¸ªé‡‡ç”¨ç¼–ç å™¨å’Œè§£ç å™¨æ¥æ„å»º\nT-S æ¨¡å‹çš„æ–¹æ³•ã€‚\næ•™å¸ˆå’Œå­¦ç”Ÿç½‘ç»œçš„å¼‚è´¨æ€§ä»¥åŠçŸ¥è¯†è’¸é¦ä¸­çš„åå‘æ•°æ®æµå°†æˆ‘ä»¬çš„æ–¹æ³•ä¸ç°æœ‰æŠ€æœ¯åŒºåˆ†å¼€æ¥ã€‚\n","slug":"ä¸€ç±»åµŒå…¥åå‘è’¸é¦","date":"2022-05-04T03:30:00.000Z","categories_index":"","tags_index":"æ·±åº¦å­¦ä¹ ,å¼‚å¸¸åˆ†å‰²","author_index":"Star"},{"id":"4346091fabb18c4f718acfd51c087897","title":"Pytorch & python","content":"pytorch\nå‚æ•° &amp; å‘½ä»¤è¡Œ &amp; è¾…åŠ©\nlogger\nloggeræ¨¡å—è§£é‡Š\nâ€”â€” CSDN loggerä½¿ç”¨æ¡ˆä¾‹\nloggingæ¨¡å—æ˜¯Pythonå†…ç½®çš„æ ‡å‡†æ¨¡å—ï¼Œä¸»è¦ç”¨äºè¾“å‡ºè¿è¡Œæ—¥å¿—ï¼Œå¯ä»¥è®¾ç½®è¾“å‡ºæ—¥å¿—çš„ç­‰çº§ã€æ—¥å¿—ä¿å­˜è·¯å¾„ã€æ—¥å¿—æ–‡ä»¶å›æ»šç­‰\nyacs.config\nyacsä½¿ç”¨ â€”â€”\nçŸ¥ä¹\nyacsåº“ï¼Œç”¨äºä¸ºä¸€ä¸ªç³»ç»Ÿæ„å»ºconfigæ–‡ä»¶\néœ€è¦åˆ›å»ºCN()è¿™ä¸ªä½œä¸ºå®¹å™¨æ¥è£…è½½æˆ‘ä»¬çš„å‚æ•°ï¼Œè¿™ä¸ªå®¹å™¨å¯ä»¥åµŒå¥—\nè®¾å¤‡ç›¸å…³\ntorch.cuda.synchronize()\nç­‰å¾…å½“å‰è®¾å¤‡ä¸Šæ‰€æœ‰æµä¸­çš„æ‰€æœ‰æ ¸å¿ƒå®Œæˆã€‚\nğŸŒ°ï¼šæµ‹è¯•æ—¶é—´çš„ä»£ç \n# code 1\nstart = time.time()\nresult = model(input)\nend = time.time()\n\n# code 2\ntorch.cuda.synchronize()\nstart = time.time()\nresult = model(input)\ntorch.cuda.synchronize()\nend = time.time()\n\n# code 3\nstart = time.time()\nresult = model(input)\nprint(result)\nend = time.time()\nä»£ç 2æ˜¯æ­£ç¡®çš„ã€‚å› ä¸ºåœ¨pytorché‡Œé¢ï¼Œç¨‹åºçš„æ‰§è¡Œéƒ½æ˜¯å¼‚æ­¥çš„ã€‚\nå¦‚æœé‡‡ç”¨ä»£ç 1ï¼Œæµ‹è¯•çš„æ—¶é—´ä¼šå¾ˆçŸ­ï¼Œå› ä¸ºæ‰§è¡Œå®Œend=time.time()ç¨‹åºå°±é€€å‡ºäº†ï¼Œåå°çš„cuä¹Ÿå› ä¸ºpythonçš„é€€å‡ºé€€å‡ºäº†ã€‚\nå¦‚æœé‡‡ç”¨ä»£ç 2ï¼Œä»£ç ä¼šåŒæ­¥cuçš„æ“ä½œï¼Œç­‰å¾…gpuä¸Šçš„æ“ä½œéƒ½å®Œæˆäº†å†ç»§ç»­æˆå½¢end\n= time.time()\nä»£ç 3å’Œä»£ç 2çš„æ—¶é—´æ˜¯ç±»ä¼¼çš„ã€‚\nå› ä¸ºä»£ç 3ä¼šç­‰å¾…gpuä¸Šçš„ç»“æœæ‰§è¡Œå®Œä¼ ç»™printå‡½æ•°ï¼Œæ‰€ä»¥æ—¶é—´å°±å’Œä»£ç 2åŒæ­¥çš„æ“ä½œçš„æ—¶é—´åŸºæœ¬ä¸Šæ˜¯ä¸€è‡´çš„äº†ã€‚\nå°†print(result)æ¢æˆresult.cpu()ç»“æœæ˜¯ä¸€è‡´çš„ã€‚\næ•°æ®åŠ è½½\nå›¾åƒæ•°æ®å˜æ¢\ntransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224,\n0.225])\nNormalizeæ˜¯æŠŠå›¾åƒæ•°æ®ä»[0,1]å˜æˆ[-1,1]ï¼Œå˜æ¢å…¬å¼æ˜¯image=(image-mean)/stdï¼Œé‚£ä¹ˆå…¶ä¸­çš„å‚æ•°å°±åˆ†åˆ«æ˜¯ä¸‰ä¸ªé€šé“çš„meanå’Œstdï¼Œè¿™ä¸ªå‡å€¼å’Œæ ‡å‡†å·®éœ€è¦è‡ªå·±è®¡ç®—ï¼ŒèŒƒå›´å°±æ˜¯è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ‰€æœ‰å›¾åƒã€‚\nDataLoader\nCSDNåŸæ–‡é“¾æ¥\ncollate_fnå‚æ•°ä½¿ç”¨è¯¦è§£\nâ€”â€” çŸ¥ä¹ num_workså‚æ•°\nâ€”â€” CSDN\n\nåŠ è½½ä¸€ä¸ªbatchçš„æ•°æ®è¿™ä¸€æ­¥éœ€è¦ä½¿ç”¨ä¸€ä¸ªtorch.utils.data.DataLoaderå¯¹è±¡ï¼Œå¹¶ä¸”DataLoaderæ˜¯ä¸€ä¸ªåŸºäºæŸä¸ªdatasetçš„iterableï¼Œè¿™ä¸ªiterableæ¯æ¬¡ä»datasetä¸­åŸºäºæŸç§é‡‡æ ·åŸåˆ™å–å‡ºä¸€ä¸ªbatchçš„æ•°æ®ã€‚\nä¹Ÿå¯ä»¥è¿™æ ·è¯´ï¼šTorchä¸­å¯ä»¥åˆ›å»ºä¸€ä¸ªtorch.utils.data.==Dataset==å¯¹è±¡ï¼Œå¹¶ä¸torch.utils.data.==DataLoader==ä¸€èµ·ä½¿ç”¨ï¼Œåœ¨è®­ç»ƒæ¨¡å‹æ—¶ä¸æ–­ä¸ºæ¨¡å‹æä¾›æ•°æ®ã€‚\ntorch.utils.data.DataLoader\nå®šä¹‰ï¼šData loader. Combines a dataset and a sampler, and provides an\niterable over the given dataset. æ„é€ å‡½æ•°: torch.utils.data.DataLoader(dataset, \n\t\t\t\t\t\t\tbatch_size=1, \n\t\t\t\t\t\t\tshuffle=False, \n\t\t\t\t\t\t\tsampler=None,\n\t\t\t\t\t\t\tbatch_sampler=None, num_workers=0, collate_fn=None,\n\t\t\t\t\t\t\tpin_memory=False, drop_last=False, timeout=0,\n\t\t\t\t\t\t\tworker_init_fn=None) - dataset:\næŠ½è±¡ç±»,åŒ…å«ä¸¤ç§ç±»å‹ - map-style datasets -\niterable-style datasets - batch_size :\næ¯ä¸€æ¬¡æŠ½æ ·çš„batch-sizeå¤§å° - shuffle : Trueåˆ™éšæœºæ‰“ä¹±æ•°æ® -\nNum_worksï¼šå°†batchåŠ è½½è¿›RAMçš„è¿›ç¨‹æ•°ã€‚å†…å­˜å¼€é”€å¤§ï¼ŒCPUè´Ÿæ‹…å¤§ã€‚å¯èƒ½ä¹‹åå‡ æ¬¡è¿­ä»£çš„æ•°æ®åœ¨æœ¬æ¬¡è¿­ä»£çš„æ—¶å€™å·²ç»åŠ è½½è¿›å†…å­˜ã€‚\n-\ncollate_fnï¼šå¦‚ä½•å–æ ·æœ¬çš„ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰è‡ªå·±çš„å‡½æ•°æ¥å‡†ç¡®åœ°å®ç°æƒ³è¦çš„åŠŸèƒ½ã€‚\n-\ndrop_lastï¼šå‘Šè¯‰å¦‚ä½•å¤„ç†æ•°æ®é›†é•¿åº¦é™¤äºbatch_sizeä½™ä¸‹çš„æ•°æ®ã€‚Trueå°±æŠ›å¼ƒï¼Œå¦åˆ™ä¿ç•™ã€‚\nMap-style datasets\næ˜¯ä¸€ä¸ªç±»ï¼Œè¦æ±‚æœ‰\n__getitem__()and__len__()è¿™ä¸¤ä¸ªæ„é€ å‡½æ•°ï¼Œä»£è¡¨ä¸€ä¸ªä»ç´¢å¼•æ˜ å°„åˆ°æ•°æ®æ ·æœ¬ã€‚\n- __getitem__(): æ ¹æ®ç´¢å¼•indexéå†æ•°æ® -\n__len__(): è¿”å›æ•°æ®é›†çš„é•¿åº¦ - å¯ç¼–å†™ç‹¬ç«‹çš„æ•°æ®å¤„ç†å‡½æ•° - åœ¨\n__getitem()__ å‡½æ•°ä¸­è¿›è¡Œè°ƒç”¨ - ç›´æ¥å°†æ•°æ®å¤„ç†å‡½æ•°å†™åœ¨\n__getitem()__ æˆ–è€… __init()__\nå‡½æ•°ä¸­ï¼Œä½†æ˜¯__getitem()__\nå¿…é¡»æ ¹æ®==index==è¿”å›å“åº”çš„å€¼ï¼Œè¯¥å€¼ä¼šé€šè¿‡indexä¼ åˆ°dataloaderä¸­è¿›è¡Œåç»­çš„batchæ‰¹å¤„ç†ã€‚\nåŸºæœ¬éœ€è¦æ»¡è¶³ï¼š def __getitem__(self, index):\n    return self.src[index], self.trg[index]\n\ndef __len__(self):\n\treturn len(self.src)  \ngetitem()æ–¹æ³•ç”¨æ¥ä»datasetsä¸­è¯»å–ä¸€æ¡æ•°æ®ï¼Œè¿™æ¡æ•°æ®åŒ…å«è®­ç»ƒå›¾ç‰‡ï¼ˆå·²CVè·ç¦»ï¼‰å’Œæ ‡ç­¾ï¼Œå‚æ•°indexè¡¨ç¤ºå›¾ç‰‡å’Œæ ‡ç­¾åœ¨æ€»æ•°æ®é›†ä¸­çš„Indexã€‚\nlen()æ–¹æ³•è¿”å›æ•°æ®é›†çš„æ€»é•¿åº¦ï¼ˆè®­ç»ƒé›†çš„æ€»æ•°ï¼‰ã€‚\nå®ç° MyDatasets ç±»\n\nç®€å•ç›´ç™½\n\næŠŠ x å’Œ label åˆ†åˆ«è£…å…¥ä¸¤ä¸ªåˆ—è¡¨ self.src å’Œ self.trg ï¼Œç„¶åé€šè¿‡\ngetitem(self, idex) è¿”å›å¯¹åº”å…ƒç´  import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n \nclass My_dataset(Dataset):\n    def __init__(self):\n        super().__init__()\n        ## ä½¿ç”¨sinå‡½æ•°è¿”å›10000ä¸ªæ—¶é—´åºåˆ—,å¦‚æœä¸è‡ªå·±æ„é€ æ•°æ®ï¼Œå°±ä½¿ç”¨numpy,pandasç­‰è¯»å–è‡ªå·±çš„æ•°æ®ä¸ºxå³å¯ã€‚\n        ## ä»¥ä¸‹æ•°æ®ç»„ç»‡è¿™å—æ—¢å¯ä»¥æ”¾åœ¨initæ–¹æ³•é‡Œï¼Œä¹Ÿå¯ä»¥æ”¾åœ¨getitemæ–¹æ³•é‡Œ\n        self.x = torch.randn(1000,3)\n        self.y = self.x.sum(axis=1)\n        self.src,  self.trg = [], []\n        for i in range(1000):\n            self.src.append(self.x[i])\n            self.trg.append(self.y[i])\n    \n           \n    def __getitem__(self, index):\n        return self.src[index], self.trg[index]\n\n    def __len__(self):\n        return len(self.src) \n        \n ## æˆ–è€…return len(self.trg), srcå’Œtrgé•¿åº¦ä¸€æ ·\n \ndata_train = My_dataset()\ndata_test = My_dataset()\ndata_loader_train = DataLoader(data_train, batch_size=5, shuffle=False)\ndata_loader_test = DataLoader(data_test, batch_size=5, shuffle=False)\n## i_batchçš„å¤šå°‘æ ¹æ®batch sizeå’Œdef __len__(self)è¿”å›çš„é•¿åº¦ç¡®å®š\n## batch_dataè¿”å›çš„å€¼æ ¹æ®def __getitem__(self, index)æ¥ç¡®å®š\n## å¯¹è®­ç»ƒé›†ï¼š(ä¸å¤ªæ¸…æ¥šenumerateè¿”å›ä»€ä¹ˆçš„æ—¶å€™å°±å¤šprintè¯•è¯•)\nfor i_batch, batch_data in enumerate(data_loader_train):\n    print(i_batch)  ## æ‰“å°batchç¼–å·\n    print(batch_data[0])  ## æ‰“å°è¯¥batché‡Œé¢src\n    print(batch_data[1])  ## æ‰“å°è¯¥batché‡Œé¢trg\n## å¯¹æµ‹è¯•é›†ï¼šï¼ˆä¸‹é¢çš„è¯­å¥ä¹Ÿå¯ä»¥ï¼‰\nfor i_batch, (src, trg) in enumerate(data_loader_test):\n    print(i_batch)  ## æ‰“å°batchç¼–å·\n    print(src)  ## æ‰“å°è¯¥batché‡Œé¢srcçš„å°ºå¯¸\n    print(trg)  ## æ‰“å°è¯¥batché‡Œé¢trgçš„å°ºå¯¸    \nç”Ÿæˆçš„data_trainå¯ä»¥é€šè¿‡\ndata_train[xxx]ç›´æ¥ç´¢å¼•æŸä¸ªå…ƒç´ ï¼Œæˆ–è€…é€šè¿‡next(iter(data_train))\nå¾—åˆ°ä¸€æ¡æ¡çš„æ•°æ®ã€‚\n\nå€ŸåŠ©TensorDatasetå°†æ•°æ®åŒ…è£…æˆdataset\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n \nsrc = torch.sin(torch.arange(1, 1000, 0.1))\ntrg = torch.cos(torch.arange(1, 1000, 0.1))\n \ndata = TensorDataset(src, trg)\ndata_loader = DataLoader(data, batch_size=5, shuffle=False)\nfor i_batch, batch_data in enumerate(data_loader):\n    print(i_batch)  ## æ‰“å°batchç¼–å·\n    print(batch_data[0].size())  ## æ‰“å°è¯¥batché‡Œé¢src\n    print(batch_data[1].size())  ## æ‰“å°è¯¥batché‡Œé¢trg\n\nåœ°å€è¯»å–ï¼Œç”Ÿæˆæ•°æ®çš„è·¯å¾„ txtæ–‡ä»¶\n\nimport os\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport matplotlib.image as mpimg\n\n\n\n## å¯¹æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆpath-label map.txt è¿™ä¸ªç¨‹åºå¯æ ¹æ®å®é™…éœ€è¦é€‚å½“ä¿®æ”¹\ndef generate_map(root_dir):\n\t##å¾—åˆ°å½“å‰ç»å¯¹è·¯å¾„\n    current_path = os.path.abspath('.')\n    ##os.path.dirname()å‘å‰é€€ä¸€ä¸ªè·¯å¾„\n    father_path = os.path.abspath(os.path.dirname(current_path) + os.path.sep + \".\")\n\n    with open(root_dir + 'map.txt', 'w') as wfp:\n        for idx in range(10):\n            subdir = os.path.join(root_dir, '%d/' % idx)\n            for file_name in os.listdir(subdir):\n                abs_name = os.path.join(father_path, subdir, file_name)\n                ## linux_abs_name = abs_name.replace(\"\\\\\", '/')\n                wfp.write('&#123;file_dir&#125; &#123;label&#125;\\n'.format(file_dir=linux_abs_name, label=idx))\n\n## å®ç°MyDatasetsç±»\nclass MyDatasets(Dataset):\n\n    def __init__(self, dir):\n        ## è·å–æ•°æ®å­˜æ”¾çš„dir\n        ## ä¾‹å¦‚d:/images/\n        self.data_dir = dir\n        ## ç”¨äºå­˜æ”¾(image,label) tupleçš„list,å­˜æ”¾çš„æ•°æ®ä¾‹å¦‚(d:/image/1.png,4)\n        self.image_target_list = []\n        ## ä»dir--labelçš„mapæ–‡ä»¶ä¸­å°†æ‰€æœ‰çš„tupleå¯¹è¯»å–åˆ°image_target_listä¸­\n        ## map.txtä¸­å…¨éƒ¨å­˜æ”¾çš„æ˜¯d:/.../image_data/1/3.jpg 1 è·¯å¾„æœ€å¥½æ˜¯ç»å¯¹è·¯å¾„\n        with open(os.path.join(dir, 'map.txt'), 'r') as fp:\n            content = fp.readlines()\n            ##s.rstrip()åˆ é™¤å­—ç¬¦ä¸²æœ«å°¾æŒ‡å®šå­—ç¬¦ï¼ˆé»˜è®¤æ˜¯å­—ç¬¦ï¼‰\n            ## å¾—åˆ° [['d:/.../image_data/1/3.jpg', '1'], ...,]\n            str_list = [s.rstrip().split() for s in content]\n            ## å°†æ‰€æœ‰å›¾ç‰‡çš„dir--labelå¯¹éƒ½æ”¾å…¥åˆ—è¡¨ï¼Œå¦‚æœè¦æ‰§è¡Œå¤šä¸ªepochï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤šå¤åˆ¶å‡ éï¼Œç„¶åç»Ÿä¸€shuffleæ¯”è¾ƒå¥½\n            self.image_target_list = [(x[0], int(x[1])) for x in str_list]\n\n    def __getitem__(self, index):\n        image_label_pair = self.image_target_list[index]\n        ## æŒ‰pathè¯»å–å›¾ç‰‡æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºå›¾ç‰‡æ ¼å¼ä¾‹å¦‚[3,32,32]\n        ## å¯ä»¥ç”¨åˆ«çš„ä»£æ›¿\n        img = mpimg.imread(image_label_pair[0])\n        return img, image_label_pair[1]\n\n    def __len__(self):\n        return len(self.image_target_list)\n\n\nif __name__ == '__main__':\n    ## ç”Ÿæˆmap.txt\n    ## generate_map('train/')\n\n    train_loader = DataLoader(MyDatasets('train/'), batch_size=128, shuffle=True)\n\n    for step in range(20000):\n        for idx, (img, label) in enumerate(train_loader):\n            print(img.shape)\n            print(label.shape)\nç½‘ç»œæ­å»ºTrick\nwith torch.no_grad()\n\n\n\n\n\n\n\n\n\nå‚è€ƒï¼šhttps://blog.csdn.net/sazass/article/details/116668755\nä½œç”¨ï¼šåœ¨è¯¥æ¨¡å—ä¸‹ï¼Œæ‰€æœ‰è®¡ç®—å¾—å‡ºçš„tensorçš„requires_gradéƒ½è‡ªåŠ¨è®¾ç½®ä¸ºFalseã€‚å½“requires_gradè®¾ç½®ä¸ºFalseæ—¶,åå‘ä¼ æ’­æ—¶å°±ä¸ä¼šè‡ªåŠ¨æ±‚å¯¼äº†ï¼Œå› æ­¤å¤§å¤§èŠ‚çº¦äº†æ˜¾å­˜æˆ–è€…è¯´å†…å­˜ã€‚\nåŸºæœ¬åŠŸèƒ½å‡½æ•°\ntorch.max()\ntorch.max(input) â†’ Tensor:è¿”å›è¾“å…¥tensorä¸­æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼\ntorch.max(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor):\næŒ‰ç»´åº¦dim è¿”å›æœ€å¤§å€¼ï¼Œå¹¶ä¸”è¿”å›ç´¢å¼•ã€‚\ntorch.max()[0]ï¼Œ åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªæ•°\n\ntroch.max()[1]ï¼Œ åªè¿”å›æœ€å¤§å€¼çš„æ¯ä¸ªç´¢å¼•\n\ntorch.max()[1].data åªè¿”å›variableä¸­çš„æ•°æ®éƒ¨åˆ†ï¼ˆå»æ‰Variable containing:ï¼‰\n\ntorch.max()[1].data.numpy() æŠŠæ•°æ®è½¬åŒ–æˆnumpy ndarry\n\ntorch.max()[1].data.numpy().squeeze() æŠŠæ•°æ®æ¡ç›®ä¸­ç»´åº¦ä¸º1 çš„åˆ é™¤æ‰\npython\nstr.lower() å…¨éƒ¨è½¬åŒ–ä¸ºå°å†™å­—æ¯\n","slug":"python&pytorchä½¿ç”¨æŒ‡å—","date":"2022-05-03T12:10:00.000Z","categories_index":"","tags_index":"","author_index":"Star"},{"id":"cca6975b74b1218e11c5b9ba5de4d5ef","title":"DMLNet","content":"\nå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²\n\nå¼€é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—\n\né—­é›†è¯­ä¹‰åˆ†å‰²å­æ¨¡å—\n\nå¼‚å¸¸åˆ†å‰²å­æ¨¡å—\n\nå¢é‡å°æ ·æœ¬å­¦ä¹ æ¨¡å—\n\næˆ‘æ˜¯çŸ­å°ç²¾æ‚çš„æ–‡ç« æ‘˜è¦(à¹‘â€¢Ì€ã…‚â€¢Ì) âœ§\n\nCODE\nmultiscale æ˜¯è‡ªå·±è®¾å®šçš„å—\ncfg.DATASET.imgSizes = (300, 375, 450, 525, 600)\nSeg è½¬åŒ–ä¸ºlong Tensorçš„ç›®çš„æ˜¯ä»€ä¹ˆ\ncolorsçš„ä½œç”¨æ˜¯ä»€ä¹ˆ\nå‡ ä¸ªè¾…åŠ©å‡½æ•°çš„ä½œç”¨ï¼š\nNormalization(x): \\(\\dfrac{x -\nmin(x)}{max(x) - min(x)}\\)\nCoefficient_map(x, thre): \\(\\dfrac{1}{1 + exp(50*(x - thre))}\\)\nnormfun(x, mu, sigma):\\(\\dfrac{exp(-\\frac{(x - mu)^2}{2 *\n\\sigma^2})}{\\sigma * \\sqrt{2*\\pi}}\\)\nè®ºæ–‡é˜…è¯»\nå¼•è¨€\nClassical close-set semantic segmentation networks have limited\nability to detect out-of-distribution (OOD) objects, which is important\nfor safety-critical applications such as autonomous driving.\nIncrementally learning these OOD objects with few annotations is an\nideal way to enlarge the knowledge base of the deep learning models. In\nthis paper, we propose an open world semantic segmenta- tion system that\nincludes two modules:\n\n==an open-set semantic segmentation module to detect both\nin-distribution and OOD objects==.\nan incremental few-shot learning module to gradually incorporate\nthose OOD objects into its existing knowledge base.\n\nThis open world semantic segmentation system behaves like a human\nbeing, which is able to identify OOD objects and gradually learn them\nwith corresponding supervision.\nWe adopt the ==Deep Metric Learning Network (DMLNet) with contrastive\nclustering== to implement open-set semantic segmentation. Compared to\nother open-set semantic segmentation methods, our DMLNet achieves\nstate-of-the-art performance on three challenging open-set semantic\nsegmentation datasets without using additional data or generative\nmodels.\nOn this basis, two incremental few-shot learning methods are fur-\nther proposed to progressively improve the DMLNet with the annotations\nof OOD objects\n\nç»å…¸çš„é—­é›†è¯­ä¹‰åˆ†å‰²ç½‘ç»œæ£€æµ‹åˆ†å¸ƒå¤– (OOD)\nå¯¹è±¡çš„èƒ½åŠ›æœ‰é™ï¼Œè¿™å¯¹äºè‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨å…³é”®å‹åº”ç”¨å¾ˆé‡è¦ã€‚\nå¢é‡å­¦ä¹ è¿™äº›å¸¦æœ‰å°‘é‡æ³¨é‡Šçš„ OOD å¯¹è±¡æ˜¯æ‰©å¤§æ·±åº¦å­¦ä¹ æ¨¡å‹çŸ¥è¯†åº“çš„ç†æƒ³æ–¹æ³•ã€‚\nåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼š\n\nä¸€ä¸ªå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—ï¼Œç”¨äºæ£€æµ‹å†…åˆ†å¸ƒå’ŒOODå¯¹è±¡ã€‚\n\n(2) ä¸€ä¸ªå¢é‡çš„å°æ ·æœ¬å­¦ä¹ æ¨¡å—ï¼Œé€æ¸å°†è¿™äº› OOD\nå¯¹è±¡çº³å…¥å…¶ç°æœ‰çš„çŸ¥è¯†åº“ã€‚\nè¿™ä¸ªå¼€æ”¾ä¸–ç•Œçš„è¯­ä¹‰åˆ†å‰²ç³»ç»Ÿå°±åƒä¸€ä¸ªäººï¼Œèƒ½å¤Ÿè¯†åˆ«OODå¯¹è±¡å¹¶åœ¨ç›¸åº”çš„ç›‘ç£ä¸‹é€æ¸å­¦ä¹ å®ƒä»¬ã€‚\næˆ‘ä»¬é‡‡ç”¨å…·æœ‰==å¯¹æ¯”èšç±»çš„æ·±åº¦åº¦é‡å­¦ä¹ ç½‘ç»œï¼ˆDMLNetï¼‰==æ¥å®ç°å¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²ã€‚\nä¸å…¶ä»–å¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ DMLNet\nåœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€Œæ— éœ€ä½¿ç”¨é¢å¤–çš„æ•°æ®æˆ–ç”Ÿæˆæ¨¡å‹ã€‚\nåœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥æå‡ºäº†ä¸¤ç§å¢é‡å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ OOD\nå¯¹è±¡çš„æ³¨é‡Šé€æ­¥æ”¹è¿› DMLNet\n6. Conclusion\nWe introduce an open world semantic segmentation system which\nincorporates two modules:\n\nan open-set segmentation module\nan incremental few-shot learning module.\n\nOur proposed open-set segmentation module is based on the\ndeep metric learning network, and it uses the\nEuclidean distance sum criterion to achieve\nstate-of-the-art performance.\nTwo incremental few-shot learning methods are proposed to broaden the\nperception knowledge of the network. Both modules of the open world\nsemantic segmentation system can be further studied to improve the\nperformance. We hope our work can draw more researchers to contribute to\nthis practically valuable research direction.\n\næˆ‘ä»¬ä»‹ç»äº†ä¸€ä¸ªå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿï¼Œå®ƒåŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šä¸€ä¸ªå¼€æ”¾é›†åˆ†å‰²æ¨¡å—å’Œä¸€ä¸ªå¢é‡å°æ ·æœ¬å­¦ä¹ æ¨¡å—ã€‚\næˆ‘ä»¬æå‡ºçš„å¼€æ”¾é›†åˆ†å‰²æ¨¡å—åŸºäºæ·±åº¦åº¦é‡å­¦ä¹ ç½‘ç»œï¼Œå®ƒä½¿ç”¨==æ¬§å‡ é‡Œå¾·è·ç¦»å’Œæ ‡å‡†==æ¥å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚\næå‡ºäº†ä¸¤ç§å¢é‡å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•æ¥æ‹“å®½ç½‘ç»œçš„æ„ŸçŸ¥çŸ¥è¯†ã€‚\nå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿçš„ä¸¤ä¸ªæ¨¡å—éƒ½å¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶ä»¥æé«˜æ€§èƒ½ã€‚\næˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„å·¥ä½œèƒ½å¤Ÿå¸å¼•æ›´å¤šçš„ç ”ç©¶äººå‘˜ä¸ºè¿™ä¸ªå…·æœ‰å®é™…ä»·å€¼çš„ç ”ç©¶æ–¹å‘åšå‡ºè´¡çŒ®\n1. ä»‹ç»\nå¾—ç›Šäºé«˜è´¨é‡çš„æ•°æ®é›† [3,4,5]ï¼Œæ·±åº¦å·ç§¯ç½‘ç»œåœ¨è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ [1, 2]\nä¸­å–å¾—äº†å·¨å¤§æˆåŠŸã€‚\nè¿™äº›è¯­ä¹‰åˆ†å‰²ç½‘ç»œåœ¨è®¸å¤šåº”ç”¨ä¸­è¢«ç”¨ä½œæ„ŸçŸ¥ç³»ç»Ÿï¼Œå¦‚è‡ªåŠ¨é©¾é©¶[6]ã€åŒ»ç–—è¯Šæ–­[7]ç­‰ã€‚ç„¶è€Œï¼Œè¿™äº›æ„ŸçŸ¥ç³»ç»Ÿä¸­çš„å¤§å¤šæ•°éƒ½æ˜¯é—­é›†å’Œé™æ€çš„ã€‚\né—­é›†è¯­ä¹‰åˆ†å‰²å‡è®¾æµ‹è¯•ä¸­çš„æ‰€æœ‰ç±»éƒ½å·²ç»åœ¨è®­ç»ƒæœŸé—´å‚ä¸ï¼Œè¿™åœ¨å¼€æ”¾ä¸–ç•Œä¸­æ˜¯ä¸æ­£ç¡®çš„ã€‚\nå¦‚æœé—­é›†ç³»ç»Ÿé”™è¯¯åœ°å°†åˆ†å‘ä¸­æ ‡ç­¾åˆ†é…ç»™ OOD å¯¹è±¡\n[8]ï¼Œå®ƒå¯èƒ½ä¼šåœ¨å®‰å…¨å…³é”®å‹åº”ç”¨ç¨‹åºï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ï¼‰ä¸­é€ æˆç¾éš¾æ€§åæœã€‚\nåŒæ—¶ï¼Œé™æ€æ„ŸçŸ¥ç³»ç»Ÿæ— æ³•æ ¹æ®æ‰€è§å†…å®¹æ›´æ–°å…¶çŸ¥è¯†åº“ï¼Œå› æ­¤ï¼Œå®ƒä»…é™äºç‰¹å®šåœºæ™¯ï¼Œéœ€è¦åœ¨ä¸€å®šæ—¶é—´åé‡æ–°è®­ç»ƒã€‚\nä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¼€æ”¾é›†çš„åŠ¨æ€æ„ŸçŸ¥ç³»ç»Ÿï¼Œç§°ä¸ºå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿã€‚\nå®ƒåŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼š\nï¼ˆ1ï¼‰ä¸€ä¸ªå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—ï¼Œç”¨äºæ£€æµ‹OODå¯¹è±¡å¹¶å°†æ­£ç¡®çš„æ ‡ç­¾åˆ†é…ç»™åˆ†å¸ƒä¸­çš„å¯¹è±¡ã€‚\n\nä¸€ä¸ªå¢é‡çš„å°æ ·æœ¬å­¦ä¹ æ¨¡å—ï¼Œå°†è¿™äº›æœªçŸ¥å¯¹è±¡é€æ­¥åˆå¹¶åˆ°å…¶ç°æœ‰çš„çŸ¥è¯†åº“ä¸­ã€‚\n\næˆ‘ä»¬æå‡ºçš„å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿçš„æ•´ä¸ªæµç¨‹å¦‚å›¾ 1\næ‰€ç¤º\nå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²å’Œå¢é‡å°æ ·æœ¬å­¦ä¹ éƒ½æ²¡æœ‰å¾—åˆ°å¾ˆå¥½çš„è§£å†³ã€‚\nå¯¹äºå¼€é›†è¯­ä¹‰åˆ†å‰²ï¼Œæœ€é‡è¦çš„éƒ¨åˆ†æ˜¯åœ¨ä¸€å¼ å›¾åƒçš„æ‰€æœ‰åƒç´ ä¸­è¯†åˆ«OODåƒç´ ï¼Œç§°ä¸ºå¼‚å¸¸åˆ†å‰²ã€‚\nå¼‚å¸¸åˆ†å‰²çš„å…¸å‹æ–¹æ³•æ˜¯å°†å›¾åƒçº§çš„å¼€é›†åˆ†ç±»æ–¹æ³•åº”ç”¨äºåƒç´ çº§çš„å¼€é›†åˆ†ç±»ã€‚\nè¿™äº›æ–¹æ³•åŒ…æ‹¬åŸºäºä¸ç¡®å®šæ€§ä¼°è®¡çš„æ–¹æ³• [9, 10, 11, 12]\nå’ŒåŸºäºè‡ªåŠ¨ç¼–ç å™¨çš„æ–¹æ³• [13, 14]ã€‚\nç„¶è€Œï¼Œè¿™ä¸¤ç§æ–¹æ³•å·²è¢«è¯æ˜åœ¨é©¾é©¶åœºæ™¯ä¸­æ— æ•ˆï¼Œå› ä¸ºåŸºäºä¸ç¡®å®šæ€§ä¼°è®¡çš„æ–¹æ³•==ä¼šç»™å‡ºè®¸å¤šå‡é˜³æ€§å¼‚å¸¸å€¼æ£€æµ‹==\n[15] å¹¶ä¸”è‡ªåŠ¨ç¼–ç å™¨==æ— æ³•é‡æ–°ç”Ÿæˆå¤æ‚çš„åŸå¸‚åœºæ™¯== [16]ã€‚\næœ€è¿‘ï¼ŒåŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆåŸºäº GANï¼‰çš„æ–¹æ³• [16, 17]\nå·²è¢«è¯æ˜æ˜¯æœ‰æ•ˆçš„ï¼Œä½†å®ƒä»¬è¿œ==éè½»é‡çº§==ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦åœ¨ç®¡é“ä¸­ä½¿ç”¨å¤šä¸ªæ·±åº¦ç½‘ç»œã€‚\nå¯¹äºå¢é‡å°‘æ ·æœ¬å­¦ä¹ ï¼Œæˆ‘ä»¬ä¸ä»…è¦å¤„ç†å¢é‡å­¦ä¹ çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚ç¾éš¾æ€§é—å¿˜[18]ï¼Œè¿˜è¦å¤„ç†å°‘æ ·æœ¬å­¦ä¹ çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬ä»å°‘é‡æ ·æœ¬ä¸­æå–ä»£è¡¨æ€§ç‰¹å¾[19]\nåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ DMLNet æ¥è§£å†³å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²é—®é¢˜ã€‚\nåŸå› æœ‰ä¸‰ï¼š\n\nDMLNetçš„åˆ†ç±»åŸç†æ˜¯åŸºäºå¯¹æ¯”èšç±»ï¼Œå¯ä»¥æœ‰æ•ˆè¯†åˆ«å¼‚å¸¸ç‰©ä½“ï¼Œå¦‚å›¾2æ‰€ç¤º\n\n\n\n\n\n\n\n\n\n\n\nåº¦é‡å­¦ä¹ ï¼šä»æ•°æ®ä¸­å­¦ä¹ ä¸€ç§åº¦é‡æ•°æ®å¯¹è±¡é—´è·ç¦»çš„æ–¹æ³•ã€‚å…¶ç›®æ ‡æ˜¯ä½¿å¾—åœ¨å­¦å¾—çš„è·ç¦»åº¦é‡ä¸‹ï¼Œç›¸ä¼¼å¯¹è±¡é—´çš„è·ç¦»å°ï¼Œä¸ç›¸ä¼¼å¯¹è±¡é—´çš„è·ç¦»å¤§ã€‚\nä¼ ç»Ÿçš„åº¦é‡å­¦ä¹ æ–¹æ³•åªèƒ½å­¦ä¹ å‡ºçº¿æ€§ç‰¹å¾ï¼Œè™½ç„¶æœ‰ä¸€äº›èƒ½å¤Ÿæå–éçº¿æ€§ç‰¹å¾çš„æ ¸æ–¹æ³•è¢«æå‡ºï¼Œä½†å¯¹å­¦ä¹ æ•ˆæœä¹Ÿæ²¡æœ‰æ˜æ˜¾æå‡\næ·±åº¦åº¦é‡å­¦ä¹ ï¼šæ·±åº¦å­¦ä¹ çš„æ¿€æ´»å‡½æ•°å­¦ä¹ éçº¿æ€§ç‰¹å¾çš„ä¼˜ç§€èƒ½åŠ›ï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿè‡ªåŠ¨åœ°ä»åŸå§‹æ•°æ®ä¸­å­¦å‡ºé«˜è´¨é‡çš„ç‰¹å¾ã€‚å› æ­¤æ·±åº¦å­¦ä¹ çš„ç½‘ç»œç»“æ„ä¸ä¼ ç»Ÿçš„åº¦é‡å­¦ä¹ æ–¹æ³•ç›¸ç»“åˆèƒ½å¤Ÿå¸¦æ¥ç†æƒ³çš„æ•ˆæœã€‚\n(2) DMLNetç»“åˆåŸå‹éå¸¸é€‚åˆfew-shot ä»»åŠ¡[19]ã€‚\n(3) DMLNet\nçš„å¢é‡å­¦ä¹ å¯ä»¥é€šè¿‡æ·»åŠ æ–°çš„åŸå‹æ¥å®ç°ï¼Œè¿™æ˜¯ä¸€ç§è‡ªç„¶è€Œæœ‰ç”¨çš„æ–¹æ³•\n[20]ã€‚\nåŸºäº DMLNet\næ¶æ„ï¼Œæˆ‘ä»¬ä¸ºå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—å¼€å‘äº†ä¸¤ç§æœªçŸ¥è¯†åˆ«æ ‡å‡†ï¼Œä¸ºå¢é‡å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—å¼€å‘äº†ä¸¤ç§æ–¹æ³•ã€‚\næ ¹æ®æˆ‘ä»¬çš„å®éªŒï¼Œè¿™ä¸¤ä¸ªæ¨¡å—éƒ½è¢«éªŒè¯ä¸ºæœ‰æ•ˆä¸”è½»é‡çº§çš„ã€‚\næ€»è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬çš„è´¡çŒ®å¦‚ä¸‹ï¼š\n\næˆ‘ä»¬ç‡å…ˆæ¨å‡ºå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿï¼Œåœ¨å®é™…åº”ç”¨ä¸­æ›´åŠ ç¨³å¥å®ç”¨ã€‚\næˆ‘ä»¬æå‡ºçš„åŸºäº DMLNet\nçš„å¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—åœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚\næˆ‘ä»¬æå‡ºçš„few-shot\nå¢é‡å­¦ä¹ æ¨¡å—æ–¹æ³•åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šç¼“è§£äº†ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚\né€šè¿‡ç»“åˆæˆ‘ä»¬æå‡ºçš„å¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—å’Œå¢é‡å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—ï¼Œå®ç°äº†ä¸€ä¸ªå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿã€‚\n\n2. Related Work\n2.1 å¼‚å¸¸è¯­ä¹‰åˆ†å‰²\nå¼‚å¸¸è¯­ä¹‰åˆ†å‰²çš„æ–¹æ³•å¯ä»¥åˆ†ä¸ºä¸¤ç§è¶‹åŠ¿ï¼š\nåŸºäºä¸ç¡®å®šæ€§ä¼°è®¡çš„æ–¹æ³•å’ŒåŸºäºç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•ã€‚\nä¸ç¡®å®šæ€§ä¼°è®¡çš„åŸºçº¿æ˜¯æœ€å¤§softmaxæ¦‚ç‡ï¼ˆMSPï¼‰ï¼Œå®ƒé¦–å…ˆåœ¨[9]ä¸­æå‡ºã€‚ Dan\nç­‰äººæ²¡æœ‰ä½¿ç”¨ softmax æ¦‚ç‡ã€‚\n[11]æå‡ºä½¿ç”¨æœ€å¤§logitï¼ˆMaxLogitï¼‰å¹¶å–å¾—æ›´å¥½çš„å¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚\nè´å¶æ–¯ç½‘ç»œé‡‡ç”¨æ·±åº¦å­¦ä¹ ç½‘ç»œçš„æ¦‚ç‡è§‚ç‚¹ï¼Œæ‰€ä»¥å®ƒä»¬çš„æƒé‡å’Œè¾“å‡ºæ˜¯æ¦‚ç‡åˆ†å¸ƒè€Œä¸æ˜¯ç‰¹å®šçš„æ•°å­—\n[21, 22]ã€‚ åœ¨å®è·µä¸­ï¼ŒDropout [10] æˆ–é›†æˆ [12]\né€šå¸¸ç”¨äºè¿‘ä¼¼è´å¶æ–¯æ¨ç†ã€‚\nè‡ªåŠ¨ç¼–ç å™¨ï¼ˆAEï¼‰[23, 13] å’Œ RBM [14] æ˜¯å…¸å‹çš„ç”Ÿæˆæ–¹æ³•ï¼Œå‡è®¾ OOD\nå›¾åƒçš„é‡å»ºè¯¯å·®å¤§äºåˆ†å¸ƒå†…å›¾åƒ\næœ€è¿‘ï¼Œå¦ä¸€ç§åŸºäº GAN\nå†åˆæˆçš„ç”Ÿæˆæ¨¡å‹è¢«è¯æ˜å¯ä»¥åŸºäºå…¶å¯é çš„é«˜åˆ†è¾¨ç‡åƒç´ åˆ°åƒç´ è½¬æ¢ç»“æœå®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚\nSynthCP [17] å’Œ DUIR [16] æ˜¯åŸºäº GAN å†åˆæˆçš„ä¸¤ç§æ–¹æ³•ã€‚\nä¸å¹¸çš„æ˜¯ï¼Œå®ƒä»¬ç¦»è½»é‡çº§è¿˜å¾ˆè¿œï¼Œå› ä¸ºå¿…é¡»ä¾æ¬¡ä½¿ç”¨ä¸¤ä¸ªæˆ–ä¸‰ä¸ªç¥ç»ç½‘ç»œæ¥è¿›è¡Œ\nOOD æ£€æµ‹ã€‚\nä¸å®ƒä»¬ç›¸æ¯”ï¼Œæˆ‘ä»¬è¯æ˜äº†åŸºäºå¯¹æ¯”èšç±»çš„ DMLNet\nå…·æœ‰æ›´å¥½çš„å¼‚å¸¸åˆ†å‰²æ€§èƒ½ï¼Œè€Œåªéœ€è¦æ¨ç†ä¸€æ¬¡\n2.2 æ·±åº¦åº¦é‡å­¦ä¹ ç½‘ç»œ\nDMLNets å·²ç”¨äºå¤šç§åº”ç”¨ï¼ŒåŒ…æ‹¬è§†é¢‘ç†è§£ [24] å’Œäººå‘˜é‡æ–°è¯†åˆ« [25]ã€‚\nDMLNet ä½¿ç”¨æ¬§å‡ é‡Œå¾—ã€é©¬æ°è·ç¦»æˆ– Matusita è·ç¦» [26]\nå°†æ­¤ç±»é—®é¢˜è½¬æ¢ä¸ºè®¡ç®—åº¦é‡ç©ºé—´ä¸­çš„åµŒå…¥ç‰¹å¾ç›¸ä¼¼åº¦ã€‚\nå·ç§¯åŸå‹ç½‘ç»œå’Œ DMLNets\né€šå¸¸ä¸€èµ·ç”¨äºè§£å†³ç‰¹å®šé—®é¢˜ï¼Œä¾‹å¦‚æ£€æµ‹å›¾åƒçº§ OOD æ ·æœ¬ [27ã€28ã€29]\nå’Œç”¨äºè¯­ä¹‰åˆ†å‰²çš„å°æ ·æœ¬å­¦ä¹  [19ã€30ã€31]ã€‚\næˆ‘ä»¬ä¹ŸæŒ‰ç…§è¿™ç§ç»„åˆæ„å»ºäº†ç¬¬ä¸€ä¸ªç”¨äºå¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²çš„ DMLNet\n2.3 å¼€æ”¾ä¸–ç•Œåˆ†ç±»å’Œæ£€æµ‹\nå¼€æ”¾ä¸–ç•Œåˆ†ç±»é¦–å…ˆç”± [32] æå‡ºã€‚è¿™é¡¹å·¥ä½œæå‡ºäº†æœ€è¿‘éå¼‚å¸¸å€¼ (NNO)\nç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨å¢é‡æ·»åŠ å¯¹è±¡ç±»åˆ«ã€æ£€æµ‹å¼‚å¸¸å€¼å’Œç®¡ç†å¼€æ”¾ç©ºé—´é£é™©æ–¹é¢éå¸¸æœ‰æ•ˆã€‚\næœ€è¿‘çº¦ç‘Ÿå¤«ç­‰äººã€‚\n[33]æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”èšç±»ã€æœªçŸ¥æ„ŸçŸ¥æè®®ç½‘ç»œå’ŒåŸºäºèƒ½é‡çš„æœªçŸ¥è¯†åˆ«æ ‡å‡†çš„å¼€æ”¾ä¸–ç•Œå¯¹è±¡æ£€æµ‹ç³»ç»Ÿã€‚\næˆ‘ä»¬çš„å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿçš„ç®¡é“ä¸ä»–ä»¬çš„ç›¸ä¼¼ï¼Œé™¤äº†ä¸¤ä¸ªé‡è¦çš„åŒºåˆ«ä½¿æˆ‘ä»¬çš„ä»»åŠ¡æ›´å…·æŒ‘æˆ˜æ€§ï¼šï¼ˆ1ï¼‰åœ¨ä»–ä»¬çš„å¼€æ”¾é›†æ£€æµ‹æ¨¡å—ä¸­ï¼Œä»–ä»¬ä¾èµ–äºåŒºåŸŸæè®®ç½‘ç»œï¼ˆRPNï¼‰æ˜¯\nç±»ä¸å¯çŸ¥ï¼Œå› æ­¤ä¹Ÿå¯ä»¥æ£€æµ‹åˆ°æœªæ ‡è®°çš„æ½œåœ¨ OOD å¯¹è±¡ã€‚\nè¿™æ ·ï¼ŒOODæ ·æœ¬çš„ä¿¡æ¯å¯¹äºè®­ç»ƒæ˜¯æœ‰æ•ˆçš„ã€‚\nä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸“æ³¨äºè¯­ä¹‰åˆ†å‰²ï¼Œå…¶ä¸­è®­ç»ƒä¸­ä½¿ç”¨çš„æ¯ä¸ªåƒç´ éƒ½è¢«åˆ†é…äº†ä¸€ä¸ªåˆ†å¸ƒå†…æ ‡ç­¾ï¼Œå› æ­¤ä¸èƒ½å°†\nOOD æ ·æœ¬æ·»åŠ åˆ°è®­ç»ƒä¸­ã€‚ (2)\nåœ¨å¢é‡å­¦ä¹ æ¨¡å—ä¸­ï¼Œä»–ä»¬ä½¿ç”¨æ–°ç±»çš„æ‰€æœ‰æ ‡è®°æ•°æ®ï¼Œè€Œæˆ‘ä»¬ä¸“æ³¨äºè‡ªç„¶æ›´å›°éš¾çš„å°‘æ ·æœ¬æ¡ä»¶ã€‚\nå¾ˆå°‘æœ‰ç ”ç©¶é›†ä¸­åœ¨å¢é‡å°æ ·æœ¬å­¦ä¹ ä¸Šï¼Œå…¶ä¸­åŒ…æ‹¬ç”¨äºåˆ†ç±»çš„å¢é‡å°æ ·æœ¬å­¦ä¹ [34]ã€å¯¹è±¡æ£€æµ‹[35]å’Œè¯­ä¹‰åˆ†å‰²[36]\n3. å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²\nåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç»™å‡ºäº†å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿçš„å·¥ä½œæµç¨‹ã€‚\nè¯¥ç³»ç»Ÿç”±ä¸€ä¸ªå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—å’Œä¸€ä¸ªå¢é‡å°æ ·æœ¬å­¦ä¹ æ¨¡å—ç»„æˆã€‚ å‡è®¾\\(\\mathcal{C}_{in} = \\{\\mathcal{C}_{in,1},\n\\mathcal{C}_{in,2},...,\\mathcal{C}_{in,N} \\}\\) æ˜¯ N\nä¸ªåˆ†å¸ƒå†…çš„ç±»ï¼Œå®ƒä»¬éƒ½åœ¨è®­ç»ƒæ•°æ®é›†ä¸­è¿›è¡Œäº†æ³¨é‡Šï¼Œå¹¶ä¸” \\(\\mathcal{C}_{out} =\n\\{\\mathcal{C}_{out,1},\\mathcal{C}_{out,2},...,\\mathcal{C}_{out,M}\n\\}\\) æ˜¯è®­ç»ƒæ•°æ®é›†ä¸­æ²¡æœ‰é‡åˆ°çš„ M ä¸ª OOD ç±»\nå¼€é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—åˆåˆ†ä¸ºä¸¤ä¸ªå­æ¨¡å—ï¼šé—­é›†è¯­ä¹‰åˆ†å‰²å­æ¨¡å—å’Œå¼‚å¸¸åˆ†å‰²å­æ¨¡å—ã€‚\n\n\\(\\hat{Y}^{close}\\)\næ˜¯é—­é›†è¯­ä¹‰åˆ†å‰²å­æ¨¡å—çš„è¾“å‡ºå›¾ï¼Œæ‰€ä»¥æ¯ä¸ªåƒç´ çš„ç±»åˆ« \\(\\hat{Y}^{close}_{i,j} âˆˆ C_{in}\\)ã€‚\nå¼‚å¸¸åˆ†å‰²å­æ¨¡å—çš„åŠŸèƒ½æ˜¯è¯†åˆ«OODåƒç´ ï¼Œå…¶è¾“å‡ºç§°ä¸ºå¼‚å¸¸æ¦‚ç‡å›¾ï¼š\\(\\hat{P} \\in [1,0]^{H \\times W}\\)ï¼Œå…¶ä¸­\n\\(H\\) å’Œ \\(W\\) è¡¨ç¤ºè¾“å…¥å›¾åƒçš„é«˜åº¦å’Œå®½åº¦ã€‚\n\nåŸºäº \\(\\hat{Y}_{close}\\) å’Œ \\(\\hat{P}\\)ï¼Œå¼€é›†è¯­ä¹‰åˆ†å‰²å›¾ \\(\\hat{Y}^{open}\\) ç»™å‡ºä¸º: \\[\n\\hat{Y}^{open}_{i,j} =\n\\begin{cases}\n\\mathcal{C}_{anomaly} \\quad \\     \\hat{P}_{i,j} &gt; \\lambda_{out} \\\\\n\\hat{Y}_{i,j}^{close} \\quad \\quad \\hat{P}_{i,j} \\le \\lambda_{out}\n\\end{cases} \\tag{1}\n\\] \\(\\mathcal{C}_{anomaly}\\)\nï¼šè¡¨ç¤º OOD ç±»åˆ« \\(Î»_{out}\\) ï¼šç¡®å®š OOD\nåƒç´ çš„é˜ˆå€¼ã€‚\nå› æ­¤ï¼Œopensetè¯­ä¹‰åˆ†å‰²æ¨¡å—åº”è¯¥è¯†åˆ«OODåƒç´ å¹¶åˆ†é…æ­£ç¡®çš„åˆ†å¸ƒæ ‡ç­¾ã€‚ç„¶å\nYopen å¯ä»¥è½¬å‘ç»™å¯ä»¥ä» \\(C_{out}\\)\nä¸­è¯†åˆ« \\(C_{anomaly}\\)\nå¹¶ç»™å‡ºæ–°ç±»çš„ç›¸åº”æ³¨é‡Šçš„æ ‡æ³¨è€…\nå¢é‡å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—ç”¨äºåœ¨æœ‰æ–°æ ‡ç­¾æ—¶å°†è¿‘é›†åˆ†å‰²å­æ¨¡å—çš„çŸ¥è¯†åº“ä» \\(C_{in}\\) ä¸€ä¸ªä¸€ä¸ªæ›´æ–°ä¸º \\(C_{in+M}\\)ï¼Œå…¶ä¸­ \\(C_{in+t} = Cin \\cup\n\\{C_{out,1},C_{out,2},...,C_{out,t}\\},t âˆˆ{1,2,...,M}\\)ã€‚\nå›¾ 1 æ˜¾ç¤ºäº†å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿçš„å¾ªç¯å·¥ä½œæµæ°´çº¿\nå›¾ 1. å¼€æ”¾ä¸–ç•Œè¯­ä¹‰åˆ†å‰²ç³»ç»Ÿã€‚ ç¬¬ 1\næ­¥ï¼šè¯†åˆ«å·²çŸ¥å’ŒæœªçŸ¥å¯¹è±¡ï¼ˆè“è‰²ç®­å¤´ï¼‰ã€‚ ç¬¬ 2 æ­¥ï¼šæ³¨é‡ŠæœªçŸ¥å¯¹è±¡ï¼ˆçº¢è‰²ç®­å¤´ï¼‰ã€‚\nç¬¬ 3 æ­¥ï¼šåº”ç”¨å¢é‡å°‘æ ·æœ¬å­¦ä¹ æ¥å¢åŠ ç½‘ç»œçš„åˆ†ç±»èŒƒå›´ï¼ˆç»¿è‰²ç®­å¤´ï¼‰ã€‚ ç¬¬ 4\næ­¥ï¼šåœ¨å¢é‡å°‘æ ·æœ¬å­¦ä¹ ä¹‹åï¼ŒDMLNet å¯ä»¥åœ¨æ›´å¤§çš„åŸŸä¸­è¾“å‡ºç»“æœï¼ˆç´«è‰²ç®­å¤´ï¼‰ã€‚\n\n4. æ–¹æ³•\næˆ‘ä»¬é‡‡ç”¨ DMLNet ä½œä¸ºæˆ‘ä»¬çš„ç‰¹å¾æå–å™¨ï¼Œå¹¶åœ¨ 4.1 èŠ‚è®¨è®ºæ¶æ„å’ŒæŸå¤±å‡½æ•°ã€‚\nå¼€æ”¾é›†åˆ†å‰²æ¨¡å—å’Œå¢é‡å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—åœ¨ 4.2 å’Œ 4.3 èŠ‚ä¸­è¿›è¡Œäº†è¯´æ˜\n4.1 æ·±åº¦åº¦é‡å­¦ä¹ ç½‘ç»œ\n\n\n\n\n\n\n\n\n\nClassical CNN-based semantic segmentation networks can be\ndisentangled into two parts:\n\na feature extractor \\(f(X;Î¸_f)\\)\nfor obtaining the embedding vector of each pixel\na classifier \\(g(f(X;Î¸_f);Î¸_g)\\)\nfor generating the decision boundary,\n\nwhere \\(X\\), \\(Î¸_f\\) and \\(Î¸_g\\) denote the input\nimage, parameters of the feature extractor and\nclassifier respectively.\nThis learnable classifier is not suitable for OOD detection because\nit assigns all feature space to known classes and leaves no space for\nOOD classes.\nä¼ ç»ŸCNN-basedè¯­ä¹‰åˆ†å‰²ç½‘ç»œï¼š\n\n\\(f(X;\\theta_f)\\)\nç‰¹å¾æå–å™¨ï¼šè·å–æ¯ä¸ªåƒç´ çš„åµŒå…¥å‘é‡\n\\(g(f(X;\\theta_f);\\theta_g)\\)\nåˆ†ç±»å™¨ï¼šç”Ÿæˆå†³ç­–è¾¹ç•Œ\n\nè¿™ç§==å¯å­¦ä¹ çš„åˆ†ç±»å™¨ä¸é€‚ç”¨äº OOD\næ£€æµ‹==ï¼Œå› ä¸ºå®ƒå°†æ‰€æœ‰ç‰¹å¾ç©ºé—´åˆ†é…ç»™å·²çŸ¥ç±»ï¼Œå¹¶ä¸”æ²¡æœ‰ä¸º OOD\nç±»ç•™ä¸‹ç©ºé—´ã€‚\n\n\n\n\n\n\n\n\n\nIn contrast, the classifier is replaced by the Euclidean distance\nrepresentation with all prototypes \\(\\mathcal{M}_{in} = \\{ m_t \\in \\mathbb{R}^{1 \\times\nN}|t \\in \\{1,2,...,N\\} \\}\\) in DMLNet, where \\(m_t\\) refers to the prototype of class\n\\(\\mathcal{C}_{in,t}\\). The feature\nextractor \\(f(X;Î¸_f)\\) learns to map\nthe input \\(X\\) to the feature vector\nwhich has the same length as the prototype in metric space. For the\nclose-set segmentation task, the probability of one pixel \\(X_{i,j}\\) belonging to the class \\(\\mathcal{C}_{in,t}\\) is formulated as:\nDMLNet ä¸­, ==æ‰€æœ‰åŸå‹çš„æ¬§å‡ é‡Œå¾—è·ç¦»==è¡¨ç¤ºä»£æ›¿äº†ä¼ ç»Ÿçš„å¯å­¦ä¹ åˆ†ç±»å™¨\n\n\\(m_t\\) æŒ‡çš„æ˜¯ \\(\\mathcal{C}_{in,t}\\) ç±»çš„åŸå‹ã€‚\n\nç‰¹å¾æå–å™¨ \\(f(X;Î¸_f)\\)å­¦ä¹ å°†è¾“å…¥ X\næ˜ å°„åˆ°ä¸åº¦é‡ç©ºé—´ä¸­çš„åŸå‹é•¿åº¦ç›¸åŒçš„ç‰¹å¾å‘é‡ã€‚\nå¯¹äºé—­é›†åˆ†å‰²ä»»åŠ¡ï¼Œä¸€ä¸ªåƒç´  \\(X_{i,j}\\) å±äºç±» \\(\\mathcal{C}_{in,t}\\) çš„æ¦‚ç‡å…¬å¼ä¸ºï¼š \\[\np_t(X_{i,j}) = \\frac{exp(-||f(X;\\theta_f)_{i,j} -\nm_t||^2)}{\\sum^N_{t&#39;=1} exp(-||f(X;\\theta_f)_{i,j} -\nm_{t&#39;}||^2)} \\tag{2}\n\\]\nåŸºäºè¿™ç§åŸºäºæ¬§å‡ é‡Œå¾·è·ç¦»çš„æ¦‚ç‡ï¼Œåˆ¤åˆ«äº¤å‰ç†µ (DCE)\næŸå¤±å‡½æ•° \\(\\mathcal{L}_{DCE}(X_{i,j},Y_{i,j};Î¸_f,M_{in})\\)\n[27] å®šä¹‰ä¸º: \\[\n\\mathcal{L}_{DCE} = \\sum_{i,j} -log (\\frac{exp(-||f(X;\\theta_f)_{i,j} -\nm_{Y_{i,j}}||^2)}{\\sum^N_{k=1} exp(-||f(X;\\theta_f)_{i,j} - m_{k}||^2)}\n\\tag{3}\n\\]\n\\(Y\\)ï¼šè¾“å…¥å›¾åƒ \\(X\\) çš„æ ‡ç­¾ \\(\\mathcal{L}_{DCE}\\)\nçš„åˆ†å­å’Œåˆ†æ¯åˆ†åˆ«æŒ‡å›¾2ä¸­çš„å¸å¼•åŠ›å’Œæ’æ–¥åŠ›ã€‚\n\n\n\n\n\n\n\n\n\næ’æ–¥åŠ›ä¸éœ€è¦é™¤å»æœ¬èº«æ‰€å±çš„ç±»ï¼Œæœ¬èº«ç±»çš„åŸå‹å—ï¼Ÿ\nå›¾ 2. DMLNet çš„å¯¹æ¯”èšç±»ã€‚\nåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå·²çŸ¥å¯¹è±¡å°†è¢«åŒä¸€ç±»çš„åŸå‹æ‰€å¸å¼•ï¼Œè€Œè¢«å‰©ä½™çš„åŸå‹æ‰€æ’æ–¥ã€‚\næœ€åï¼Œå®ƒä»¬å°†å›´ç»•ç‰¹å®šçš„åŸå‹è¿›è¡Œèšåˆã€‚\nç›¸åï¼Œå¼‚å¸¸å¯¹è±¡å°†è¢«æ‰€æœ‰åŸå‹æ’æ–¥ï¼Œå› æ­¤å®ƒä»¬å°†èšé›†åœ¨åº¦é‡ç©ºé—´çš„ä¸­é—´ã€‚\n\næˆ‘ä»¬åˆ¶å®šäº†å¦ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œç§°ä¸ºæ–¹å·®æŸå¤± (VL) å‡½æ•°\n\\(\\mathcal{L}_{VL}(X_{i,j},Y_{i,j};Î¸_f,M_{in})\\)ï¼Œå…¶å®šä¹‰ä¸ºï¼š\n\\[\n\\mathcal{L}_{VL} = \\sum_{i,j} ||f(X;\\theta_f)_{i,j} - m_{Y_{i,j}}||^2\n\\tag{4}\n\\] \\(\\mathcal{L}_{VL}\\)\nåªæœ‰å¸å¼•åŠ›ä½œç”¨ï¼Œæ²¡æœ‰æ’æ–¥åŠ›ä½œç”¨ã€‚\nä½¿ç”¨ DCE å’Œ VLï¼Œæ··åˆæŸå¤±å®šä¹‰ä¸ºï¼š\\(\\mathcal{L}= \\mathcal{L}_{DCE} +\nÎ»_{VL}\\mathcal{L}_{VL}\\)ï¼Œå…¶ä¸­ \\(Î»_{VL}\\) æ˜¯æƒé‡å‚æ•°\n4.2 å¼€é›†è¯­ä¹‰åˆ†å‰²æ¨¡å‹\nå¼€é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—ç”±é—­é›†è¯­ä¹‰åˆ†å‰²å­æ¨¡å—å’Œå¼‚å¸¸åˆ†å‰²å­æ¨¡å—ç»„æˆã€‚\nå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ¨¡å—çš„æµç¨‹å¦‚ å›¾3 æ‰€ç¤ºã€‚\nå›¾3.é—­é›†åˆ†å‰²å­æ¨¡å—åŒ…å«åœ¨è“è‰²è™šçº¿æ¡†å†…ï¼Œå¼‚å¸¸åˆ†å‰²å­æ¨¡å—åŒ…å«åœ¨çº¢è‰²è™šçº¿æ¡†å†…ã€‚\nå¼€é›†åˆ†å‰²å›¾æ˜¯è¿™ä¸¤ä¸ªå­æ¨¡å—ç”Ÿæˆçš„ç»“æœçš„ç»„åˆã€‚\nåœ¨å¼€æ”¾é›†åˆ†å‰²å›¾ä¸­é¢„æµ‹åˆ†å¸ƒå†…ç±»å’Œ OOD ç±»ã€‚ EDS map å’Œ MMSP map çš„å®šä¹‰è¯·å‚è€ƒ\n4.2 èŠ‚ã€‚ \n\né—­é›†è¯­ä¹‰åˆ†å‰²å­æ¨¡å—ä¸ºä¸€å¹…å›¾åƒçš„æ‰€æœ‰åƒç´ åˆ†é…åˆ†å¸ƒæ ‡ç­¾ã€‚\nç”±äºä¸€ä¸ªåƒç´  \\(X_{i,j}\\) å±äºç±» \\(\\mathcal{C}_{in,t}\\) çš„æ¦‚ç‡æ˜¯ç”¨å…¬å¼ 2\nè¡¨ç¤ºï¼Œé—­é›†åˆ†å‰²å›¾ä¸ºï¼š \\[\n\\hat{Y}_{i,j}^{close} = argmax_t \\ p_t(X_{i,j}) \\tag{5}\n\\]\nå¼‚å¸¸åˆ†å‰²å­æ¨¡å—æ£€æµ‹OODåƒç´ ã€‚\næˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªæœªçŸ¥çš„è¯†åˆ«æ ‡å‡†æ¥æµ‹é‡å¼‚å¸¸æ¦‚ç‡ï¼ŒåŒ…æ‹¬_åŸºäºåº¦é‡çš„æœ€å¤§softmaxæ¦‚ç‡ï¼ˆMMSPï¼‰å’Œ_æ¬§å‡ é‡Œå¾—è·ç¦»å’Œï¼ˆEDSï¼‰ã€‚\n\nä»¥ä¸‹æ˜¯åŸºäº MMSP çš„å¼‚å¸¸æ¦‚ç‡ï¼š \\[\n\\hat{P}^{MMSP}_{i,j} = 1 - max \\ p_t(X_{i,j}),\\ t \\in \\{ 1,2,3...,N \\}\n\\tag{6}\n\\]\nEDS æ˜¯æ ¹æ®ä»¥ä¸‹å‘ç°æå‡ºçš„ï¼šå¦‚æœç‰¹å¾ä½äº OOD\nåƒç´ èšé›†çš„åº¦é‡ç©ºé—´çš„ä¸­å¿ƒï¼Œåˆ™ä¸æ‰€æœ‰åŸå‹çš„æ¬§å‡ é‡Œå¾—è·ç¦»å’Œæ›´å°ï¼Œå³==å¼‚å¸¸çš„æ¬§å‡ é‡Œå¾—è·ç¦»è¾ƒå°==ã€‚\nEDS å®šä¹‰ä¸ºï¼š \\[\nS(X_{i,j}) = \\sum_{t=1}^N ||f(X;\\theta_f)_{i,j} - m_t||^2 \\tag{7}\n\\] åŸºäº EDS çš„å¼‚å¸¸æ¦‚ç‡è®¡ç®—å¦‚ä¸‹ï¼š \\[\n\\hat{P}^{EDS}_{i,j} = 1- \\frac{S(X_{i,j})}{maxS(X)} \\tag{8}\n\\]\n\n\nEDS\næ˜¯ç±»ç‹¬ç«‹çš„ï¼Œå› æ­¤æ‰€æœ‰ç±»çš„åŸå‹åº”è¯¥å‡åŒ€åˆ†å¸ƒåœ¨åº¦é‡ç©ºé—´ä¸­ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒæœŸé—´ä¸ç§»åŠ¨ã€‚\n==å¯å­¦ä¹ çš„åŸå‹ä¼šåœ¨è®­ç»ƒæœŸé—´å¯¼è‡´ä¸ç¨³å®šï¼Œå¹¶ä¸”å¯¹æ›´å¥½çš„æ€§èƒ½æ²¡æœ‰è´¡çŒ®== [37]ã€‚\nå› æ­¤ï¼Œæˆ‘ä»¬ä»¥ one-hot å‘é‡å½¢å¼å®šä¹‰åŸå‹ï¼šåªæœ‰ \\(m_t\\) çš„ç¬¬ t ä¸ªå…ƒç´ æ˜¯ \\(T\\)ï¼Œè€Œå…¶ä»–å…ƒç´ ä¿æŒä¸ºé›¶ï¼Œå…¶ä¸­ t âˆˆ\n{1,2,...,N}\n\n\n\n\n\n\n\n\n\nPAnSæ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿ\nEDS æ˜¯ç›¸å¯¹äºæ‰€æœ‰åƒç´ ä¹‹é—´çš„æœ€å¤§è·ç¦»å’Œçš„æ¯”ç‡ï¼Œå³ä½¿å›¾åƒä¸­æ²¡æœ‰ OOD\nå¯¹è±¡ï¼Œé«˜å¼‚å¸¸åˆ†æ•°åŒºåŸŸè‚¯å®šå­˜åœ¨äºæ¯å¹…å›¾åƒä¸­ã€‚\næ­¤å¤–ï¼Œæ¯ä¸ªåˆ†å¸ƒå†…ç±»åˆ«çš„è·ç¦»æ€»å’Œåˆ†å¸ƒå½¼æ­¤ç•¥æœ‰ä¸åŒï¼Œå¦‚å›¾4æ‰€ç¤ºã€‚ \nå°†MMSPä¸EDSç›¸ç»“åˆï¼Œä»¥æŠ‘åˆ¶é‚£äº›å®é™…ä¸Šå¤„äºåˆ†å¸ƒçŠ¶æ€çš„å…·æœ‰ä¸­é—´å“åº”çš„åƒç´ ã€‚\næ··åˆå‡½æ•°ä¸ºï¼š \\[\n\\hat{P} = \\alpha \\hat{P}^{EDS} + (1-\\alpha)\\hat{P}^{MMSP} \\tag{9}\n\\]\n\nÎ± ï¼š \\[\n\\alpha = \\frac{1}{1 + exp(-\\beta(\\hat{P}^{EDS} - \\gamma))} \\tag{10}\n\\]\n\nÎ² å’Œ Î³ æ˜¯æ§åˆ¶æŠ‘åˆ¶æ•ˆæœå’Œé˜ˆå€¼çš„è¶…å‚æ•°ã€‚\n\n\né€šè¿‡æ–¹ç¨‹ 9 å¾—åˆ°å¼‚å¸¸æ¦‚ç‡å›¾å’Œæ–¹ç¨‹ 5 å¾—åˆ°é—­é›†åˆ†å‰²å›¾åï¼Œæˆ‘ä»¬åº”ç”¨æ–¹ç¨‹ 1\nç”Ÿæˆæœ€ç»ˆçš„å¼€é›†åˆ†å‰²å›¾\n5. å®éªŒ\nOur experiments are divided into three parts.\n\nWe first evaluate our open-set semantic segmentation approach in\nSection 5.1.\nThen we demonstrate our incremental few-shot learning results\nin Section 5.2.\nBased on the open-set semantic segmentation module and\nincremental few-show learning module, the whole open world semantic\nsegmentation is realized in Section 5.3.\n\n5.1 å¼€é›†è¯­ä¹‰åˆ†å‰²\næ•°æ®é›†ã€‚ ä¸‰ä¸ªæ•°æ®é›†åŒ…æ‹¬ StreetHazards [11]ã€Lost and\nFound [38] å’Œ Road Anomaly [16] ç”¨äºè¯æ˜æˆ‘ä»¬åŸºäº DMLNet\nçš„å¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ–¹æ³•çš„ç¨³å¥æ€§å’Œæœ‰æ•ˆæ€§ã€‚\n\nStreetHazards\nçš„å¤§å¤šæ•°å¼‚å¸¸ç‰©ä½“æ˜¯å¤§å‹ç¨€æœ‰è¿è¾“æœºå™¨ï¼Œä¾‹å¦‚ç›´å‡æœºã€é£æœºå’Œæ‹–æ‹‰æœºã€‚\nLost and Found å«è®¸å¤šå°çš„å¼‚å¸¸ç‰©å“ï¼Œå¦‚è´§ç‰©ã€ç©å…·å’Œç›’å­ã€‚\n\nRoad Anomaly\næ•°æ®é›†ä¸å†é™åˆ¶åŸå¸‚åœºæ™¯ä¸­çš„åœºæ™¯ï¼Œè¿˜åŒ…å«æ‘åº„å’Œå±±è„‰çš„å›¾åƒã€‚\n\næŒ‡æ ‡ã€‚\nå¼€æ”¾é›†è¯­ä¹‰åˆ†å‰²æ˜¯å°é—­é›†åˆ†å‰²å’Œå¼‚å¸¸åˆ†å‰²çš„ç»„åˆï¼Œå¦‚ 4.2 èŠ‚æ‰€è¿°ã€‚\n\nå¯¹äºé—­é›†è¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ mIoU æ¥è¯„ä¼°æ€§èƒ½ã€‚\nå¯¹äºå¼‚å¸¸åˆ†å‰²ä»»åŠ¡ï¼Œæ ¹æ® [11] ä½¿ç”¨ä¸‰ä¸ªæŒ‡æ ‡ï¼ŒåŒ…æ‹¬ ROC\næ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUROCï¼‰ã€95%\nå¬å›çš„è¯¯æŠ¥ç‡ï¼ˆFPR95ï¼‰å’Œç²¾ç¡®å¬å›æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUPRï¼‰ã€‚\n\nå®æ–½ç»†èŠ‚ã€‚\n\nå¯¹äº StreetHazardsï¼Œæˆ‘ä»¬éµå¾ªä¸ [11] ç›¸åŒçš„è®­ç»ƒç¨‹åºï¼Œåœ¨\nStreetHazards çš„è®­ç»ƒé›†ä¸Šè®­ç»ƒ PSPNet [2]ã€‚\n\n\n\n\n\n\n\n\n\n[11]: Scaling out-of-distribution detection for real-world\nsettings.\nå¯¹äºLost and Foundå’Œ Road Anomalyï¼Œæˆ‘ä»¬æŒ‰ç…§ [16] ä½¿ç”¨ BDD-100k\n[39] æ¥è®­ç»ƒ PSPNetã€‚ è¯·æ³¨æ„ï¼ŒPSPNet ä»…ç”¨äºæå–æˆ‘ä»¬åœ¨ 4.1\nèŠ‚ä¸­è®¨è®ºçš„ç‰¹å¾ï¼ˆè·å¾—æ¯ä¸ªåƒç´ çš„åµŒå…¥å‘é‡ï¼‰ã€‚ æ··åˆæŸå¤±çš„ \\(Î»_{VL}\\) ä¸º 0.01ã€‚ æ‰€æœ‰åŸå‹ä¸­éé›¶å…ƒç´  \\(T\\) ä¸º 3ã€‚ç­‰å¼ 10 ä¸­çš„ Î² å’Œ Î³ åˆ†åˆ«ä¸º 20 å’Œ\n0.8ã€‚\n\n\n\n\n\n\n\n\n\n[16]: Detecting the unexpected via image resynthesis\n\nåŸºçº¿ã€‚\n\nStreetHazards: MSP [9]ã€Dropout [10]ã€AE [13]ã€MaxLogit [11] å’Œ\nSynthCP [17]ã€‚\nLost and Found å’Œ Road Anomaly: MSPã€MaxLogitã€Ensemble [12]ã€RBM\n[14] å’Œ DUIR [16]ã€‚\n\nç»“æœã€‚\nStreetHazards çš„ç»“æœå¦‚è¡¨ 1 æ‰€ç¤ºã€‚ \nå¯¹äº Lost and Found å’Œ Road Anomalyï¼ŒmIoU æ˜¯æ— æ•ˆçš„ï¼Œå› ä¸ºå®ƒä»¬åªæä¾›\nOOD ç±»æ ‡ç­¾ï¼Œä½†æ²¡æœ‰ç‰¹å®šçš„åˆ†å¸ƒå†…ç±»æ ‡ç­¾ã€‚ ç»“æœåœ¨è¡¨ 2 ä¸­ã€‚ \næˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼š\n\nåŸºäº DMLNet\nçš„æ–¹æ³•åœ¨æ‰€æœ‰ä¸‰ä¸ªå¼‚å¸¸åˆ†å‰²ç›¸å…³æŒ‡æ ‡ä¸­éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚\nä¸æœ€è¿‘æå‡ºçš„åŸºäº GAN çš„æ–¹æ³•ï¼ˆåŒ…æ‹¬ DUIR å’Œ\nSynthCPï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¼‚å¸¸åˆ†å‰²è´¨é‡æ–¹é¢ä¼˜äºå®ƒä»¬ï¼Œç»“æ„æ›´è½»é‡çº§ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ•´ä¸ªæµç¨‹ä¸­éœ€è¦ä¸¤ä¸ªæˆ–ä¸‰ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼Œè€Œæˆ‘ä»¬åªéœ€è¦æ¨ç†ä¸€æ¬¡ã€‚\n\nStreetHazards ä¸­é—­é›†åˆ†å‰²çš„ mIoU\nå€¼è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•å¯¹é—­é›†åˆ†å‰²æ²¡æœ‰å±å®³ã€‚\n\nä¸€äº›å®šæ€§ç»“æœå¦‚å›¾ 8 æ‰€ç¤º\n\næ¶ˆèç ”ç©¶ã€‚\næˆ‘ä»¬ä»”ç»†è¿›è¡Œäº†æ¶ˆèå®éªŒï¼Œç ”ç©¶äº†ä¸åŒæŸå¤±å‡½æ•°ï¼ˆVL å’Œ\nDCEï¼‰å’Œå¼‚å¸¸åˆ¤æ–­æ ‡å‡†ï¼ˆEDS å’Œ MMSPï¼‰çš„å½±å“ï¼Œå¦‚è¡¨ 3 æ‰€ç¤ºã€‚ \n\nDCE åœ¨ mIoU ä¸Šçš„æ€§èƒ½ä¼˜äº VL çš„äº‹å®è¡¨æ˜äº† æ’æ–¥åŠ›ã€‚\n\nEDS åœ¨æ‰€æœ‰æŸå¤±ä¸‹éƒ½ä¼˜äº MMSP\nå‡½æ•°ï¼Œè¿™æ„å‘³ç€==ä¸ç±»æ— å…³çš„æ ‡å‡†æ›´é€‚åˆäºå¼‚å¸¸åˆ†å‰²ä»»åŠ¡==\n\n","slug":"DMLNet","date":"2022-05-03T12:07:00.000Z","categories_index":"","tags_index":"æ·±åº¦å­¦ä¹ ,å¼‚å¸¸åˆ†å‰²,åº¦é‡å­¦ä¹ ","author_index":"Star"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very\nfirst post. Check documentation for\nmore info. If you get any problems when using Hexo, you can find the\nanswer in troubleshooting or\nyou can ask me on GitHub.\n\nQuick Start\nCreate a new post\n$ hexo new \"My New Post\"\nMore info: Writing\nRun server\n$ hexo server\nMore info: Server\nGenerate static files\n$ hexo generate\nMore info: Generating\nDeploy to remote sites\n$ hexo deploy\nMore info: Deployment\n","slug":"hello-world","date":"2022-05-03T10:31:15.256Z","categories_index":"","tags_index":"","author_index":"Star"}]